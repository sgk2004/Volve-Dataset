{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WELL_BORE_CODE</th>\n",
       "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
       "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
       "      <th>AVG_CHOKE_SIZE_P</th>\n",
       "      <th>AVG_WHP_P</th>\n",
       "      <th>AVG_WHT_P</th>\n",
       "      <th>DP_CHOKE_SIZE</th>\n",
       "      <th>BORE_OIL_VOL</th>\n",
       "      <th>BORE_GAS_VOL</th>\n",
       "      <th>BORE_WAT_VOL</th>\n",
       "      <th>FLOW_KIND</th>\n",
       "      <th>WELL_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>289.42</td>\n",
       "      <td>106.35</td>\n",
       "      <td>43.34</td>\n",
       "      <td>107.36</td>\n",
       "      <td>37.94</td>\n",
       "      <td>78.94</td>\n",
       "      <td>631.47</td>\n",
       "      <td>90439.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>270.24</td>\n",
       "      <td>107.64</td>\n",
       "      <td>47.17</td>\n",
       "      <td>99.19</td>\n",
       "      <td>60.76</td>\n",
       "      <td>70.63</td>\n",
       "      <td>1166.46</td>\n",
       "      <td>165720.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>262.84</td>\n",
       "      <td>107.87</td>\n",
       "      <td>47.73</td>\n",
       "      <td>94.60</td>\n",
       "      <td>63.05</td>\n",
       "      <td>66.05</td>\n",
       "      <td>1549.81</td>\n",
       "      <td>221707.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>255.53</td>\n",
       "      <td>107.97</td>\n",
       "      <td>48.53</td>\n",
       "      <td>89.99</td>\n",
       "      <td>64.55</td>\n",
       "      <td>61.41</td>\n",
       "      <td>1248.70</td>\n",
       "      <td>178063.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>247.20</td>\n",
       "      <td>108.05</td>\n",
       "      <td>49.84</td>\n",
       "      <td>84.78</td>\n",
       "      <td>65.72</td>\n",
       "      <td>56.15</td>\n",
       "      <td>1345.78</td>\n",
       "      <td>192602.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>8923</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.58</td>\n",
       "      <td>15.81</td>\n",
       "      <td>49.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>144.01</td>\n",
       "      <td>23201.35</td>\n",
       "      <td>203.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>8924</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.54</td>\n",
       "      <td>15.77</td>\n",
       "      <td>48.99</td>\n",
       "      <td>1.20</td>\n",
       "      <td>145.22</td>\n",
       "      <td>23068.07</td>\n",
       "      <td>202.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>8925</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.32</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.70</td>\n",
       "      <td>50.10</td>\n",
       "      <td>1.28</td>\n",
       "      <td>142.74</td>\n",
       "      <td>23059.68</td>\n",
       "      <td>203.84</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>8926</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.21</td>\n",
       "      <td>106.51</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.61</td>\n",
       "      <td>49.84</td>\n",
       "      <td>1.20</td>\n",
       "      <td>144.46</td>\n",
       "      <td>23090.47</td>\n",
       "      <td>202.76</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>8927</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.31</td>\n",
       "      <td>106.51</td>\n",
       "      <td>24.92</td>\n",
       "      <td>15.76</td>\n",
       "      <td>48.73</td>\n",
       "      <td>1.30</td>\n",
       "      <td>106.30</td>\n",
       "      <td>17537.08</td>\n",
       "      <td>155.70</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5943 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  WELL_BORE_CODE  AVG_DOWNHOLE_PRESSURE  \\\n",
       "0             15   NO 15/9-F-1 C                 289.42   \n",
       "1             16   NO 15/9-F-1 C                 270.24   \n",
       "2             17   NO 15/9-F-1 C                 262.84   \n",
       "3             18   NO 15/9-F-1 C                 255.53   \n",
       "4             19   NO 15/9-F-1 C                 247.20   \n",
       "...          ...             ...                    ...   \n",
       "5938        8923  NO 15/9-F-15 D                 194.98   \n",
       "5939        8924  NO 15/9-F-15 D                 194.98   \n",
       "5940        8925  NO 15/9-F-15 D                 194.32   \n",
       "5941        8926  NO 15/9-F-15 D                 195.21   \n",
       "5942        8927  NO 15/9-F-15 D                 195.31   \n",
       "\n",
       "      AVG_DOWNHOLE_TEMPERATURE  AVG_CHOKE_SIZE_P  AVG_WHP_P  AVG_WHT_P  \\\n",
       "0                       106.35             43.34     107.36      37.94   \n",
       "1                       107.64             47.17      99.19      60.76   \n",
       "2                       107.87             47.73      94.60      63.05   \n",
       "3                       107.97             48.53      89.99      64.55   \n",
       "4                       108.05             49.84      84.78      65.72   \n",
       "...                        ...               ...        ...        ...   \n",
       "5938                    106.52             31.58      15.81      49.02   \n",
       "5939                    106.52             31.54      15.77      48.99   \n",
       "5940                    106.52             31.52      15.70      50.10   \n",
       "5941                    106.51             31.52      15.61      49.84   \n",
       "5942                    106.51             24.92      15.76      48.73   \n",
       "\n",
       "      DP_CHOKE_SIZE  BORE_OIL_VOL  BORE_GAS_VOL  BORE_WAT_VOL   FLOW_KIND  \\\n",
       "0             78.94        631.47      90439.09          0.00  production   \n",
       "1             70.63       1166.46     165720.39          0.00  production   \n",
       "2             66.05       1549.81     221707.31          0.00  production   \n",
       "3             61.41       1248.70     178063.52          0.00  production   \n",
       "4             56.15       1345.78     192602.19          0.00  production   \n",
       "...             ...           ...           ...           ...         ...   \n",
       "5938           1.26        144.01      23201.35        203.93  production   \n",
       "5939           1.20        145.22      23068.07        202.93  production   \n",
       "5940           1.28        142.74      23059.68        203.84  production   \n",
       "5941           1.20        144.46      23090.47        202.76  production   \n",
       "5942           1.30        106.30      17537.08        155.70  production   \n",
       "\n",
       "     WELL_TYPE  \n",
       "0           OP  \n",
       "1           OP  \n",
       "2           OP  \n",
       "3           OP  \n",
       "4           OP  \n",
       "...        ...  \n",
       "5938        OP  \n",
       "5939        OP  \n",
       "5940        OP  \n",
       "5941        OP  \n",
       "5942        OP  \n",
       "\n",
       "[5943 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data csv\n",
    "all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "all_wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUTS: AVG_CHOKE_SIZE_P, AVG_WHP_P, AVG_WHT_P, BORE_OIL_VOL, BORE_GAS_VOL, BORE_WAT_VOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5943, 6)\n"
     ]
    }
   ],
   "source": [
    "#read in data for analysis \n",
    "X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = X_train.shape[1]\n",
    "number_hidden_nodes = 100\n",
    "\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(number_hidden_nodes, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "from keras import losses\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",\n",
    "              optimizer=\"adam\", metrics=[r_square, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,901\n",
      "Trainable params: 10,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "1263/1263 - 1s - loss: 0.6181 - r_square: 0.3275 - rmse: 0.6181 - val_loss: 0.4434 - val_r_square: 0.5749 - val_rmse: 0.4434\n",
      "Epoch 2/100\n",
      "1263/1263 - 0s - loss: 0.3762 - r_square: 0.6564 - rmse: 0.3762 - val_loss: 0.3439 - val_r_square: 0.6459 - val_rmse: 0.3439\n",
      "Epoch 3/100\n",
      "1263/1263 - 0s - loss: 0.2944 - r_square: 0.7600 - rmse: 0.2944 - val_loss: 0.2964 - val_r_square: 0.6773 - val_rmse: 0.2964\n",
      "Epoch 4/100\n",
      "1263/1263 - 0s - loss: 0.2461 - r_square: 0.8033 - rmse: 0.2461 - val_loss: 0.2866 - val_r_square: 0.6703 - val_rmse: 0.2866\n",
      "Epoch 5/100\n",
      "1263/1263 - 0s - loss: 0.2321 - r_square: 0.8203 - rmse: 0.2321 - val_loss: 0.2685 - val_r_square: 0.6724 - val_rmse: 0.2685\n",
      "Epoch 6/100\n",
      "1263/1263 - 0s - loss: 0.2143 - r_square: 0.8387 - rmse: 0.2143 - val_loss: 0.2544 - val_r_square: 0.6619 - val_rmse: 0.2544\n",
      "Epoch 7/100\n",
      "1263/1263 - 0s - loss: 0.2063 - r_square: 0.8550 - rmse: 0.2063 - val_loss: 0.2492 - val_r_square: 0.6664 - val_rmse: 0.2492\n",
      "Epoch 8/100\n",
      "1263/1263 - 0s - loss: 0.1968 - r_square: 0.8596 - rmse: 0.1968 - val_loss: 0.2499 - val_r_square: 0.6578 - val_rmse: 0.2499\n",
      "Epoch 9/100\n",
      "1263/1263 - 0s - loss: 0.1930 - r_square: 0.8570 - rmse: 0.1930 - val_loss: 0.2845 - val_r_square: 0.6571 - val_rmse: 0.2845\n",
      "Epoch 10/100\n",
      "1263/1263 - 0s - loss: 0.1980 - r_square: 0.8623 - rmse: 0.1980 - val_loss: 0.2372 - val_r_square: 0.6519 - val_rmse: 0.2372\n",
      "Epoch 11/100\n",
      "1263/1263 - 0s - loss: 0.1819 - r_square: 0.8627 - rmse: 0.1819 - val_loss: 0.2267 - val_r_square: 0.6570 - val_rmse: 0.2267\n",
      "Epoch 12/100\n",
      "1263/1263 - 0s - loss: 0.1708 - r_square: 0.8792 - rmse: 0.1708 - val_loss: 0.2154 - val_r_square: 0.6631 - val_rmse: 0.2154\n",
      "Epoch 13/100\n",
      "1263/1263 - 0s - loss: 0.1692 - r_square: 0.8793 - rmse: 0.1692 - val_loss: 0.2248 - val_r_square: 0.6545 - val_rmse: 0.2248\n",
      "Epoch 14/100\n",
      "1263/1263 - 0s - loss: 0.1695 - r_square: 0.8581 - rmse: 0.1695 - val_loss: 0.2252 - val_r_square: 0.6564 - val_rmse: 0.2252\n",
      "Epoch 15/100\n",
      "1263/1263 - 0s - loss: 0.1720 - r_square: 0.8835 - rmse: 0.1720 - val_loss: 0.2238 - val_r_square: 0.6414 - val_rmse: 0.2238\n",
      "Epoch 16/100\n",
      "1263/1263 - 0s - loss: 0.1657 - r_square: 0.8762 - rmse: 0.1657 - val_loss: 0.2142 - val_r_square: 0.6518 - val_rmse: 0.2142\n",
      "Epoch 17/100\n",
      "1263/1263 - 0s - loss: 0.1590 - r_square: 0.8773 - rmse: 0.1590 - val_loss: 0.2262 - val_r_square: 0.6505 - val_rmse: 0.2262\n",
      "Epoch 18/100\n",
      "1263/1263 - 0s - loss: 0.1608 - r_square: 0.8799 - rmse: 0.1608 - val_loss: 0.2185 - val_r_square: 0.6578 - val_rmse: 0.2185\n",
      "Epoch 19/100\n",
      "1263/1263 - 0s - loss: 0.1582 - r_square: 0.8861 - rmse: 0.1582 - val_loss: 0.2098 - val_r_square: 0.6490 - val_rmse: 0.2098\n",
      "Epoch 20/100\n",
      "1263/1263 - 0s - loss: 0.1537 - r_square: 0.8850 - rmse: 0.1537 - val_loss: 0.2071 - val_r_square: 0.6574 - val_rmse: 0.2071\n",
      "Epoch 21/100\n",
      "1263/1263 - 0s - loss: 0.1569 - r_square: 0.8795 - rmse: 0.1569 - val_loss: 0.2085 - val_r_square: 0.6427 - val_rmse: 0.2085\n",
      "Epoch 22/100\n",
      "1263/1263 - 0s - loss: 0.1529 - r_square: 0.8855 - rmse: 0.1529 - val_loss: 0.2075 - val_r_square: 0.6463 - val_rmse: 0.2075\n",
      "Epoch 23/100\n",
      "1263/1263 - 0s - loss: 0.1458 - r_square: 0.8847 - rmse: 0.1458 - val_loss: 0.2085 - val_r_square: 0.6490 - val_rmse: 0.2085\n",
      "Epoch 24/100\n",
      "1263/1263 - 0s - loss: 0.1616 - r_square: 0.8788 - rmse: 0.1616 - val_loss: 0.2156 - val_r_square: 0.6489 - val_rmse: 0.2156\n",
      "Epoch 25/100\n",
      "1263/1263 - 0s - loss: 0.1562 - r_square: 0.8859 - rmse: 0.1562 - val_loss: 0.2139 - val_r_square: 0.6454 - val_rmse: 0.2139\n",
      "Epoch 26/100\n",
      "1263/1263 - 0s - loss: 0.1544 - r_square: 0.8852 - rmse: 0.1544 - val_loss: 0.2056 - val_r_square: 0.6536 - val_rmse: 0.2056\n",
      "Epoch 27/100\n",
      "1263/1263 - 0s - loss: 0.1460 - r_square: 0.8840 - rmse: 0.1460 - val_loss: 0.2084 - val_r_square: 0.6483 - val_rmse: 0.2084\n",
      "Epoch 28/100\n",
      "1263/1263 - 0s - loss: 0.1459 - r_square: 0.8848 - rmse: 0.1459 - val_loss: 0.2028 - val_r_square: 0.6518 - val_rmse: 0.2028\n",
      "Epoch 29/100\n",
      "1263/1263 - 0s - loss: 0.1420 - r_square: 0.8880 - rmse: 0.1420 - val_loss: 0.2002 - val_r_square: 0.6432 - val_rmse: 0.2002\n",
      "Epoch 30/100\n",
      "1263/1263 - 0s - loss: 0.1489 - r_square: 0.8916 - rmse: 0.1489 - val_loss: 0.1986 - val_r_square: 0.6477 - val_rmse: 0.1986\n",
      "Epoch 31/100\n",
      "1263/1263 - 0s - loss: 0.1424 - r_square: 0.8768 - rmse: 0.1424 - val_loss: 0.1975 - val_r_square: 0.6537 - val_rmse: 0.1975\n",
      "Epoch 32/100\n",
      "1263/1263 - 0s - loss: 0.1428 - r_square: 0.8827 - rmse: 0.1428 - val_loss: 0.1968 - val_r_square: 0.6532 - val_rmse: 0.1968\n",
      "Epoch 33/100\n",
      "1263/1263 - 0s - loss: 0.1382 - r_square: 0.8911 - rmse: 0.1382 - val_loss: 0.1966 - val_r_square: 0.6521 - val_rmse: 0.1966\n",
      "Epoch 34/100\n",
      "1263/1263 - 0s - loss: 0.1415 - r_square: 0.8927 - rmse: 0.1415 - val_loss: 0.2054 - val_r_square: 0.6456 - val_rmse: 0.2054\n",
      "Epoch 35/100\n",
      "1263/1263 - 0s - loss: 0.1471 - r_square: 0.8900 - rmse: 0.1471 - val_loss: 0.2142 - val_r_square: 0.6418 - val_rmse: 0.2142\n",
      "Epoch 36/100\n",
      "1263/1263 - 0s - loss: 0.1436 - r_square: 0.8900 - rmse: 0.1436 - val_loss: 0.2046 - val_r_square: 0.6516 - val_rmse: 0.2046\n",
      "Epoch 37/100\n",
      "1263/1263 - 0s - loss: 0.1512 - r_square: 0.8888 - rmse: 0.1512 - val_loss: 0.1982 - val_r_square: 0.6584 - val_rmse: 0.1982\n",
      "Epoch 38/100\n",
      "1263/1263 - 0s - loss: 0.1418 - r_square: 0.8951 - rmse: 0.1418 - val_loss: 0.2033 - val_r_square: 0.6539 - val_rmse: 0.2033\n",
      "Epoch 39/100\n",
      "1263/1263 - 0s - loss: 0.1433 - r_square: 0.8673 - rmse: 0.1433 - val_loss: 0.2037 - val_r_square: 0.6527 - val_rmse: 0.2037\n",
      "Epoch 40/100\n",
      "1263/1263 - 0s - loss: 0.1366 - r_square: 0.8981 - rmse: 0.1366 - val_loss: 0.1961 - val_r_square: 0.6527 - val_rmse: 0.1961\n",
      "Epoch 41/100\n",
      "1263/1263 - 0s - loss: 0.1381 - r_square: 0.8931 - rmse: 0.1381 - val_loss: 0.2072 - val_r_square: 0.6529 - val_rmse: 0.2072\n",
      "Epoch 42/100\n",
      "1263/1263 - 0s - loss: 0.1412 - r_square: 0.8884 - rmse: 0.1412 - val_loss: 0.1970 - val_r_square: 0.6471 - val_rmse: 0.1970\n",
      "Epoch 43/100\n",
      "1263/1263 - 0s - loss: 0.1429 - r_square: 0.8874 - rmse: 0.1429 - val_loss: 0.1925 - val_r_square: 0.6545 - val_rmse: 0.1925\n",
      "Epoch 44/100\n",
      "1263/1263 - 0s - loss: 0.1349 - r_square: 0.9016 - rmse: 0.1349 - val_loss: 0.2062 - val_r_square: 0.6300 - val_rmse: 0.2062\n",
      "Epoch 45/100\n",
      "1263/1263 - 0s - loss: 0.1397 - r_square: 0.8956 - rmse: 0.1397 - val_loss: 0.2005 - val_r_square: 0.6521 - val_rmse: 0.2005\n",
      "Epoch 46/100\n",
      "1263/1263 - 0s - loss: 0.1317 - r_square: 0.8947 - rmse: 0.1317 - val_loss: 0.1907 - val_r_square: 0.6464 - val_rmse: 0.1907\n",
      "Epoch 47/100\n",
      "1263/1263 - 0s - loss: 0.1303 - r_square: 0.9029 - rmse: 0.1303 - val_loss: 0.2040 - val_r_square: 0.6416 - val_rmse: 0.2040\n",
      "Epoch 48/100\n",
      "1263/1263 - 0s - loss: 0.1405 - r_square: 0.9032 - rmse: 0.1405 - val_loss: 0.2106 - val_r_square: 0.6336 - val_rmse: 0.2106\n",
      "Epoch 49/100\n",
      "1263/1263 - 0s - loss: 0.1382 - r_square: 0.8975 - rmse: 0.1382 - val_loss: 0.2050 - val_r_square: 0.6475 - val_rmse: 0.2050\n",
      "Epoch 50/100\n",
      "1263/1263 - 0s - loss: 0.1319 - r_square: 0.8995 - rmse: 0.1319 - val_loss: 0.1956 - val_r_square: 0.6457 - val_rmse: 0.1956\n",
      "Epoch 51/100\n",
      "1263/1263 - 0s - loss: 0.1304 - r_square: 0.8875 - rmse: 0.1304 - val_loss: 0.1894 - val_r_square: 0.6469 - val_rmse: 0.1894\n",
      "Epoch 52/100\n",
      "1263/1263 - 0s - loss: 0.1348 - r_square: 0.8949 - rmse: 0.1348 - val_loss: 0.1980 - val_r_square: 0.6422 - val_rmse: 0.1980\n",
      "Epoch 53/100\n",
      "1263/1263 - 0s - loss: 0.1321 - r_square: 0.9007 - rmse: 0.1321 - val_loss: 0.1874 - val_r_square: 0.6490 - val_rmse: 0.1874\n",
      "Epoch 54/100\n",
      "1263/1263 - 0s - loss: 0.1385 - r_square: 0.8894 - rmse: 0.1385 - val_loss: 0.1972 - val_r_square: 0.6421 - val_rmse: 0.1972\n",
      "Epoch 55/100\n",
      "1263/1263 - 0s - loss: 0.1343 - r_square: 0.9033 - rmse: 0.1343 - val_loss: 0.2095 - val_r_square: 0.6521 - val_rmse: 0.2095\n",
      "Epoch 56/100\n",
      "1263/1263 - 0s - loss: 0.1301 - r_square: 0.9039 - rmse: 0.1301 - val_loss: 0.1879 - val_r_square: 0.6463 - val_rmse: 0.1879\n",
      "Epoch 57/100\n",
      "1263/1263 - 0s - loss: 0.1313 - r_square: 0.9010 - rmse: 0.1313 - val_loss: 0.1940 - val_r_square: 0.6529 - val_rmse: 0.1940\n",
      "Epoch 58/100\n",
      "1263/1263 - 0s - loss: 0.1295 - r_square: 0.9022 - rmse: 0.1295 - val_loss: 0.1888 - val_r_square: 0.6536 - val_rmse: 0.1888\n",
      "Epoch 59/100\n",
      "1263/1263 - 0s - loss: 0.1289 - r_square: 0.9045 - rmse: 0.1289 - val_loss: 0.1929 - val_r_square: 0.6484 - val_rmse: 0.1929\n",
      "Epoch 60/100\n",
      "1263/1263 - 0s - loss: 0.1318 - r_square: 0.9033 - rmse: 0.1318 - val_loss: 0.1959 - val_r_square: 0.6519 - val_rmse: 0.1959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "1263/1263 - 0s - loss: 0.1311 - r_square: 0.9019 - rmse: 0.1311 - val_loss: 0.1994 - val_r_square: 0.6510 - val_rmse: 0.1994\n",
      "Epoch 62/100\n",
      "1263/1263 - 0s - loss: 0.1372 - r_square: 0.9006 - rmse: 0.1372 - val_loss: 0.1943 - val_r_square: 0.6381 - val_rmse: 0.1943\n",
      "Epoch 63/100\n",
      "1263/1263 - 0s - loss: 0.1309 - r_square: 0.8986 - rmse: 0.1309 - val_loss: 0.2170 - val_r_square: 0.6467 - val_rmse: 0.2170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29df8dabc88>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping tuning #1\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10,verbose=0, mode='min')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486/1486 [==============================] - 0s 25us/sample - loss: 0.1540 - r_square: 0.8638 - rmse: 0.1540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15397970598005511, 0.86375046, 0.15397969]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "1263/1263 - 0s - loss: 0.1282 - r_square: 0.8927 - rmse: 0.1282 - val_loss: 0.2024 - val_r_square: 0.6462 - val_rmse: 0.2024\n",
      "Epoch 2/100\n",
      "1263/1263 - 0s - loss: 0.1269 - r_square: 0.8994 - rmse: 0.1269 - val_loss: 0.1923 - val_r_square: 0.6564 - val_rmse: 0.1923\n",
      "Epoch 3/100\n",
      "1263/1263 - 0s - loss: 0.1315 - r_square: 0.8990 - rmse: 0.1315 - val_loss: 0.1863 - val_r_square: 0.6583 - val_rmse: 0.1863\n",
      "Epoch 4/100\n",
      "1263/1263 - 0s - loss: 0.1275 - r_square: 0.9042 - rmse: 0.1275 - val_loss: 0.1868 - val_r_square: 0.6549 - val_rmse: 0.1868\n",
      "Epoch 5/100\n",
      "1263/1263 - 0s - loss: 0.1270 - r_square: 0.9041 - rmse: 0.1270 - val_loss: 0.1962 - val_r_square: 0.6486 - val_rmse: 0.1962\n",
      "Epoch 6/100\n",
      "1263/1263 - 0s - loss: 0.1283 - r_square: 0.9036 - rmse: 0.1283 - val_loss: 0.1919 - val_r_square: 0.6515 - val_rmse: 0.1919\n",
      "Epoch 7/100\n",
      "1263/1263 - 0s - loss: 0.1252 - r_square: 0.8838 - rmse: 0.1252 - val_loss: 0.2021 - val_r_square: 0.6550 - val_rmse: 0.2021\n",
      "Epoch 8/100\n",
      "1263/1263 - 0s - loss: 0.1244 - r_square: 0.9079 - rmse: 0.1244 - val_loss: 0.1884 - val_r_square: 0.6545 - val_rmse: 0.1884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29dfa3e3688>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping tuning #2\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_r_square', min_delta=0.000001, patience=5,verbose=0, mode='max')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486/1486 [==============================] - 0s 23us/sample - loss: 0.1283 - r_square: 0.8711 - rmse: 0.1283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12826210706623856, 0.87107533, 0.12826209]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperas Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scale data for create model function\n",
    "def data():\n",
    "    #read in data for analysis \n",
    "    all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "    X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "    y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "    #split into test and train data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # # Create a StandardScater model and fit it to the training data\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    y_scaler = StandardScaler().fit(y_train)\n",
    "    # # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    y_train_scaled = y_scaler.transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    \n",
    "    x_train = X_train_scaled.reshape(-1,6)\n",
    "    x_test = X_test_scaled.reshape(-1,6)\n",
    "    y_train = y_train_scaled.reshape(-1,1)\n",
    "    y_test = y_test_scaled.reshape(-1,1)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import losses\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import print_summary\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [50,200,500]),\n",
      "        'Dropout': hp.uniform('Dropout', 0,1),\n",
      "        'Dense_1': hp.choice('Dense_1', [50,200,500]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0,1),\n",
      "        'batch_size': hp.choice('batch_size', [64,128]),\n",
      "        'epochs': hp.choice('epochs', [50,100,150]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: #read in data for analysis \n",
      "   3: all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
      "   4: X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
      "   5: y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
      "   6: #split into test and train data\n",
      "   7: from sklearn.model_selection import train_test_split\n",
      "   8: X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
      "   9: from sklearn.preprocessing import StandardScaler\n",
      "  10: # # Create a StandardScater model and fit it to the training data\n",
      "  11: X_scaler = StandardScaler().fit(X_train)\n",
      "  12: y_scaler = StandardScaler().fit(y_train)\n",
      "  13: # # Transform the training and testing data using the X_scaler and y_scaler models\n",
      "  14: X_train_scaled = X_scaler.transform(X_train)\n",
      "  15: X_test_scaled = X_scaler.transform(X_test)\n",
      "  16: y_train_scaled = y_scaler.transform(y_train)\n",
      "  17: y_test_scaled = y_scaler.transform(y_test)\n",
      "  18: \n",
      "  19: x_train = X_train_scaled.reshape(-1,6)\n",
      "  20: x_test = X_test_scaled.reshape(-1,6)\n",
      "  21: y_train = y_train_scaled.reshape(-1,1)\n",
      "  22: y_test = y_test_scaled.reshape(-1,1)\n",
      "  23: \n",
      "  24: \n",
      "  25: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print(x_train.shape)\n",
      "   4:     model= Sequential() \n",
      "   5:     model.add(Dense(space['Dense'], input_dim=x_train.shape[1], activation= 'relu'))\n",
      "   6: #     model.add(Activation('relu'))\n",
      "   7:     model.add(Dropout(space['Dropout']))\n",
      "   8:     model.add(Dense(space['Dense_1'],activation= 'relu'))\n",
      "   9:     #model.add(Activation('relu'))\n",
      "  10:     model.add(Dropout(space['Dropout_1']))\n",
      "  11:     model.add(Dense(1, activation= 'linear'))\n",
      "  12:    # model.add(Activation('linear'))\n",
      "  13:     \n",
      "  14: ################################################\n",
      "  15:     def rmse(y_true, y_pred):\n",
      "  16:         return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
      "  17: # mean squared error (mse) for regression  (only for Keras tensors)\n",
      "  18:     def mse(y_true, y_pred):\n",
      "  19:         return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
      "  20:     def r_square(y_true, y_pred):\n",
      "  21:         SS_res =  K.sum(K.square(y_true - y_pred)) \n",
      "  22:         SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
      "  23:         return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
      "  24: #############################################\n",
      "  25: \n",
      "  26:     model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
      "  27:     print_summary(model, line_length=None, positions=None, print_fn=None)\n",
      "  28:     result= model.fit(x_train, y_train,\n",
      "  29:                       batch_size=space['batch_size'],\n",
      "  30:                       epochs=space['epochs'],\n",
      "  31:                       verbose=2,\n",
      "  32:                       validation_split =0.15)\n",
      "  33:     validation_acc= np.min(result.history['val_loss'])\n",
      "  34:     print('Lowest Validation Loss:', validation_acc)\n",
      "  35:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
      "  36: \n",
      "(4457, 6)                                                                                                              \n",
      "  0%|                                                                            | 0/5 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:Large dropout rate: 0.73717 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.651797 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_1\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_1 (Dense)              (None, 200)               1400                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_1 (Dropout)          (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_2 (Dense)              (None, 200)               40200                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_2 (Dropout)          (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_3 (Dense)              (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 41,801                                                                                                   \n",
      "Trainable params: 41,801                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/150                                                                                                            \n",
      " - 0s - loss: 0.7132 - r_square: 0.1023 - rmse: 0.7132 - val_loss: 0.4879 - val_r_square: 0.5976 - val_rmse: 0.4879    \n",
      "\n",
      "Epoch 2/150                                                                                                            \n",
      " - 0s - loss: 0.5688 - r_square: 0.4086 - rmse: 0.5688 - val_loss: 0.4514 - val_r_square: 0.6538 - val_rmse: 0.4514    \n",
      "\n",
      "Epoch 3/150                                                                                                            \n",
      " - 0s - loss: 0.5185 - r_square: 0.4889 - rmse: 0.5185 - val_loss: 0.4156 - val_r_square: 0.6926 - val_rmse: 0.4156    \n",
      "\n",
      "Epoch 4/150                                                                                                            \n",
      " - 0s - loss: 0.4780 - r_square: 0.5408 - rmse: 0.4780 - val_loss: 0.4048 - val_r_square: 0.7083 - val_rmse: 0.4048    \n",
      "\n",
      "Epoch 5/150                                                                                                            \n",
      " - 0s - loss: 0.4568 - r_square: 0.5779 - rmse: 0.4568 - val_loss: 0.3839 - val_r_square: 0.7247 - val_rmse: 0.3839    \n",
      "\n",
      "Epoch 6/150                                                                                                            \n",
      " - 0s - loss: 0.4286 - r_square: 0.6127 - rmse: 0.4286 - val_loss: 0.3741 - val_r_square: 0.7377 - val_rmse: 0.3741    \n",
      "\n",
      "Epoch 7/150                                                                                                            \n",
      " - 0s - loss: 0.4197 - r_square: 0.6241 - rmse: 0.4197 - val_loss: 0.3769 - val_r_square: 0.7273 - val_rmse: 0.3769    \n",
      "\n",
      "Epoch 8/150                                                                                                            \n",
      " - 0s - loss: 0.4118 - r_square: 0.6272 - rmse: 0.4118 - val_loss: 0.3660 - val_r_square: 0.7371 - val_rmse: 0.3660    \n",
      "\n",
      "Epoch 9/150                                                                                                            \n",
      " - 0s - loss: 0.3984 - r_square: 0.6561 - rmse: 0.3984 - val_loss: 0.3543 - val_r_square: 0.7528 - val_rmse: 0.3543    \n",
      "\n",
      "Epoch 10/150                                                                                                           \n",
      " - 0s - loss: 0.3838 - r_square: 0.6696 - rmse: 0.3838 - val_loss: 0.3407 - val_r_square: 0.7639 - val_rmse: 0.3407    \n",
      "\n",
      "Epoch 11/150                                                                                                           \n",
      " - 0s - loss: 0.3863 - r_square: 0.6669 - rmse: 0.3863 - val_loss: 0.3283 - val_r_square: 0.7741 - val_rmse: 0.3283    \n",
      "\n",
      "Epoch 12/150                                                                                                           \n",
      " - 0s - loss: 0.3680 - r_square: 0.6957 - rmse: 0.3680 - val_loss: 0.3367 - val_r_square: 0.7636 - val_rmse: 0.3367    \n",
      "\n",
      "Epoch 13/150                                                                                                           \n",
      " - 0s - loss: 0.3643 - r_square: 0.6934 - rmse: 0.3643 - val_loss: 0.3270 - val_r_square: 0.7752 - val_rmse: 0.3270    \n",
      "\n",
      "Epoch 14/150                                                                                                           \n",
      " - 0s - loss: 0.3588 - r_square: 0.6895 - rmse: 0.3588 - val_loss: 0.3153 - val_r_square: 0.7835 - val_rmse: 0.3153    \n",
      "\n",
      "Epoch 15/150                                                                                                           \n",
      " - 0s - loss: 0.3512 - r_square: 0.7072 - rmse: 0.3512 - val_loss: 0.3057 - val_r_square: 0.7920 - val_rmse: 0.3057    \n",
      "\n",
      "Epoch 16/150                                                                                                           \n",
      " - 0s - loss: 0.3492 - r_square: 0.7003 - rmse: 0.3492 - val_loss: 0.3195 - val_r_square: 0.7760 - val_rmse: 0.3195    \n",
      "\n",
      "Epoch 17/150                                                                                                           \n",
      " - 0s - loss: 0.3334 - r_square: 0.7227 - rmse: 0.3334 - val_loss: 0.3082 - val_r_square: 0.7867 - val_rmse: 0.3082    \n",
      "\n",
      "Epoch 18/150                                                                                                           \n",
      " - 0s - loss: 0.3361 - r_square: 0.7144 - rmse: 0.3361 - val_loss: 0.2971 - val_r_square: 0.7962 - val_rmse: 0.2971    \n",
      "\n",
      "Epoch 19/150                                                                                                           \n",
      " - 0s - loss: 0.3328 - r_square: 0.7299 - rmse: 0.3328 - val_loss: 0.2809 - val_r_square: 0.8147 - val_rmse: 0.2809    \n",
      "\n",
      "Epoch 20/150                                                                                                           \n",
      " - 0s - loss: 0.3276 - r_square: 0.7370 - rmse: 0.3276 - val_loss: 0.2907 - val_r_square: 0.8066 - val_rmse: 0.2907    \n",
      "\n",
      "Epoch 21/150                                                                                                           \n",
      " - 0s - loss: 0.3261 - r_square: 0.7296 - rmse: 0.3261 - val_loss: 0.2780 - val_r_square: 0.8193 - val_rmse: 0.2780    \n",
      "\n",
      "Epoch 22/150                                                                                                           \n",
      " - 0s - loss: 0.3263 - r_square: 0.7313 - rmse: 0.3263 - val_loss: 0.2668 - val_r_square: 0.8226 - val_rmse: 0.2668    \n",
      "\n",
      "Epoch 23/150                                                                                                           \n",
      " - 0s - loss: 0.3149 - r_square: 0.7437 - rmse: 0.3149 - val_loss: 0.2777 - val_r_square: 0.8194 - val_rmse: 0.2777    \n",
      "\n",
      "Epoch 24/150                                                                                                           \n",
      " - 0s - loss: 0.3205 - r_square: 0.7456 - rmse: 0.3205 - val_loss: 0.2703 - val_r_square: 0.8229 - val_rmse: 0.2703    \n",
      "\n",
      "Epoch 25/150                                                                                                           \n",
      " - 0s - loss: 0.3116 - r_square: 0.7390 - rmse: 0.3116 - val_loss: 0.2633 - val_r_square: 0.8284 - val_rmse: 0.2633    \n",
      "\n",
      "Epoch 26/150                                                                                                           \n",
      " - 0s - loss: 0.3096 - r_square: 0.7539 - rmse: 0.3096 - val_loss: 0.2617 - val_r_square: 0.8281 - val_rmse: 0.2617    \n",
      "\n",
      "Epoch 27/150                                                                                                           \n",
      " - 0s - loss: 0.3061 - r_square: 0.7576 - rmse: 0.3061 - val_loss: 0.2601 - val_r_square: 0.8334 - val_rmse: 0.2601    \n",
      "\n",
      "Epoch 28/150                                                                                                           \n",
      " - 0s - loss: 0.3070 - r_square: 0.7473 - rmse: 0.3070 - val_loss: 0.2646 - val_r_square: 0.8307 - val_rmse: 0.2646    \n",
      "\n",
      "Epoch 29/150                                                                                                           \n",
      " - 0s - loss: 0.3065 - r_square: 0.7600 - rmse: 0.3065 - val_loss: 0.2613 - val_r_square: 0.8306 - val_rmse: 0.2613    \n",
      "\n",
      "Epoch 30/150                                                                                                           \n",
      " - 0s - loss: 0.2984 - r_square: 0.7653 - rmse: 0.2984 - val_loss: 0.2578 - val_r_square: 0.8336 - val_rmse: 0.2578    \n",
      "\n",
      "Epoch 31/150                                                                                                           \n",
      " - 0s - loss: 0.3039 - r_square: 0.7592 - rmse: 0.3039 - val_loss: 0.2629 - val_r_square: 0.8339 - val_rmse: 0.2629    \n",
      "\n",
      "Epoch 32/150                                                                                                           \n",
      " - 0s - loss: 0.2946 - r_square: 0.7712 - rmse: 0.2946 - val_loss: 0.2506 - val_r_square: 0.8408 - val_rmse: 0.2506    \n",
      "\n",
      "Epoch 33/150                                                                                                           \n",
      " - 0s - loss: 0.2992 - r_square: 0.7705 - rmse: 0.2992 - val_loss: 0.2454 - val_r_square: 0.8469 - val_rmse: 0.2454    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150                                                                                                           \n",
      " - 0s - loss: 0.2966 - r_square: 0.7644 - rmse: 0.2966 - val_loss: 0.2543 - val_r_square: 0.8402 - val_rmse: 0.2543    \n",
      "\n",
      "Epoch 35/150                                                                                                           \n",
      " - 0s - loss: 0.2919 - r_square: 0.7781 - rmse: 0.2919 - val_loss: 0.2497 - val_r_square: 0.8421 - val_rmse: 0.2497    \n",
      "\n",
      "Epoch 36/150                                                                                                           \n",
      " - 0s - loss: 0.2932 - r_square: 0.7645 - rmse: 0.2932 - val_loss: 0.2528 - val_r_square: 0.8424 - val_rmse: 0.2528    \n",
      "\n",
      "Epoch 37/150                                                                                                           \n",
      " - 0s - loss: 0.2907 - r_square: 0.7755 - rmse: 0.2907 - val_loss: 0.2557 - val_r_square: 0.8399 - val_rmse: 0.2557    \n",
      "\n",
      "Epoch 38/150                                                                                                           \n",
      " - 0s - loss: 0.2879 - r_square: 0.7789 - rmse: 0.2879 - val_loss: 0.2531 - val_r_square: 0.8425 - val_rmse: 0.2531    \n",
      "\n",
      "Epoch 39/150                                                                                                           \n",
      " - 0s - loss: 0.2883 - r_square: 0.7818 - rmse: 0.2883 - val_loss: 0.2416 - val_r_square: 0.8476 - val_rmse: 0.2416    \n",
      "\n",
      "Epoch 40/150                                                                                                           \n",
      " - 0s - loss: 0.2948 - r_square: 0.7718 - rmse: 0.2948 - val_loss: 0.2529 - val_r_square: 0.8418 - val_rmse: 0.2529    \n",
      "\n",
      "Epoch 41/150                                                                                                           \n",
      " - 0s - loss: 0.2887 - r_square: 0.7737 - rmse: 0.2887 - val_loss: 0.2651 - val_r_square: 0.8320 - val_rmse: 0.2651    \n",
      "\n",
      "Epoch 42/150                                                                                                           \n",
      " - 0s - loss: 0.2872 - r_square: 0.7706 - rmse: 0.2872 - val_loss: 0.2399 - val_r_square: 0.8501 - val_rmse: 0.2399    \n",
      "\n",
      "Epoch 43/150                                                                                                           \n",
      " - 0s - loss: 0.2886 - r_square: 0.7729 - rmse: 0.2886 - val_loss: 0.2403 - val_r_square: 0.8486 - val_rmse: 0.2403    \n",
      "\n",
      "Epoch 44/150                                                                                                           \n",
      " - 0s - loss: 0.2827 - r_square: 0.7901 - rmse: 0.2827 - val_loss: 0.2491 - val_r_square: 0.8445 - val_rmse: 0.2491    \n",
      "\n",
      "Epoch 45/150                                                                                                           \n",
      " - 0s - loss: 0.2873 - r_square: 0.7853 - rmse: 0.2873 - val_loss: 0.2498 - val_r_square: 0.8438 - val_rmse: 0.2498    \n",
      "\n",
      "Epoch 46/150                                                                                                           \n",
      " - 0s - loss: 0.2826 - r_square: 0.7832 - rmse: 0.2826 - val_loss: 0.2378 - val_r_square: 0.8492 - val_rmse: 0.2378    \n",
      "\n",
      "Epoch 47/150                                                                                                           \n",
      " - 0s - loss: 0.2787 - r_square: 0.7923 - rmse: 0.2787 - val_loss: 0.2420 - val_r_square: 0.8464 - val_rmse: 0.2420    \n",
      "\n",
      "Epoch 48/150                                                                                                           \n",
      " - 0s - loss: 0.2832 - r_square: 0.7859 - rmse: 0.2832 - val_loss: 0.2433 - val_r_square: 0.8464 - val_rmse: 0.2433    \n",
      "\n",
      "Epoch 49/150                                                                                                           \n",
      " - 0s - loss: 0.2842 - r_square: 0.7859 - rmse: 0.2842 - val_loss: 0.2407 - val_r_square: 0.8502 - val_rmse: 0.2407    \n",
      "\n",
      "Epoch 50/150                                                                                                           \n",
      " - 0s - loss: 0.2741 - r_square: 0.7922 - rmse: 0.2741 - val_loss: 0.2433 - val_r_square: 0.8468 - val_rmse: 0.2433    \n",
      "\n",
      "Epoch 51/150                                                                                                           \n",
      " - 0s - loss: 0.2776 - r_square: 0.7849 - rmse: 0.2776 - val_loss: 0.2345 - val_r_square: 0.8530 - val_rmse: 0.2345    \n",
      "\n",
      "Epoch 52/150                                                                                                           \n",
      " - 0s - loss: 0.2823 - r_square: 0.7880 - rmse: 0.2823 - val_loss: 0.2357 - val_r_square: 0.8521 - val_rmse: 0.2357    \n",
      "\n",
      "Epoch 53/150                                                                                                           \n",
      " - 0s - loss: 0.2817 - r_square: 0.7755 - rmse: 0.2817 - val_loss: 0.2450 - val_r_square: 0.8490 - val_rmse: 0.2450    \n",
      "\n",
      "Epoch 54/150                                                                                                           \n",
      " - 0s - loss: 0.2767 - r_square: 0.7842 - rmse: 0.2767 - val_loss: 0.2429 - val_r_square: 0.8488 - val_rmse: 0.2429    \n",
      "\n",
      "Epoch 55/150                                                                                                           \n",
      " - 0s - loss: 0.2765 - r_square: 0.7901 - rmse: 0.2765 - val_loss: 0.2457 - val_r_square: 0.8461 - val_rmse: 0.2457    \n",
      "\n",
      "Epoch 56/150                                                                                                           \n",
      " - 0s - loss: 0.2775 - r_square: 0.7876 - rmse: 0.2775 - val_loss: 0.2302 - val_r_square: 0.8557 - val_rmse: 0.2302    \n",
      "\n",
      "Epoch 57/150                                                                                                           \n",
      " - 0s - loss: 0.2810 - r_square: 0.7866 - rmse: 0.2810 - val_loss: 0.2337 - val_r_square: 0.8510 - val_rmse: 0.2337    \n",
      "\n",
      "Epoch 58/150                                                                                                           \n",
      " - 0s - loss: 0.2749 - r_square: 0.7879 - rmse: 0.2749 - val_loss: 0.2400 - val_r_square: 0.8501 - val_rmse: 0.2400    \n",
      "\n",
      "Epoch 59/150                                                                                                           \n",
      " - 0s - loss: 0.2793 - r_square: 0.7850 - rmse: 0.2793 - val_loss: 0.2490 - val_r_square: 0.8432 - val_rmse: 0.2490    \n",
      "\n",
      "Epoch 60/150                                                                                                           \n",
      " - 0s - loss: 0.2731 - r_square: 0.7904 - rmse: 0.2731 - val_loss: 0.2474 - val_r_square: 0.8480 - val_rmse: 0.2474    \n",
      "\n",
      "Epoch 61/150                                                                                                           \n",
      " - 0s - loss: 0.2707 - r_square: 0.7919 - rmse: 0.2707 - val_loss: 0.2473 - val_r_square: 0.8460 - val_rmse: 0.2473    \n",
      "\n",
      "Epoch 62/150                                                                                                           \n",
      " - 0s - loss: 0.2735 - r_square: 0.7932 - rmse: 0.2735 - val_loss: 0.2409 - val_r_square: 0.8500 - val_rmse: 0.2409    \n",
      "\n",
      "Epoch 63/150                                                                                                           \n",
      " - 0s - loss: 0.2742 - r_square: 0.7965 - rmse: 0.2742 - val_loss: 0.2335 - val_r_square: 0.8552 - val_rmse: 0.2335    \n",
      "\n",
      "Epoch 64/150                                                                                                           \n",
      " - 0s - loss: 0.2757 - r_square: 0.7933 - rmse: 0.2757 - val_loss: 0.2303 - val_r_square: 0.8557 - val_rmse: 0.2303    \n",
      "\n",
      "Epoch 65/150                                                                                                           \n",
      " - 0s - loss: 0.2782 - r_square: 0.7932 - rmse: 0.2782 - val_loss: 0.2405 - val_r_square: 0.8513 - val_rmse: 0.2405    \n",
      "\n",
      "Epoch 66/150                                                                                                           \n",
      " - 0s - loss: 0.2767 - r_square: 0.7923 - rmse: 0.2767 - val_loss: 0.2347 - val_r_square: 0.8524 - val_rmse: 0.2347    \n",
      "\n",
      "Epoch 67/150                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2734 - r_square: 0.7882 - rmse: 0.2734 - val_loss: 0.2341 - val_r_square: 0.8546 - val_rmse: 0.2341    \n",
      "\n",
      "Epoch 68/150                                                                                                           \n",
      " - 0s - loss: 0.2755 - r_square: 0.7938 - rmse: 0.2755 - val_loss: 0.2393 - val_r_square: 0.8533 - val_rmse: 0.2393    \n",
      "\n",
      "Epoch 69/150                                                                                                           \n",
      " - 0s - loss: 0.2719 - r_square: 0.7959 - rmse: 0.2719 - val_loss: 0.2394 - val_r_square: 0.8521 - val_rmse: 0.2394    \n",
      "\n",
      "Epoch 70/150                                                                                                           \n",
      " - 0s - loss: 0.2694 - r_square: 0.8005 - rmse: 0.2694 - val_loss: 0.2348 - val_r_square: 0.8522 - val_rmse: 0.2348    \n",
      "\n",
      "Epoch 71/150                                                                                                           \n",
      " - 0s - loss: 0.2690 - r_square: 0.7969 - rmse: 0.2690 - val_loss: 0.2239 - val_r_square: 0.8600 - val_rmse: 0.2239    \n",
      "\n",
      "Epoch 72/150                                                                                                           \n",
      " - 0s - loss: 0.2713 - r_square: 0.7929 - rmse: 0.2713 - val_loss: 0.2318 - val_r_square: 0.8559 - val_rmse: 0.2318    \n",
      "\n",
      "Epoch 73/150                                                                                                           \n",
      " - 0s - loss: 0.2689 - r_square: 0.8094 - rmse: 0.2689 - val_loss: 0.2300 - val_r_square: 0.8555 - val_rmse: 0.2300    \n",
      "\n",
      "Epoch 74/150                                                                                                           \n",
      " - 0s - loss: 0.2716 - r_square: 0.7880 - rmse: 0.2716 - val_loss: 0.2274 - val_r_square: 0.8562 - val_rmse: 0.2274    \n",
      "\n",
      "Epoch 75/150                                                                                                           \n",
      " - 0s - loss: 0.2712 - r_square: 0.7941 - rmse: 0.2712 - val_loss: 0.2296 - val_r_square: 0.8558 - val_rmse: 0.2296    \n",
      "\n",
      "Epoch 76/150                                                                                                           \n",
      " - 0s - loss: 0.2695 - r_square: 0.7982 - rmse: 0.2695 - val_loss: 0.2316 - val_r_square: 0.8522 - val_rmse: 0.2316    \n",
      "\n",
      "Epoch 77/150                                                                                                           \n",
      " - 0s - loss: 0.2692 - r_square: 0.7957 - rmse: 0.2692 - val_loss: 0.2297 - val_r_square: 0.8565 - val_rmse: 0.2297    \n",
      "\n",
      "Epoch 78/150                                                                                                           \n",
      " - 0s - loss: 0.2637 - r_square: 0.8000 - rmse: 0.2637 - val_loss: 0.2281 - val_r_square: 0.8580 - val_rmse: 0.2281    \n",
      "\n",
      "Epoch 79/150                                                                                                           \n",
      " - 0s - loss: 0.2674 - r_square: 0.8064 - rmse: 0.2674 - val_loss: 0.2353 - val_r_square: 0.8528 - val_rmse: 0.2353    \n",
      "\n",
      "Epoch 80/150                                                                                                           \n",
      " - 0s - loss: 0.2716 - r_square: 0.8003 - rmse: 0.2716 - val_loss: 0.2295 - val_r_square: 0.8555 - val_rmse: 0.2295    \n",
      "\n",
      "Epoch 81/150                                                                                                           \n",
      " - 0s - loss: 0.2652 - r_square: 0.8014 - rmse: 0.2652 - val_loss: 0.2252 - val_r_square: 0.8617 - val_rmse: 0.2252    \n",
      "\n",
      "Epoch 82/150                                                                                                           \n",
      " - 0s - loss: 0.2639 - r_square: 0.8006 - rmse: 0.2639 - val_loss: 0.2390 - val_r_square: 0.8520 - val_rmse: 0.2390    \n",
      "\n",
      "Epoch 83/150                                                                                                           \n",
      " - 0s - loss: 0.2668 - r_square: 0.7981 - rmse: 0.2668 - val_loss: 0.2308 - val_r_square: 0.8590 - val_rmse: 0.2308    \n",
      "\n",
      "Epoch 84/150                                                                                                           \n",
      " - 0s - loss: 0.2637 - r_square: 0.8041 - rmse: 0.2637 - val_loss: 0.2238 - val_r_square: 0.8606 - val_rmse: 0.2238    \n",
      "\n",
      "Epoch 85/150                                                                                                           \n",
      " - 0s - loss: 0.2688 - r_square: 0.8017 - rmse: 0.2688 - val_loss: 0.2328 - val_r_square: 0.8578 - val_rmse: 0.2328    \n",
      "\n",
      "Epoch 86/150                                                                                                           \n",
      " - 0s - loss: 0.2639 - r_square: 0.8001 - rmse: 0.2639 - val_loss: 0.2349 - val_r_square: 0.8516 - val_rmse: 0.2349    \n",
      "\n",
      "Epoch 87/150                                                                                                           \n",
      " - 0s - loss: 0.2694 - r_square: 0.8001 - rmse: 0.2694 - val_loss: 0.2302 - val_r_square: 0.8544 - val_rmse: 0.2302    \n",
      "\n",
      "Epoch 88/150                                                                                                           \n",
      " - 0s - loss: 0.2684 - r_square: 0.7956 - rmse: 0.2684 - val_loss: 0.2285 - val_r_square: 0.8577 - val_rmse: 0.2285    \n",
      "\n",
      "Epoch 89/150                                                                                                           \n",
      " - 0s - loss: 0.2662 - r_square: 0.7985 - rmse: 0.2662 - val_loss: 0.2324 - val_r_square: 0.8600 - val_rmse: 0.2324    \n",
      "\n",
      "Epoch 90/150                                                                                                           \n",
      " - 0s - loss: 0.2654 - r_square: 0.7996 - rmse: 0.2654 - val_loss: 0.2234 - val_r_square: 0.8619 - val_rmse: 0.2234    \n",
      "\n",
      "Epoch 91/150                                                                                                           \n",
      " - 0s - loss: 0.2687 - r_square: 0.7936 - rmse: 0.2687 - val_loss: 0.2300 - val_r_square: 0.8554 - val_rmse: 0.2300    \n",
      "\n",
      "Epoch 92/150                                                                                                           \n",
      " - 0s - loss: 0.2698 - r_square: 0.8005 - rmse: 0.2698 - val_loss: 0.2335 - val_r_square: 0.8538 - val_rmse: 0.2335    \n",
      "\n",
      "Epoch 93/150                                                                                                           \n",
      " - 0s - loss: 0.2678 - r_square: 0.8051 - rmse: 0.2678 - val_loss: 0.2225 - val_r_square: 0.8636 - val_rmse: 0.2225    \n",
      "\n",
      "Epoch 94/150                                                                                                           \n",
      " - 0s - loss: 0.2633 - r_square: 0.8107 - rmse: 0.2633 - val_loss: 0.2360 - val_r_square: 0.8543 - val_rmse: 0.2360    \n",
      "\n",
      "Epoch 95/150                                                                                                           \n",
      " - 0s - loss: 0.2663 - r_square: 0.8020 - rmse: 0.2663 - val_loss: 0.2252 - val_r_square: 0.8601 - val_rmse: 0.2252    \n",
      "\n",
      "Epoch 96/150                                                                                                           \n",
      " - 0s - loss: 0.2666 - r_square: 0.8068 - rmse: 0.2666 - val_loss: 0.2183 - val_r_square: 0.8671 - val_rmse: 0.2183    \n",
      "\n",
      "Epoch 97/150                                                                                                           \n",
      " - 0s - loss: 0.2630 - r_square: 0.8033 - rmse: 0.2630 - val_loss: 0.2331 - val_r_square: 0.8551 - val_rmse: 0.2331    \n",
      "\n",
      "Epoch 98/150                                                                                                           \n",
      " - 0s - loss: 0.2638 - r_square: 0.8089 - rmse: 0.2638 - val_loss: 0.2296 - val_r_square: 0.8617 - val_rmse: 0.2296    \n",
      "\n",
      "Epoch 99/150                                                                                                           \n",
      " - 0s - loss: 0.2628 - r_square: 0.7990 - rmse: 0.2628 - val_loss: 0.2184 - val_r_square: 0.8676 - val_rmse: 0.2184    \n",
      "\n",
      "Epoch 100/150                                                                                                          \n",
      " - 0s - loss: 0.2608 - r_square: 0.8087 - rmse: 0.2608 - val_loss: 0.2228 - val_r_square: 0.8652 - val_rmse: 0.2228    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150                                                                                                          \n",
      " - 0s - loss: 0.2597 - r_square: 0.8019 - rmse: 0.2597 - val_loss: 0.2267 - val_r_square: 0.8604 - val_rmse: 0.2267    \n",
      "\n",
      "Epoch 102/150                                                                                                          \n",
      " - 0s - loss: 0.2587 - r_square: 0.8156 - rmse: 0.2587 - val_loss: 0.2189 - val_r_square: 0.8655 - val_rmse: 0.2189    \n",
      "\n",
      "Epoch 103/150                                                                                                          \n",
      " - 0s - loss: 0.2658 - r_square: 0.8099 - rmse: 0.2658 - val_loss: 0.2217 - val_r_square: 0.8644 - val_rmse: 0.2217    \n",
      "\n",
      "Epoch 104/150                                                                                                          \n",
      " - 0s - loss: 0.2637 - r_square: 0.8015 - rmse: 0.2637 - val_loss: 0.2224 - val_r_square: 0.8630 - val_rmse: 0.2224    \n",
      "\n",
      "Epoch 105/150                                                                                                          \n",
      " - 0s - loss: 0.2669 - r_square: 0.8025 - rmse: 0.2669 - val_loss: 0.2318 - val_r_square: 0.8584 - val_rmse: 0.2318    \n",
      "\n",
      "Epoch 106/150                                                                                                          \n",
      " - 0s - loss: 0.2669 - r_square: 0.7966 - rmse: 0.2669 - val_loss: 0.2269 - val_r_square: 0.8612 - val_rmse: 0.2269    \n",
      "\n",
      "Epoch 107/150                                                                                                          \n",
      " - 0s - loss: 0.2596 - r_square: 0.8056 - rmse: 0.2596 - val_loss: 0.2152 - val_r_square: 0.8674 - val_rmse: 0.2152    \n",
      "\n",
      "Epoch 108/150                                                                                                          \n",
      " - 0s - loss: 0.2637 - r_square: 0.8036 - rmse: 0.2637 - val_loss: 0.2232 - val_r_square: 0.8640 - val_rmse: 0.2232    \n",
      "\n",
      "Epoch 109/150                                                                                                          \n",
      " - 0s - loss: 0.2598 - r_square: 0.8121 - rmse: 0.2598 - val_loss: 0.2242 - val_r_square: 0.8603 - val_rmse: 0.2242    \n",
      "\n",
      "Epoch 110/150                                                                                                          \n",
      " - 0s - loss: 0.2606 - r_square: 0.8049 - rmse: 0.2606 - val_loss: 0.2234 - val_r_square: 0.8634 - val_rmse: 0.2234    \n",
      "\n",
      "Epoch 111/150                                                                                                          \n",
      " - 0s - loss: 0.2590 - r_square: 0.8059 - rmse: 0.2590 - val_loss: 0.2237 - val_r_square: 0.8614 - val_rmse: 0.2237    \n",
      "\n",
      "Epoch 112/150                                                                                                          \n",
      " - 0s - loss: 0.2629 - r_square: 0.8127 - rmse: 0.2629 - val_loss: 0.2236 - val_r_square: 0.8644 - val_rmse: 0.2236    \n",
      "\n",
      "Epoch 113/150                                                                                                          \n",
      " - 0s - loss: 0.2650 - r_square: 0.7968 - rmse: 0.2650 - val_loss: 0.2312 - val_r_square: 0.8568 - val_rmse: 0.2312    \n",
      "\n",
      "Epoch 114/150                                                                                                          \n",
      " - 0s - loss: 0.2662 - r_square: 0.8077 - rmse: 0.2662 - val_loss: 0.2318 - val_r_square: 0.8605 - val_rmse: 0.2318    \n",
      "\n",
      "Epoch 115/150                                                                                                          \n",
      " - 0s - loss: 0.2681 - r_square: 0.7958 - rmse: 0.2681 - val_loss: 0.2287 - val_r_square: 0.8555 - val_rmse: 0.2287    \n",
      "\n",
      "Epoch 116/150                                                                                                          \n",
      " - 0s - loss: 0.2597 - r_square: 0.8061 - rmse: 0.2597 - val_loss: 0.2147 - val_r_square: 0.8695 - val_rmse: 0.2147    \n",
      "\n",
      "Epoch 117/150                                                                                                          \n",
      " - 0s - loss: 0.2581 - r_square: 0.8134 - rmse: 0.2581 - val_loss: 0.2324 - val_r_square: 0.8568 - val_rmse: 0.2324    \n",
      "\n",
      "Epoch 118/150                                                                                                          \n",
      " - 0s - loss: 0.2556 - r_square: 0.8073 - rmse: 0.2556 - val_loss: 0.2260 - val_r_square: 0.8608 - val_rmse: 0.2260    \n",
      "\n",
      "Epoch 119/150                                                                                                          \n",
      " - 0s - loss: 0.2587 - r_square: 0.8142 - rmse: 0.2587 - val_loss: 0.2333 - val_r_square: 0.8583 - val_rmse: 0.2333    \n",
      "\n",
      "Epoch 120/150                                                                                                          \n",
      " - 0s - loss: 0.2547 - r_square: 0.8135 - rmse: 0.2547 - val_loss: 0.2220 - val_r_square: 0.8655 - val_rmse: 0.2220    \n",
      "\n",
      "Epoch 121/150                                                                                                          \n",
      " - 0s - loss: 0.2576 - r_square: 0.8063 - rmse: 0.2576 - val_loss: 0.2231 - val_r_square: 0.8628 - val_rmse: 0.2231    \n",
      "\n",
      "Epoch 122/150                                                                                                          \n",
      " - 0s - loss: 0.2591 - r_square: 0.8135 - rmse: 0.2591 - val_loss: 0.2223 - val_r_square: 0.8630 - val_rmse: 0.2223    \n",
      "\n",
      "Epoch 123/150                                                                                                          \n",
      " - 0s - loss: 0.2563 - r_square: 0.8091 - rmse: 0.2563 - val_loss: 0.2200 - val_r_square: 0.8648 - val_rmse: 0.2200    \n",
      "\n",
      "Epoch 124/150                                                                                                          \n",
      " - 0s - loss: 0.2583 - r_square: 0.8092 - rmse: 0.2583 - val_loss: 0.2269 - val_r_square: 0.8620 - val_rmse: 0.2269    \n",
      "\n",
      "Epoch 125/150                                                                                                          \n",
      " - 0s - loss: 0.2502 - r_square: 0.8116 - rmse: 0.2502 - val_loss: 0.2204 - val_r_square: 0.8648 - val_rmse: 0.2204    \n",
      "\n",
      "Epoch 126/150                                                                                                          \n",
      " - 0s - loss: 0.2548 - r_square: 0.8172 - rmse: 0.2548 - val_loss: 0.2400 - val_r_square: 0.8535 - val_rmse: 0.2400    \n",
      "\n",
      "Epoch 127/150                                                                                                          \n",
      " - 0s - loss: 0.2624 - r_square: 0.8048 - rmse: 0.2624 - val_loss: 0.2208 - val_r_square: 0.8644 - val_rmse: 0.2208    \n",
      "\n",
      "Epoch 128/150                                                                                                          \n",
      " - 0s - loss: 0.2608 - r_square: 0.8118 - rmse: 0.2608 - val_loss: 0.2186 - val_r_square: 0.8638 - val_rmse: 0.2186    \n",
      "\n",
      "Epoch 129/150                                                                                                          \n",
      " - 0s - loss: 0.2579 - r_square: 0.8084 - rmse: 0.2579 - val_loss: 0.2238 - val_r_square: 0.8615 - val_rmse: 0.2238    \n",
      "\n",
      "Epoch 130/150                                                                                                          \n",
      " - 0s - loss: 0.2619 - r_square: 0.8007 - rmse: 0.2619 - val_loss: 0.2241 - val_r_square: 0.8608 - val_rmse: 0.2241    \n",
      "\n",
      "Epoch 131/150                                                                                                          \n",
      " - 0s - loss: 0.2547 - r_square: 0.8121 - rmse: 0.2547 - val_loss: 0.2249 - val_r_square: 0.8623 - val_rmse: 0.2249    \n",
      "\n",
      "Epoch 132/150                                                                                                          \n",
      " - 0s - loss: 0.2600 - r_square: 0.8001 - rmse: 0.2600 - val_loss: 0.2209 - val_r_square: 0.8649 - val_rmse: 0.2209    \n",
      "\n",
      "Epoch 133/150                                                                                                          \n",
      " - 0s - loss: 0.2572 - r_square: 0.8091 - rmse: 0.2572 - val_loss: 0.2222 - val_r_square: 0.8649 - val_rmse: 0.2222    \n",
      "\n",
      "Epoch 134/150                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2575 - r_square: 0.8194 - rmse: 0.2575 - val_loss: 0.2304 - val_r_square: 0.8594 - val_rmse: 0.2304    \n",
      "\n",
      "Epoch 135/150                                                                                                          \n",
      " - 0s - loss: 0.2536 - r_square: 0.8089 - rmse: 0.2536 - val_loss: 0.2254 - val_r_square: 0.8636 - val_rmse: 0.2254    \n",
      "\n",
      "Epoch 136/150                                                                                                          \n",
      " - 0s - loss: 0.2554 - r_square: 0.8123 - rmse: 0.2554 - val_loss: 0.2284 - val_r_square: 0.8621 - val_rmse: 0.2284    \n",
      "\n",
      "Epoch 137/150                                                                                                          \n",
      " - 0s - loss: 0.2562 - r_square: 0.8078 - rmse: 0.2562 - val_loss: 0.2219 - val_r_square: 0.8637 - val_rmse: 0.2219    \n",
      "\n",
      "Epoch 138/150                                                                                                          \n",
      " - 0s - loss: 0.2549 - r_square: 0.8117 - rmse: 0.2549 - val_loss: 0.2359 - val_r_square: 0.8544 - val_rmse: 0.2359    \n",
      "\n",
      "Epoch 139/150                                                                                                          \n",
      " - 0s - loss: 0.2565 - r_square: 0.8096 - rmse: 0.2565 - val_loss: 0.2200 - val_r_square: 0.8617 - val_rmse: 0.2200    \n",
      "\n",
      "Epoch 140/150                                                                                                          \n",
      " - 0s - loss: 0.2507 - r_square: 0.8239 - rmse: 0.2507 - val_loss: 0.2306 - val_r_square: 0.8610 - val_rmse: 0.2306    \n",
      "\n",
      "Epoch 141/150                                                                                                          \n",
      " - 0s - loss: 0.2582 - r_square: 0.8097 - rmse: 0.2582 - val_loss: 0.2269 - val_r_square: 0.8624 - val_rmse: 0.2269    \n",
      "\n",
      "Epoch 142/150                                                                                                          \n",
      " - 0s - loss: 0.2554 - r_square: 0.8108 - rmse: 0.2554 - val_loss: 0.2400 - val_r_square: 0.8515 - val_rmse: 0.2400    \n",
      "\n",
      "Epoch 143/150                                                                                                          \n",
      " - 0s - loss: 0.2583 - r_square: 0.8124 - rmse: 0.2583 - val_loss: 0.2290 - val_r_square: 0.8603 - val_rmse: 0.2290    \n",
      "\n",
      "Epoch 144/150                                                                                                          \n",
      " - 0s - loss: 0.2574 - r_square: 0.8148 - rmse: 0.2574 - val_loss: 0.2248 - val_r_square: 0.8617 - val_rmse: 0.2248    \n",
      "\n",
      "Epoch 145/150                                                                                                          \n",
      " - 0s - loss: 0.2549 - r_square: 0.8102 - rmse: 0.2549 - val_loss: 0.2273 - val_r_square: 0.8627 - val_rmse: 0.2273    \n",
      "\n",
      "Epoch 146/150                                                                                                          \n",
      " - 0s - loss: 0.2632 - r_square: 0.8002 - rmse: 0.2632 - val_loss: 0.2227 - val_r_square: 0.8646 - val_rmse: 0.2227    \n",
      "\n",
      "Epoch 147/150                                                                                                          \n",
      " - 0s - loss: 0.2493 - r_square: 0.8174 - rmse: 0.2493 - val_loss: 0.2312 - val_r_square: 0.8553 - val_rmse: 0.2312    \n",
      "\n",
      "Epoch 148/150                                                                                                          \n",
      " - 0s - loss: 0.2500 - r_square: 0.8125 - rmse: 0.2500 - val_loss: 0.2237 - val_r_square: 0.8634 - val_rmse: 0.2237    \n",
      "\n",
      "Epoch 149/150                                                                                                          \n",
      " - 0s - loss: 0.2566 - r_square: 0.8138 - rmse: 0.2566 - val_loss: 0.2306 - val_r_square: 0.8608 - val_rmse: 0.2306    \n",
      "\n",
      "Epoch 150/150                                                                                                          \n",
      " - 0s - loss: 0.2532 - r_square: 0.8194 - rmse: 0.2532 - val_loss: 0.2196 - val_r_square: 0.8656 - val_rmse: 0.2196    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.21473375762435531                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 1/5 [00:24<01:39, 24.87s/trial, best loss: -0.21473375762435531]WARNING:tensorflow:Large dropout rate: 0.836667 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.912829 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_2\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_4 (Dense)              (None, 500)               3500                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_3 (Dropout)          (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_5 (Dense)              (None, 500)               250500                                                          \n",
      "_________________________________________________________________                                                      \n",
      "dropout_4 (Dropout)          (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_6 (Dense)              (None, 1)                 501                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 254,501                                                                                                  \n",
      "Trainable params: 254,501                                                                                              \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 1s - loss: 0.8038 - r_square: -1.7525e-01 - rmse: 0.8038 - val_loss: 0.5189 - val_r_square: 0.5372 - val_rmse: 0.5189\n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.6272 - r_square: 0.2836 - rmse: 0.6272 - val_loss: 0.4910 - val_r_square: 0.5834 - val_rmse: 0.4910    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.5454 - r_square: 0.4384 - rmse: 0.5454 - val_loss: 0.4545 - val_r_square: 0.6368 - val_rmse: 0.4545    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.5059 - r_square: 0.4989 - rmse: 0.5059 - val_loss: 0.4346 - val_r_square: 0.6635 - val_rmse: 0.4346    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4780 - r_square: 0.5518 - rmse: 0.4780 - val_loss: 0.4130 - val_r_square: 0.6876 - val_rmse: 0.4130    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.4630 - r_square: 0.5671 - rmse: 0.4630 - val_loss: 0.3960 - val_r_square: 0.7018 - val_rmse: 0.3960    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.4520 - r_square: 0.5745 - rmse: 0.4520 - val_loss: 0.3972 - val_r_square: 0.7036 - val_rmse: 0.3972    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.4370 - r_square: 0.6059 - rmse: 0.4370 - val_loss: 0.3784 - val_r_square: 0.7159 - val_rmse: 0.3784    \n",
      "\n",
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.4253 - r_square: 0.6058 - rmse: 0.4253 - val_loss: 0.3597 - val_r_square: 0.7392 - val_rmse: 0.3597    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.4224 - r_square: 0.6238 - rmse: 0.4224 - val_loss: 0.3569 - val_r_square: 0.7404 - val_rmse: 0.3569    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.4134 - r_square: 0.6373 - rmse: 0.4134 - val_loss: 0.3490 - val_r_square: 0.7503 - val_rmse: 0.3490    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.4019 - r_square: 0.6577 - rmse: 0.4019 - val_loss: 0.3384 - val_r_square: 0.7620 - val_rmse: 0.3384    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.3982 - r_square: 0.6560 - rmse: 0.3982 - val_loss: 0.3261 - val_r_square: 0.7690 - val_rmse: 0.3261    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.3995 - r_square: 0.6517 - rmse: 0.3995 - val_loss: 0.3369 - val_r_square: 0.7578 - val_rmse: 0.3369    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.3893 - r_square: 0.6604 - rmse: 0.3893 - val_loss: 0.3009 - val_r_square: 0.7888 - val_rmse: 0.3009    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.3923 - r_square: 0.6533 - rmse: 0.3923 - val_loss: 0.3032 - val_r_square: 0.7872 - val_rmse: 0.3032    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.3813 - r_square: 0.6797 - rmse: 0.3813 - val_loss: 0.2930 - val_r_square: 0.7945 - val_rmse: 0.2930    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.3787 - r_square: 0.6839 - rmse: 0.3787 - val_loss: 0.2891 - val_r_square: 0.7946 - val_rmse: 0.2891    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.3734 - r_square: 0.6744 - rmse: 0.3734 - val_loss: 0.2823 - val_r_square: 0.8024 - val_rmse: 0.2823    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.3692 - r_square: 0.6802 - rmse: 0.3692 - val_loss: 0.2896 - val_r_square: 0.8009 - val_rmse: 0.2896    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.3659 - r_square: 0.6903 - rmse: 0.3659 - val_loss: 0.3012 - val_r_square: 0.7906 - val_rmse: 0.3012    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.3664 - r_square: 0.6926 - rmse: 0.3664 - val_loss: 0.2880 - val_r_square: 0.8016 - val_rmse: 0.2880    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.3617 - r_square: 0.7035 - rmse: 0.3617 - val_loss: 0.2708 - val_r_square: 0.8135 - val_rmse: 0.2708    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.3540 - r_square: 0.7145 - rmse: 0.3540 - val_loss: 0.2643 - val_r_square: 0.8165 - val_rmse: 0.2643    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.3612 - r_square: 0.7001 - rmse: 0.3612 - val_loss: 0.2754 - val_r_square: 0.8133 - val_rmse: 0.2754    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.3534 - r_square: 0.7050 - rmse: 0.3534 - val_loss: 0.2758 - val_r_square: 0.8131 - val_rmse: 0.2758    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.3501 - r_square: 0.7056 - rmse: 0.3501 - val_loss: 0.2726 - val_r_square: 0.8136 - val_rmse: 0.2726    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.3588 - r_square: 0.6940 - rmse: 0.3588 - val_loss: 0.2531 - val_r_square: 0.8272 - val_rmse: 0.2531    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n",
      " - 0s - loss: 0.3532 - r_square: 0.7184 - rmse: 0.3532 - val_loss: 0.2762 - val_r_square: 0.8147 - val_rmse: 0.2762    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.3516 - r_square: 0.7197 - rmse: 0.3516 - val_loss: 0.2703 - val_r_square: 0.8198 - val_rmse: 0.2703    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.3506 - r_square: 0.7094 - rmse: 0.3506 - val_loss: 0.2626 - val_r_square: 0.8228 - val_rmse: 0.2626    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.3404 - r_square: 0.7309 - rmse: 0.3404 - val_loss: 0.2586 - val_r_square: 0.8262 - val_rmse: 0.2586    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.3468 - r_square: 0.7169 - rmse: 0.3468 - val_loss: 0.2545 - val_r_square: 0.8288 - val_rmse: 0.2545    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.3392 - r_square: 0.7247 - rmse: 0.3392 - val_loss: 0.2447 - val_r_square: 0.8314 - val_rmse: 0.2447    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.3440 - r_square: 0.7251 - rmse: 0.3440 - val_loss: 0.2460 - val_r_square: 0.8322 - val_rmse: 0.2460    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.3480 - r_square: 0.7226 - rmse: 0.3480 - val_loss: 0.2577 - val_r_square: 0.8273 - val_rmse: 0.2577    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.3321 - r_square: 0.7370 - rmse: 0.3321 - val_loss: 0.2524 - val_r_square: 0.8307 - val_rmse: 0.2524    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.3342 - r_square: 0.7410 - rmse: 0.3342 - val_loss: 0.2799 - val_r_square: 0.8184 - val_rmse: 0.2799    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.3300 - r_square: 0.7482 - rmse: 0.3300 - val_loss: 0.2484 - val_r_square: 0.8331 - val_rmse: 0.2484    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.3295 - r_square: 0.7370 - rmse: 0.3295 - val_loss: 0.2460 - val_r_square: 0.8370 - val_rmse: 0.2460    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.3358 - r_square: 0.7306 - rmse: 0.3358 - val_loss: 0.2514 - val_r_square: 0.8332 - val_rmse: 0.2514    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n",
      " - 0s - loss: 0.3353 - r_square: 0.7350 - rmse: 0.3353 - val_loss: 0.2507 - val_r_square: 0.8328 - val_rmse: 0.2507    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.3348 - r_square: 0.7389 - rmse: 0.3348 - val_loss: 0.2468 - val_r_square: 0.8373 - val_rmse: 0.2468    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.3335 - r_square: 0.7381 - rmse: 0.3335 - val_loss: 0.2484 - val_r_square: 0.8376 - val_rmse: 0.2484    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.3382 - r_square: 0.7221 - rmse: 0.3382 - val_loss: 0.2511 - val_r_square: 0.8335 - val_rmse: 0.2511    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.3308 - r_square: 0.7387 - rmse: 0.3308 - val_loss: 0.2537 - val_r_square: 0.8355 - val_rmse: 0.2537    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.3292 - r_square: 0.7291 - rmse: 0.3292 - val_loss: 0.2574 - val_r_square: 0.8337 - val_rmse: 0.2574    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.3324 - r_square: 0.7413 - rmse: 0.3324 - val_loss: 0.2495 - val_r_square: 0.8406 - val_rmse: 0.2495    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.3273 - r_square: 0.7430 - rmse: 0.3273 - val_loss: 0.2279 - val_r_square: 0.8453 - val_rmse: 0.2279    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.3343 - r_square: 0.7471 - rmse: 0.3343 - val_loss: 0.2402 - val_r_square: 0.8452 - val_rmse: 0.2402    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.22787381363378334                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 2/5 [00:49<01:14, 24.87s/trial, best loss: -0.22787381363378334]WARNING:tensorflow:Large dropout rate: 0.975819 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_3\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_7 (Dense)              (None, 50)                350                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_5 (Dropout)          (None, 50)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_8 (Dense)              (None, 500)               25500                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_6 (Dropout)          (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_9 (Dense)              (None, 1)                 501                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 26,351                                                                                                   \n",
      "Trainable params: 26,351                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 1s - loss: 0.9009 - r_square: -4.3286e-01 - rmse: 0.9009 - val_loss: 0.7503 - val_r_square: 0.0900 - val_rmse: 0.7503\n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.8325 - r_square: -1.7974e-01 - rmse: 0.8325 - val_loss: 0.7430 - val_r_square: 0.0969 - val_rmse: 0.7430\n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.8157 - r_square: -1.4362e-01 - rmse: 0.8157 - val_loss: 0.7551 - val_r_square: 0.0685 - val_rmse: 0.7551\n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.7875 - r_square: -5.1008e-02 - rmse: 0.7875 - val_loss: 0.7390 - val_r_square: 0.1214 - val_rmse: 0.7390\n",
      "\n",
      "Epoch 5/100                                                                                                            \n",
      " - 0s - loss: 0.7627 - r_square: 6.2121e-05 - rmse: 0.7627 - val_loss: 0.7327 - val_r_square: 0.1330 - val_rmse: 0.7327\n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.7526 - r_square: 0.0392 - rmse: 0.7526 - val_loss: 0.7358 - val_r_square: 0.1351 - val_rmse: 0.7358    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.7504 - r_square: 0.0343 - rmse: 0.7504 - val_loss: 0.7345 - val_r_square: 0.1404 - val_rmse: 0.7345    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.7363 - r_square: 0.0917 - rmse: 0.7363 - val_loss: 0.7253 - val_r_square: 0.1602 - val_rmse: 0.7253    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.7352 - r_square: 0.0773 - rmse: 0.7352 - val_loss: 0.7408 - val_r_square: 0.1207 - val_rmse: 0.7408    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.7340 - r_square: 0.0651 - rmse: 0.7340 - val_loss: 0.7372 - val_r_square: 0.1307 - val_rmse: 0.7372    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.7214 - r_square: 0.0976 - rmse: 0.7214 - val_loss: 0.7380 - val_r_square: 0.1258 - val_rmse: 0.7380    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.7125 - r_square: 0.1279 - rmse: 0.7125 - val_loss: 0.7372 - val_r_square: 0.1298 - val_rmse: 0.7372    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.6994 - r_square: 0.1486 - rmse: 0.6994 - val_loss: 0.7423 - val_r_square: 0.1132 - val_rmse: 0.7423    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.7023 - r_square: 0.1327 - rmse: 0.7023 - val_loss: 0.7349 - val_r_square: 0.1321 - val_rmse: 0.7349    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n",
      " - 0s - loss: 0.6992 - r_square: 0.1603 - rmse: 0.6992 - val_loss: 0.7478 - val_r_square: 0.0931 - val_rmse: 0.7478    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.7018 - r_square: 0.1438 - rmse: 0.7018 - val_loss: 0.7507 - val_r_square: 0.0861 - val_rmse: 0.7507    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.7000 - r_square: 0.1420 - rmse: 0.7000 - val_loss: 0.7493 - val_r_square: 0.0905 - val_rmse: 0.7493    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.6957 - r_square: 0.1572 - rmse: 0.6957 - val_loss: 0.7482 - val_r_square: 0.0934 - val_rmse: 0.7482    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.6924 - r_square: 0.1569 - rmse: 0.6924 - val_loss: 0.7513 - val_r_square: 0.0858 - val_rmse: 0.7513    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.6875 - r_square: 0.1545 - rmse: 0.6875 - val_loss: 0.7484 - val_r_square: 0.0928 - val_rmse: 0.7484    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.6757 - r_square: 0.1827 - rmse: 0.6757 - val_loss: 0.7557 - val_r_square: 0.0724 - val_rmse: 0.7557    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.6753 - r_square: 0.1970 - rmse: 0.6753 - val_loss: 0.7553 - val_r_square: 0.0745 - val_rmse: 0.7553    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.6566 - r_square: 0.2204 - rmse: 0.6566 - val_loss: 0.7496 - val_r_square: 0.0873 - val_rmse: 0.7496    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.6768 - r_square: 0.1956 - rmse: 0.6768 - val_loss: 0.7564 - val_r_square: 0.0706 - val_rmse: 0.7564    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.6767 - r_square: 0.1798 - rmse: 0.6767 - val_loss: 0.7536 - val_r_square: 0.0791 - val_rmse: 0.7536    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.6671 - r_square: 0.2053 - rmse: 0.6671 - val_loss: 0.7528 - val_r_square: 0.0811 - val_rmse: 0.7528    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.6710 - r_square: 0.1836 - rmse: 0.6710 - val_loss: 0.7564 - val_r_square: 0.0706 - val_rmse: 0.7564    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.6672 - r_square: 0.1953 - rmse: 0.6672 - val_loss: 0.7499 - val_r_square: 0.0856 - val_rmse: 0.7499    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.6749 - r_square: 0.1884 - rmse: 0.6749 - val_loss: 0.7523 - val_r_square: 0.0800 - val_rmse: 0.7523    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.6696 - r_square: 0.1925 - rmse: 0.6696 - val_loss: 0.7584 - val_r_square: 0.0661 - val_rmse: 0.7584    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.6638 - r_square: 0.2072 - rmse: 0.6638 - val_loss: 0.7609 - val_r_square: 0.0585 - val_rmse: 0.7609    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.6627 - r_square: 0.1948 - rmse: 0.6627 - val_loss: 0.7595 - val_r_square: 0.0640 - val_rmse: 0.7595    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.6661 - r_square: 0.2022 - rmse: 0.6661 - val_loss: 0.7676 - val_r_square: 0.0426 - val_rmse: 0.7676    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.6625 - r_square: 0.2137 - rmse: 0.6625 - val_loss: 0.7659 - val_r_square: 0.0445 - val_rmse: 0.7659    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.6623 - r_square: 0.1959 - rmse: 0.6623 - val_loss: 0.7682 - val_r_square: 0.0417 - val_rmse: 0.7682    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.6630 - r_square: 0.2107 - rmse: 0.6630 - val_loss: 0.7659 - val_r_square: 0.0467 - val_rmse: 0.7659    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.6526 - r_square: 0.2188 - rmse: 0.6526 - val_loss: 0.7626 - val_r_square: 0.0561 - val_rmse: 0.7626    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.6652 - r_square: 0.1919 - rmse: 0.6652 - val_loss: 0.7671 - val_r_square: 0.0489 - val_rmse: 0.7671    \n",
      "\n",
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.6541 - r_square: 0.2105 - rmse: 0.6541 - val_loss: 0.7657 - val_r_square: 0.0519 - val_rmse: 0.7657    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.6565 - r_square: 0.2130 - rmse: 0.6565 - val_loss: 0.7662 - val_r_square: 0.0506 - val_rmse: 0.7662    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.6476 - r_square: 0.2207 - rmse: 0.6476 - val_loss: 0.7673 - val_r_square: 0.0474 - val_rmse: 0.7673    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.6534 - r_square: 0.2098 - rmse: 0.6534 - val_loss: 0.7680 - val_r_square: 0.0431 - val_rmse: 0.7680    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.6549 - r_square: 0.2076 - rmse: 0.6549 - val_loss: 0.7664 - val_r_square: 0.0478 - val_rmse: 0.7664    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.6523 - r_square: 0.2214 - rmse: 0.6523 - val_loss: 0.7690 - val_r_square: 0.0409 - val_rmse: 0.7690    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.6522 - r_square: 0.2195 - rmse: 0.6522 - val_loss: 0.7706 - val_r_square: 0.0376 - val_rmse: 0.7706    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.6568 - r_square: 0.2008 - rmse: 0.6568 - val_loss: 0.7721 - val_r_square: 0.0344 - val_rmse: 0.7721    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.6412 - r_square: 0.2419 - rmse: 0.6412 - val_loss: 0.7697 - val_r_square: 0.0406 - val_rmse: 0.7697    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.6468 - r_square: 0.2307 - rmse: 0.6468 - val_loss: 0.7709 - val_r_square: 0.0371 - val_rmse: 0.7709    \n",
      "\n",
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.6519 - r_square: 0.2124 - rmse: 0.6519 - val_loss: 0.7706 - val_r_square: 0.0380 - val_rmse: 0.7706    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.6409 - r_square: 0.2321 - rmse: 0.6409 - val_loss: 0.7670 - val_r_square: 0.0458 - val_rmse: 0.7670    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.6452 - r_square: 0.2287 - rmse: 0.6452 - val_loss: 0.7696 - val_r_square: 0.0413 - val_rmse: 0.7696    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.6418 - r_square: 0.2306 - rmse: 0.6418 - val_loss: 0.7709 - val_r_square: 0.0376 - val_rmse: 0.7709    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.6499 - r_square: 0.2211 - rmse: 0.6499 - val_loss: 0.7740 - val_r_square: 0.0298 - val_rmse: 0.7740    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.6499 - r_square: 0.2326 - rmse: 0.6499 - val_loss: 0.7725 - val_r_square: 0.0337 - val_rmse: 0.7725    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.6390 - r_square: 0.2560 - rmse: 0.6390 - val_loss: 0.7721 - val_r_square: 0.0347 - val_rmse: 0.7721    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.6448 - r_square: 0.2245 - rmse: 0.6448 - val_loss: 0.7732 - val_r_square: 0.0331 - val_rmse: 0.7732    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.6453 - r_square: 0.2381 - rmse: 0.6453 - val_loss: 0.7715 - val_r_square: 0.0367 - val_rmse: 0.7715    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.6486 - r_square: 0.2225 - rmse: 0.6486 - val_loss: 0.7731 - val_r_square: 0.0336 - val_rmse: 0.7731    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.6359 - r_square: 0.2354 - rmse: 0.6359 - val_loss: 0.7702 - val_r_square: 0.0397 - val_rmse: 0.7702    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.6521 - r_square: 0.2258 - rmse: 0.6521 - val_loss: 0.7681 - val_r_square: 0.0453 - val_rmse: 0.7681    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.6532 - r_square: 0.2205 - rmse: 0.6532 - val_loss: 0.7697 - val_r_square: 0.0421 - val_rmse: 0.7697    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.6416 - r_square: 0.2386 - rmse: 0.6416 - val_loss: 0.7701 - val_r_square: 0.0409 - val_rmse: 0.7701    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.6359 - r_square: 0.2382 - rmse: 0.6359 - val_loss: 0.7744 - val_r_square: 0.0318 - val_rmse: 0.7744    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.6438 - r_square: 0.2352 - rmse: 0.6438 - val_loss: 0.7721 - val_r_square: 0.0369 - val_rmse: 0.7721    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.6496 - r_square: 0.2267 - rmse: 0.6496 - val_loss: 0.7745 - val_r_square: 0.0322 - val_rmse: 0.7745    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.6453 - r_square: 0.2243 - rmse: 0.6453 - val_loss: 0.7749 - val_r_square: 0.0314 - val_rmse: 0.7749    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.6388 - r_square: 0.2336 - rmse: 0.6388 - val_loss: 0.7720 - val_r_square: 0.0370 - val_rmse: 0.7720    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.6398 - r_square: 0.2344 - rmse: 0.6398 - val_loss: 0.7726 - val_r_square: 0.0368 - val_rmse: 0.7726    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.6462 - r_square: 0.2129 - rmse: 0.6462 - val_loss: 0.7725 - val_r_square: 0.0373 - val_rmse: 0.7725    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.6491 - r_square: 0.2170 - rmse: 0.6491 - val_loss: 0.7736 - val_r_square: 0.0346 - val_rmse: 0.7736    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.6319 - r_square: 0.2587 - rmse: 0.6319 - val_loss: 0.7740 - val_r_square: 0.0341 - val_rmse: 0.7740    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n",
      " - 0s - loss: 0.6346 - r_square: 0.2533 - rmse: 0.6346 - val_loss: 0.7726 - val_r_square: 0.0385 - val_rmse: 0.7726    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.6354 - r_square: 0.2502 - rmse: 0.6354 - val_loss: 0.7756 - val_r_square: 0.0327 - val_rmse: 0.7756    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.6363 - r_square: 0.2251 - rmse: 0.6363 - val_loss: 0.7770 - val_r_square: 0.0299 - val_rmse: 0.7770    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.6498 - r_square: 0.2089 - rmse: 0.6498 - val_loss: 0.7755 - val_r_square: 0.0325 - val_rmse: 0.7755    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.6366 - r_square: 0.2401 - rmse: 0.6366 - val_loss: 0.7744 - val_r_square: 0.0364 - val_rmse: 0.7744    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6444 - r_square: 0.2260 - rmse: 0.6444 - val_loss: 0.7739 - val_r_square: 0.0368 - val_rmse: 0.7739    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.6408 - r_square: 0.2396 - rmse: 0.6408 - val_loss: 0.7762 - val_r_square: 0.0320 - val_rmse: 0.7762    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.6323 - r_square: 0.2387 - rmse: 0.6323 - val_loss: 0.7761 - val_r_square: 0.0327 - val_rmse: 0.7761    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.6385 - r_square: 0.2256 - rmse: 0.6385 - val_loss: 0.7734 - val_r_square: 0.0387 - val_rmse: 0.7734    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.6477 - r_square: 0.2195 - rmse: 0.6477 - val_loss: 0.7744 - val_r_square: 0.0359 - val_rmse: 0.7744    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n",
      " - 0s - loss: 0.6344 - r_square: 0.2453 - rmse: 0.6344 - val_loss: 0.7736 - val_r_square: 0.0382 - val_rmse: 0.7736    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.6474 - r_square: 0.2173 - rmse: 0.6474 - val_loss: 0.7763 - val_r_square: 0.0334 - val_rmse: 0.7763    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.6407 - r_square: 0.2317 - rmse: 0.6407 - val_loss: 0.7764 - val_r_square: 0.0328 - val_rmse: 0.7764    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.6417 - r_square: 0.2156 - rmse: 0.6417 - val_loss: 0.7777 - val_r_square: 0.0297 - val_rmse: 0.7777    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.6505 - r_square: 0.2084 - rmse: 0.6505 - val_loss: 0.7750 - val_r_square: 0.0355 - val_rmse: 0.7750    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.6375 - r_square: 0.2363 - rmse: 0.6375 - val_loss: 0.7770 - val_r_square: 0.0319 - val_rmse: 0.7770    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.6297 - r_square: 0.2500 - rmse: 0.6297 - val_loss: 0.7752 - val_r_square: 0.0357 - val_rmse: 0.7752    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.6433 - r_square: 0.2283 - rmse: 0.6433 - val_loss: 0.7781 - val_r_square: 0.0291 - val_rmse: 0.7781    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.6250 - r_square: 0.2646 - rmse: 0.6250 - val_loss: 0.7754 - val_r_square: 0.0359 - val_rmse: 0.7754    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.6412 - r_square: 0.2379 - rmse: 0.6412 - val_loss: 0.7772 - val_r_square: 0.0321 - val_rmse: 0.7772    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.6346 - r_square: 0.2479 - rmse: 0.6346 - val_loss: 0.7765 - val_r_square: 0.0338 - val_rmse: 0.7765    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.6363 - r_square: 0.2391 - rmse: 0.6363 - val_loss: 0.7772 - val_r_square: 0.0330 - val_rmse: 0.7772    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.6395 - r_square: 0.2379 - rmse: 0.6395 - val_loss: 0.7805 - val_r_square: 0.0267 - val_rmse: 0.7805    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.6445 - r_square: 0.2086 - rmse: 0.6445 - val_loss: 0.7786 - val_r_square: 0.0307 - val_rmse: 0.7786    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.6338 - r_square: 0.2399 - rmse: 0.6338 - val_loss: 0.7794 - val_r_square: 0.0298 - val_rmse: 0.7794    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.6308 - r_square: 0.2493 - rmse: 0.6308 - val_loss: 0.7808 - val_r_square: 0.0269 - val_rmse: 0.7808    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.6358 - r_square: 0.2361 - rmse: 0.6358 - val_loss: 0.7812 - val_r_square: 0.0260 - val_rmse: 0.7812    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.6350 - r_square: 0.2455 - rmse: 0.6350 - val_loss: 0.7823 - val_r_square: 0.0234 - val_rmse: 0.7823    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.6269 - r_square: 0.2582 - rmse: 0.6269 - val_loss: 0.7834 - val_r_square: 0.0218 - val_rmse: 0.7834    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.7253285911942099                                                                                                     \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_4\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_10 (Dense)             (None, 500)               3500                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_7 (Dropout)          (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_11 (Dense)             (None, 50)                25050                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_8 (Dropout)          (None, 50)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_12 (Dense)             (None, 1)                 51                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 28,601                                                                                                   \n",
      "Trainable params: 28,601                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 0s - loss: 0.7002 - r_square: 0.1577 - rmse: 0.7002 - val_loss: 0.5390 - val_r_square: 0.5030 - val_rmse: 0.5390    \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.5797 - r_square: 0.3963 - rmse: 0.5797 - val_loss: 0.4964 - val_r_square: 0.5923 - val_rmse: 0.4964    \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.5279 - r_square: 0.4767 - rmse: 0.5279 - val_loss: 0.4393 - val_r_square: 0.6683 - val_rmse: 0.4393    \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.4968 - r_square: 0.5199 - rmse: 0.4968 - val_loss: 0.4177 - val_r_square: 0.6964 - val_rmse: 0.4177    \n",
      "\n",
      "Epoch 5/100                                                                                                            \n",
      " - 0s - loss: 0.4688 - r_square: 0.5538 - rmse: 0.4688 - val_loss: 0.3848 - val_r_square: 0.7265 - val_rmse: 0.3848    \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.4609 - r_square: 0.5745 - rmse: 0.4609 - val_loss: 0.3636 - val_r_square: 0.7422 - val_rmse: 0.3636    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.4377 - r_square: 0.6051 - rmse: 0.4377 - val_loss: 0.3474 - val_r_square: 0.7561 - val_rmse: 0.3474    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.4294 - r_square: 0.6063 - rmse: 0.4294 - val_loss: 0.3522 - val_r_square: 0.7576 - val_rmse: 0.3522    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.4152 - r_square: 0.6460 - rmse: 0.4152 - val_loss: 0.3438 - val_r_square: 0.7629 - val_rmse: 0.3438    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.4167 - r_square: 0.6223 - rmse: 0.4167 - val_loss: 0.3206 - val_r_square: 0.7789 - val_rmse: 0.3206    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.4028 - r_square: 0.6478 - rmse: 0.4028 - val_loss: 0.3207 - val_r_square: 0.7794 - val_rmse: 0.3207    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.3947 - r_square: 0.6528 - rmse: 0.3947 - val_loss: 0.3142 - val_r_square: 0.7875 - val_rmse: 0.3142    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.3870 - r_square: 0.6598 - rmse: 0.3870 - val_loss: 0.3106 - val_r_square: 0.7864 - val_rmse: 0.3106    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.3798 - r_square: 0.6782 - rmse: 0.3798 - val_loss: 0.3013 - val_r_square: 0.7954 - val_rmse: 0.3013    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n",
      " - 0s - loss: 0.3769 - r_square: 0.6796 - rmse: 0.3769 - val_loss: 0.2856 - val_r_square: 0.8061 - val_rmse: 0.2856    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.3665 - r_square: 0.6791 - rmse: 0.3665 - val_loss: 0.2935 - val_r_square: 0.8045 - val_rmse: 0.2935    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.3618 - r_square: 0.6882 - rmse: 0.3618 - val_loss: 0.2827 - val_r_square: 0.8127 - val_rmse: 0.2827    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.3674 - r_square: 0.6805 - rmse: 0.3674 - val_loss: 0.2806 - val_r_square: 0.8138 - val_rmse: 0.2806    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.3619 - r_square: 0.6888 - rmse: 0.3619 - val_loss: 0.2657 - val_r_square: 0.8221 - val_rmse: 0.2657    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.3575 - r_square: 0.6991 - rmse: 0.3575 - val_loss: 0.2649 - val_r_square: 0.8248 - val_rmse: 0.2649    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.3506 - r_square: 0.7026 - rmse: 0.3506 - val_loss: 0.2647 - val_r_square: 0.8242 - val_rmse: 0.2647    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.3526 - r_square: 0.7085 - rmse: 0.3526 - val_loss: 0.2600 - val_r_square: 0.8275 - val_rmse: 0.2600    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.3453 - r_square: 0.7068 - rmse: 0.3453 - val_loss: 0.2508 - val_r_square: 0.8327 - val_rmse: 0.2508    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.3446 - r_square: 0.7211 - rmse: 0.3446 - val_loss: 0.2473 - val_r_square: 0.8370 - val_rmse: 0.2473    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.3379 - r_square: 0.7257 - rmse: 0.3379 - val_loss: 0.2445 - val_r_square: 0.8372 - val_rmse: 0.2445    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.3369 - r_square: 0.7213 - rmse: 0.3369 - val_loss: 0.2454 - val_r_square: 0.8366 - val_rmse: 0.2454    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.3303 - r_square: 0.7325 - rmse: 0.3303 - val_loss: 0.2436 - val_r_square: 0.8407 - val_rmse: 0.2436    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.3322 - r_square: 0.7333 - rmse: 0.3322 - val_loss: 0.2358 - val_r_square: 0.8421 - val_rmse: 0.2358    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.3309 - r_square: 0.7342 - rmse: 0.3309 - val_loss: 0.2312 - val_r_square: 0.8465 - val_rmse: 0.2312    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.3296 - r_square: 0.7312 - rmse: 0.3296 - val_loss: 0.2411 - val_r_square: 0.8407 - val_rmse: 0.2411    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.3237 - r_square: 0.7431 - rmse: 0.3237 - val_loss: 0.2432 - val_r_square: 0.8408 - val_rmse: 0.2432    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.3297 - r_square: 0.7394 - rmse: 0.3297 - val_loss: 0.2432 - val_r_square: 0.8444 - val_rmse: 0.2432    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.3260 - r_square: 0.7394 - rmse: 0.3260 - val_loss: 0.2357 - val_r_square: 0.8504 - val_rmse: 0.2357    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.3195 - r_square: 0.7546 - rmse: 0.3195 - val_loss: 0.2330 - val_r_square: 0.8473 - val_rmse: 0.2330    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.3268 - r_square: 0.7358 - rmse: 0.3268 - val_loss: 0.2272 - val_r_square: 0.8524 - val_rmse: 0.2272    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.3207 - r_square: 0.7339 - rmse: 0.3207 - val_loss: 0.2271 - val_r_square: 0.8525 - val_rmse: 0.2271    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.3220 - r_square: 0.7452 - rmse: 0.3220 - val_loss: 0.2242 - val_r_square: 0.8531 - val_rmse: 0.2242    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.3246 - r_square: 0.7492 - rmse: 0.3246 - val_loss: 0.2210 - val_r_square: 0.8530 - val_rmse: 0.2210    \n",
      "\n",
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.3170 - r_square: 0.7545 - rmse: 0.3170 - val_loss: 0.2152 - val_r_square: 0.8562 - val_rmse: 0.2152    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.3200 - r_square: 0.7387 - rmse: 0.3200 - val_loss: 0.2390 - val_r_square: 0.8486 - val_rmse: 0.2390    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.3238 - r_square: 0.7422 - rmse: 0.3238 - val_loss: 0.2261 - val_r_square: 0.8502 - val_rmse: 0.2261    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.3143 - r_square: 0.7645 - rmse: 0.3143 - val_loss: 0.2376 - val_r_square: 0.8491 - val_rmse: 0.2376    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.3181 - r_square: 0.7452 - rmse: 0.3181 - val_loss: 0.2275 - val_r_square: 0.8519 - val_rmse: 0.2275    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.3068 - r_square: 0.7598 - rmse: 0.3068 - val_loss: 0.2224 - val_r_square: 0.8553 - val_rmse: 0.2224    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.3138 - r_square: 0.7454 - rmse: 0.3138 - val_loss: 0.2100 - val_r_square: 0.8564 - val_rmse: 0.2100    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.3120 - r_square: 0.7527 - rmse: 0.3120 - val_loss: 0.2288 - val_r_square: 0.8542 - val_rmse: 0.2288    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.3118 - r_square: 0.7585 - rmse: 0.3118 - val_loss: 0.2124 - val_r_square: 0.8577 - val_rmse: 0.2124    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.3128 - r_square: 0.7554 - rmse: 0.3128 - val_loss: 0.2233 - val_r_square: 0.8565 - val_rmse: 0.2233    \n",
      "\n",
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.3184 - r_square: 0.7510 - rmse: 0.3184 - val_loss: 0.2147 - val_r_square: 0.8614 - val_rmse: 0.2147    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.3154 - r_square: 0.7524 - rmse: 0.3154 - val_loss: 0.2168 - val_r_square: 0.8570 - val_rmse: 0.2168    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.3097 - r_square: 0.7481 - rmse: 0.3097 - val_loss: 0.2200 - val_r_square: 0.8569 - val_rmse: 0.2200    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.3103 - r_square: 0.7483 - rmse: 0.3103 - val_loss: 0.2123 - val_r_square: 0.8599 - val_rmse: 0.2123    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.3073 - r_square: 0.7654 - rmse: 0.3073 - val_loss: 0.2063 - val_r_square: 0.8616 - val_rmse: 0.2063    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.3121 - r_square: 0.7436 - rmse: 0.3121 - val_loss: 0.2130 - val_r_square: 0.8590 - val_rmse: 0.2130    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.3051 - r_square: 0.7604 - rmse: 0.3051 - val_loss: 0.2147 - val_r_square: 0.8584 - val_rmse: 0.2147    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.3069 - r_square: 0.7635 - rmse: 0.3069 - val_loss: 0.2168 - val_r_square: 0.8601 - val_rmse: 0.2168    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.3050 - r_square: 0.7656 - rmse: 0.3050 - val_loss: 0.2124 - val_r_square: 0.8625 - val_rmse: 0.2124    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.3036 - r_square: 0.7723 - rmse: 0.3036 - val_loss: 0.2210 - val_r_square: 0.8596 - val_rmse: 0.2210    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.3002 - r_square: 0.7689 - rmse: 0.3002 - val_loss: 0.2140 - val_r_square: 0.8623 - val_rmse: 0.2140    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.3043 - r_square: 0.7604 - rmse: 0.3043 - val_loss: 0.2229 - val_r_square: 0.8561 - val_rmse: 0.2229    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.3069 - r_square: 0.7638 - rmse: 0.3069 - val_loss: 0.2181 - val_r_square: 0.8601 - val_rmse: 0.2181    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.3024 - r_square: 0.7640 - rmse: 0.3024 - val_loss: 0.2036 - val_r_square: 0.8630 - val_rmse: 0.2036    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.3038 - r_square: 0.7598 - rmse: 0.3038 - val_loss: 0.2082 - val_r_square: 0.8627 - val_rmse: 0.2082    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.3068 - r_square: 0.7670 - rmse: 0.3068 - val_loss: 0.2140 - val_r_square: 0.8629 - val_rmse: 0.2140    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.3006 - r_square: 0.7639 - rmse: 0.3006 - val_loss: 0.2091 - val_r_square: 0.8629 - val_rmse: 0.2091    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.3016 - r_square: 0.7640 - rmse: 0.3016 - val_loss: 0.2090 - val_r_square: 0.8630 - val_rmse: 0.2090    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2996 - r_square: 0.7659 - rmse: 0.2996 - val_loss: 0.1974 - val_r_square: 0.8659 - val_rmse: 0.1974    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.3042 - r_square: 0.7667 - rmse: 0.3042 - val_loss: 0.2124 - val_r_square: 0.8654 - val_rmse: 0.2124    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.3026 - r_square: 0.7642 - rmse: 0.3026 - val_loss: 0.2108 - val_r_square: 0.8670 - val_rmse: 0.2108    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.3009 - r_square: 0.7650 - rmse: 0.3009 - val_loss: 0.2104 - val_r_square: 0.8647 - val_rmse: 0.2104    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.2991 - r_square: 0.7641 - rmse: 0.2991 - val_loss: 0.1997 - val_r_square: 0.8662 - val_rmse: 0.1997    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n",
      " - 0s - loss: 0.3009 - r_square: 0.7675 - rmse: 0.3009 - val_loss: 0.2204 - val_r_square: 0.8626 - val_rmse: 0.2204    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.3000 - r_square: 0.7601 - rmse: 0.3000 - val_loss: 0.2089 - val_r_square: 0.8662 - val_rmse: 0.2089    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.2979 - r_square: 0.7641 - rmse: 0.2979 - val_loss: 0.2185 - val_r_square: 0.8636 - val_rmse: 0.2185    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.2986 - r_square: 0.7791 - rmse: 0.2986 - val_loss: 0.2238 - val_r_square: 0.8612 - val_rmse: 0.2238    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.2992 - r_square: 0.7724 - rmse: 0.2992 - val_loss: 0.2212 - val_r_square: 0.8628 - val_rmse: 0.2212    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.3013 - r_square: 0.7621 - rmse: 0.3013 - val_loss: 0.2123 - val_r_square: 0.8631 - val_rmse: 0.2123    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.2943 - r_square: 0.7713 - rmse: 0.2943 - val_loss: 0.2133 - val_r_square: 0.8642 - val_rmse: 0.2133    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.3027 - r_square: 0.7666 - rmse: 0.3027 - val_loss: 0.2060 - val_r_square: 0.8653 - val_rmse: 0.2060    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.2985 - r_square: 0.7709 - rmse: 0.2985 - val_loss: 0.2098 - val_r_square: 0.8652 - val_rmse: 0.2098    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.2974 - r_square: 0.7704 - rmse: 0.2974 - val_loss: 0.2128 - val_r_square: 0.8642 - val_rmse: 0.2128    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n",
      " - 0s - loss: 0.3028 - r_square: 0.7723 - rmse: 0.3028 - val_loss: 0.2103 - val_r_square: 0.8649 - val_rmse: 0.2103    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.2963 - r_square: 0.7769 - rmse: 0.2963 - val_loss: 0.2132 - val_r_square: 0.8656 - val_rmse: 0.2132    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.2970 - r_square: 0.7702 - rmse: 0.2970 - val_loss: 0.2074 - val_r_square: 0.8683 - val_rmse: 0.2074    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.3003 - r_square: 0.7685 - rmse: 0.3003 - val_loss: 0.2071 - val_r_square: 0.8674 - val_rmse: 0.2071    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.3056 - r_square: 0.7599 - rmse: 0.3056 - val_loss: 0.2178 - val_r_square: 0.8649 - val_rmse: 0.2178    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.2978 - r_square: 0.7680 - rmse: 0.2978 - val_loss: 0.2107 - val_r_square: 0.8664 - val_rmse: 0.2107    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.2944 - r_square: 0.7760 - rmse: 0.2944 - val_loss: 0.2054 - val_r_square: 0.8680 - val_rmse: 0.2054    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.2920 - r_square: 0.7782 - rmse: 0.2920 - val_loss: 0.2033 - val_r_square: 0.8681 - val_rmse: 0.2033    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.2967 - r_square: 0.7690 - rmse: 0.2967 - val_loss: 0.2113 - val_r_square: 0.8653 - val_rmse: 0.2113    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.2917 - r_square: 0.7763 - rmse: 0.2917 - val_loss: 0.2070 - val_r_square: 0.8678 - val_rmse: 0.2070    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.2928 - r_square: 0.7715 - rmse: 0.2928 - val_loss: 0.2081 - val_r_square: 0.8688 - val_rmse: 0.2081    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.2940 - r_square: 0.7807 - rmse: 0.2940 - val_loss: 0.2080 - val_r_square: 0.8693 - val_rmse: 0.2080    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.2992 - r_square: 0.7693 - rmse: 0.2992 - val_loss: 0.2000 - val_r_square: 0.8711 - val_rmse: 0.2000    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.2932 - r_square: 0.7754 - rmse: 0.2932 - val_loss: 0.2077 - val_r_square: 0.8685 - val_rmse: 0.2077    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.3000 - r_square: 0.7664 - rmse: 0.3000 - val_loss: 0.2128 - val_r_square: 0.8682 - val_rmse: 0.2128    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.2935 - r_square: 0.7816 - rmse: 0.2935 - val_loss: 0.1977 - val_r_square: 0.8728 - val_rmse: 0.1977    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.2933 - r_square: 0.7816 - rmse: 0.2933 - val_loss: 0.2020 - val_r_square: 0.8723 - val_rmse: 0.2020    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.2949 - r_square: 0.7783 - rmse: 0.2949 - val_loss: 0.2016 - val_r_square: 0.8715 - val_rmse: 0.2016    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.2901 - r_square: 0.7778 - rmse: 0.2901 - val_loss: 0.2157 - val_r_square: 0.8666 - val_rmse: 0.2157    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest Validation Loss:                                                                                                \n",
      "0.19735512516067344                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_5\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_13 (Dense)             (None, 500)               3500                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_9 (Dropout)          (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_14 (Dense)             (None, 200)               100200                                                          \n",
      "_________________________________________________________________                                                      \n",
      "dropout_10 (Dropout)         (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_15 (Dense)             (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 103,901                                                                                                  \n",
      "Trainable params: 103,901                                                                                              \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 0s - loss: 0.4564 - r_square: 0.5400 - rmse: 0.4564 - val_loss: 0.2955 - val_r_square: 0.7902 - val_rmse: 0.2955    \n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.2911 - r_square: 0.7621 - rmse: 0.2911 - val_loss: 0.2344 - val_r_square: 0.8282 - val_rmse: 0.2344    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.2524 - r_square: 0.7966 - rmse: 0.2524 - val_loss: 0.2178 - val_r_square: 0.8483 - val_rmse: 0.2178    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.2288 - r_square: 0.8145 - rmse: 0.2288 - val_loss: 0.2053 - val_r_square: 0.8524 - val_rmse: 0.2053    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.2168 - r_square: 0.8204 - rmse: 0.2168 - val_loss: 0.1805 - val_r_square: 0.8615 - val_rmse: 0.1805    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.2082 - r_square: 0.8222 - rmse: 0.2082 - val_loss: 0.1788 - val_r_square: 0.8706 - val_rmse: 0.1788    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.2053 - r_square: 0.8271 - rmse: 0.2053 - val_loss: 0.1772 - val_r_square: 0.8755 - val_rmse: 0.1772    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.2024 - r_square: 0.8334 - rmse: 0.2024 - val_loss: 0.1662 - val_r_square: 0.8745 - val_rmse: 0.1662    \n",
      "\n",
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.1905 - r_square: 0.8397 - rmse: 0.1905 - val_loss: 0.1643 - val_r_square: 0.8761 - val_rmse: 0.1643    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.1842 - r_square: 0.8438 - rmse: 0.1842 - val_loss: 0.1680 - val_r_square: 0.8723 - val_rmse: 0.1680    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.1869 - r_square: 0.8409 - rmse: 0.1869 - val_loss: 0.1616 - val_r_square: 0.8789 - val_rmse: 0.1616    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.1887 - r_square: 0.8448 - rmse: 0.1887 - val_loss: 0.1538 - val_r_square: 0.8850 - val_rmse: 0.1538    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.1796 - r_square: 0.8478 - rmse: 0.1796 - val_loss: 0.1644 - val_r_square: 0.8797 - val_rmse: 0.1644    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.1795 - r_square: 0.8542 - rmse: 0.1795 - val_loss: 0.1544 - val_r_square: 0.8869 - val_rmse: 0.1544    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.1750 - r_square: 0.8497 - rmse: 0.1750 - val_loss: 0.1555 - val_r_square: 0.8932 - val_rmse: 0.1555    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.1726 - r_square: 0.8492 - rmse: 0.1726 - val_loss: 0.1449 - val_r_square: 0.8958 - val_rmse: 0.1449    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.1755 - r_square: 0.8490 - rmse: 0.1755 - val_loss: 0.1594 - val_r_square: 0.8864 - val_rmse: 0.1594    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.1744 - r_square: 0.8548 - rmse: 0.1744 - val_loss: 0.1526 - val_r_square: 0.8920 - val_rmse: 0.1526    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.1724 - r_square: 0.8575 - rmse: 0.1724 - val_loss: 0.1648 - val_r_square: 0.8811 - val_rmse: 0.1648    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.1717 - r_square: 0.8490 - rmse: 0.1717 - val_loss: 0.1441 - val_r_square: 0.8967 - val_rmse: 0.1441    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.1690 - r_square: 0.8492 - rmse: 0.1690 - val_loss: 0.1413 - val_r_square: 0.8963 - val_rmse: 0.1413    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.1732 - r_square: 0.8549 - rmse: 0.1732 - val_loss: 0.1441 - val_r_square: 0.9003 - val_rmse: 0.1441    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.1639 - r_square: 0.8560 - rmse: 0.1639 - val_loss: 0.1393 - val_r_square: 0.9024 - val_rmse: 0.1393    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.1653 - r_square: 0.8568 - rmse: 0.1653 - val_loss: 0.1407 - val_r_square: 0.9016 - val_rmse: 0.1407    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.1673 - r_square: 0.8551 - rmse: 0.1673 - val_loss: 0.1418 - val_r_square: 0.9022 - val_rmse: 0.1418    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.1662 - r_square: 0.8630 - rmse: 0.1662 - val_loss: 0.1311 - val_r_square: 0.9040 - val_rmse: 0.1311    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.1605 - r_square: 0.8579 - rmse: 0.1605 - val_loss: 0.1378 - val_r_square: 0.8996 - val_rmse: 0.1378    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.1573 - r_square: 0.8707 - rmse: 0.1573 - val_loss: 0.1407 - val_r_square: 0.9011 - val_rmse: 0.1407    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n",
      " - 0s - loss: 0.1607 - r_square: 0.8619 - rmse: 0.1607 - val_loss: 0.1441 - val_r_square: 0.9013 - val_rmse: 0.1441    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.1628 - r_square: 0.8661 - rmse: 0.1628 - val_loss: 0.1380 - val_r_square: 0.9043 - val_rmse: 0.1380    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.1614 - r_square: 0.8615 - rmse: 0.1614 - val_loss: 0.1439 - val_r_square: 0.9036 - val_rmse: 0.1439    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.1613 - r_square: 0.8647 - rmse: 0.1613 - val_loss: 0.1369 - val_r_square: 0.9050 - val_rmse: 0.1369    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.1583 - r_square: 0.8704 - rmse: 0.1583 - val_loss: 0.1292 - val_r_square: 0.9076 - val_rmse: 0.1292    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.1560 - r_square: 0.8705 - rmse: 0.1560 - val_loss: 0.1427 - val_r_square: 0.9076 - val_rmse: 0.1427    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.1591 - r_square: 0.8695 - rmse: 0.1591 - val_loss: 0.1283 - val_r_square: 0.9094 - val_rmse: 0.1283    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.1563 - r_square: 0.8688 - rmse: 0.1563 - val_loss: 0.1361 - val_r_square: 0.9070 - val_rmse: 0.1361    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.1598 - r_square: 0.8690 - rmse: 0.1598 - val_loss: 0.1400 - val_r_square: 0.9081 - val_rmse: 0.1400    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.1602 - r_square: 0.8714 - rmse: 0.1602 - val_loss: 0.1380 - val_r_square: 0.9032 - val_rmse: 0.1380    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.1570 - r_square: 0.8722 - rmse: 0.1570 - val_loss: 0.1569 - val_r_square: 0.8902 - val_rmse: 0.1569    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.1536 - r_square: 0.8726 - rmse: 0.1536 - val_loss: 0.1355 - val_r_square: 0.9102 - val_rmse: 0.1355    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.1540 - r_square: 0.8854 - rmse: 0.1540 - val_loss: 0.1345 - val_r_square: 0.9098 - val_rmse: 0.1345    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n",
      " - 0s - loss: 0.1525 - r_square: 0.8708 - rmse: 0.1525 - val_loss: 0.1261 - val_r_square: 0.9117 - val_rmse: 0.1261    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.1552 - r_square: 0.8642 - rmse: 0.1552 - val_loss: 0.1370 - val_r_square: 0.9067 - val_rmse: 0.1370    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.1549 - r_square: 0.8769 - rmse: 0.1549 - val_loss: 0.1265 - val_r_square: 0.9084 - val_rmse: 0.1265    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.1505 - r_square: 0.8767 - rmse: 0.1505 - val_loss: 0.1343 - val_r_square: 0.9049 - val_rmse: 0.1343    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.1542 - r_square: 0.8713 - rmse: 0.1542 - val_loss: 0.1313 - val_r_square: 0.9080 - val_rmse: 0.1313    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.1489 - r_square: 0.8831 - rmse: 0.1489 - val_loss: 0.1281 - val_r_square: 0.9132 - val_rmse: 0.1281    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.1538 - r_square: 0.8655 - rmse: 0.1538 - val_loss: 0.1356 - val_r_square: 0.9065 - val_rmse: 0.1356    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.1509 - r_square: 0.8770 - rmse: 0.1509 - val_loss: 0.1344 - val_r_square: 0.9097 - val_rmse: 0.1344    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.1481 - r_square: 0.8829 - rmse: 0.1481 - val_loss: 0.1304 - val_r_square: 0.9101 - val_rmse: 0.1304    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.12613668797262045                                                                                                    \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:45<00:00, 21.05s/trial, best loss: -0.7253285911942099]\n",
      "1486/1486 [==============================] - 0s 19us/step\n",
      "Evaluate: 0.7948254023554508\n",
      "Best Performing Model: {'Dense': 50, 'Dense_1': 500, 'Dropout': 0.9758185183456943, 'Dropout_1': 0.288662535902546, 'batch_size': 64, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#defining the create model function\n",
    "exec('from __future__ import absolute_import, division, print_function')\n",
    "from hyperas.distributions import uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras import backend as K\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    print(x_train.shape)\n",
    "    model= Sequential() \n",
    "    model.add(Dense({{choice([50,200,500])}}, input_dim=x_train.shape[1], activation= 'relu'))\n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Dense({{choice([50,200,500])}},activation= 'relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Dense(1, activation= 'linear'))\n",
    "\n",
    "    \n",
    "################################################\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "    def rmse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "    def mse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "    def r_square(y_true, y_pred):\n",
    "        SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "        SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "        return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "#############################################\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
    "    from keras.utils import print_summary\n",
    "    print_summary(model, line_length=None, positions=None, print_fn=None)\n",
    "    result= model.fit(x_train, y_train,\n",
    "                      batch_size={{choice([64,128])}},\n",
    "                      epochs={{choice([50,100,150])}},\n",
    "                      verbose=2,\n",
    "                      validation_split =0.15)\n",
    "    validation_acc= np.min(result.history['val_loss'])\n",
    "    print('Lowest Validation Loss:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
    "\n",
    "#finding the best model\n",
    "best_run, best_model= optim.minimize(model=create_model,\n",
    "                                     data=data,\n",
    "                                     algo=tpe.suggest,\n",
    "                                     max_evals=5,\n",
    "                                     trials=Trials(),\n",
    "                                     eval_space=True,\n",
    "                                     notebook_name='NeuralAnalysis')\n",
    "score= best_model.evaluate(X_test_scaled,y_test_scaled, batch_size= 64)\n",
    "\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "#print best model results\n",
    "print('Evaluate:', score[0])\n",
    "#print('Predictions:', predictions[:6])\n",
    "print('Best Performing Model:', best_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17784706],\n",
       "       [ 0.06881683],\n",
       "       [ 0.11936215],\n",
       "       ...,\n",
       "       [-0.07202001],\n",
       "       [-0.07231262],\n",
       "       [-0.07336685]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using model to predict y values\n",
    "predictions1 = best_model.predict(X_train_scaled)\n",
    "predictions1\n",
    "#predictions= test\n",
    "#predictions1= train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Residuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Neural Network Residual Plot')\n",
    "plt.scatter(predictions1, predictions1 - y_train_scaled, c= \"orange\",label=\"Training Data\", s=4)\n",
    "plt.scatter(predictions, predictions - y_test_scaled, c= \"blue\",label=\"Testing Data\",s=4)\n",
    "plt.ylim(-2,2)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('neuralnetworkresidual.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Volve",
   "language": "python",
   "name": "volve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
