{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WELL_BORE_CODE</th>\n",
       "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
       "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
       "      <th>AVG_CHOKE_SIZE_P</th>\n",
       "      <th>AVG_WHP_P</th>\n",
       "      <th>AVG_WHT_P</th>\n",
       "      <th>DP_CHOKE_SIZE</th>\n",
       "      <th>BORE_OIL_VOL</th>\n",
       "      <th>BORE_GAS_VOL</th>\n",
       "      <th>BORE_WAT_VOL</th>\n",
       "      <th>FLOW_KIND</th>\n",
       "      <th>WELL_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>289.42</td>\n",
       "      <td>106.35</td>\n",
       "      <td>43.34</td>\n",
       "      <td>107.36</td>\n",
       "      <td>37.94</td>\n",
       "      <td>78.94</td>\n",
       "      <td>631.47</td>\n",
       "      <td>90439.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>270.24</td>\n",
       "      <td>107.64</td>\n",
       "      <td>47.17</td>\n",
       "      <td>99.19</td>\n",
       "      <td>60.76</td>\n",
       "      <td>70.63</td>\n",
       "      <td>1166.46</td>\n",
       "      <td>165720.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>262.84</td>\n",
       "      <td>107.87</td>\n",
       "      <td>47.73</td>\n",
       "      <td>94.60</td>\n",
       "      <td>63.05</td>\n",
       "      <td>66.05</td>\n",
       "      <td>1549.81</td>\n",
       "      <td>221707.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>255.53</td>\n",
       "      <td>107.97</td>\n",
       "      <td>48.53</td>\n",
       "      <td>89.99</td>\n",
       "      <td>64.55</td>\n",
       "      <td>61.41</td>\n",
       "      <td>1248.70</td>\n",
       "      <td>178063.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>247.20</td>\n",
       "      <td>108.05</td>\n",
       "      <td>49.84</td>\n",
       "      <td>84.78</td>\n",
       "      <td>65.72</td>\n",
       "      <td>56.15</td>\n",
       "      <td>1345.78</td>\n",
       "      <td>192602.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>8923</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.58</td>\n",
       "      <td>15.81</td>\n",
       "      <td>49.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>144.01</td>\n",
       "      <td>23201.35</td>\n",
       "      <td>203.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>8924</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.54</td>\n",
       "      <td>15.77</td>\n",
       "      <td>48.99</td>\n",
       "      <td>1.20</td>\n",
       "      <td>145.22</td>\n",
       "      <td>23068.07</td>\n",
       "      <td>202.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>8925</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.32</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.70</td>\n",
       "      <td>50.10</td>\n",
       "      <td>1.28</td>\n",
       "      <td>142.74</td>\n",
       "      <td>23059.68</td>\n",
       "      <td>203.84</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>8926</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.21</td>\n",
       "      <td>106.51</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.61</td>\n",
       "      <td>49.84</td>\n",
       "      <td>1.20</td>\n",
       "      <td>144.46</td>\n",
       "      <td>23090.47</td>\n",
       "      <td>202.76</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>8927</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.31</td>\n",
       "      <td>106.51</td>\n",
       "      <td>24.92</td>\n",
       "      <td>15.76</td>\n",
       "      <td>48.73</td>\n",
       "      <td>1.30</td>\n",
       "      <td>106.30</td>\n",
       "      <td>17537.08</td>\n",
       "      <td>155.70</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5943 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  WELL_BORE_CODE  AVG_DOWNHOLE_PRESSURE  \\\n",
       "0             15   NO 15/9-F-1 C                 289.42   \n",
       "1             16   NO 15/9-F-1 C                 270.24   \n",
       "2             17   NO 15/9-F-1 C                 262.84   \n",
       "3             18   NO 15/9-F-1 C                 255.53   \n",
       "4             19   NO 15/9-F-1 C                 247.20   \n",
       "...          ...             ...                    ...   \n",
       "5938        8923  NO 15/9-F-15 D                 194.98   \n",
       "5939        8924  NO 15/9-F-15 D                 194.98   \n",
       "5940        8925  NO 15/9-F-15 D                 194.32   \n",
       "5941        8926  NO 15/9-F-15 D                 195.21   \n",
       "5942        8927  NO 15/9-F-15 D                 195.31   \n",
       "\n",
       "      AVG_DOWNHOLE_TEMPERATURE  AVG_CHOKE_SIZE_P  AVG_WHP_P  AVG_WHT_P  \\\n",
       "0                       106.35             43.34     107.36      37.94   \n",
       "1                       107.64             47.17      99.19      60.76   \n",
       "2                       107.87             47.73      94.60      63.05   \n",
       "3                       107.97             48.53      89.99      64.55   \n",
       "4                       108.05             49.84      84.78      65.72   \n",
       "...                        ...               ...        ...        ...   \n",
       "5938                    106.52             31.58      15.81      49.02   \n",
       "5939                    106.52             31.54      15.77      48.99   \n",
       "5940                    106.52             31.52      15.70      50.10   \n",
       "5941                    106.51             31.52      15.61      49.84   \n",
       "5942                    106.51             24.92      15.76      48.73   \n",
       "\n",
       "      DP_CHOKE_SIZE  BORE_OIL_VOL  BORE_GAS_VOL  BORE_WAT_VOL   FLOW_KIND  \\\n",
       "0             78.94        631.47      90439.09          0.00  production   \n",
       "1             70.63       1166.46     165720.39          0.00  production   \n",
       "2             66.05       1549.81     221707.31          0.00  production   \n",
       "3             61.41       1248.70     178063.52          0.00  production   \n",
       "4             56.15       1345.78     192602.19          0.00  production   \n",
       "...             ...           ...           ...           ...         ...   \n",
       "5938           1.26        144.01      23201.35        203.93  production   \n",
       "5939           1.20        145.22      23068.07        202.93  production   \n",
       "5940           1.28        142.74      23059.68        203.84  production   \n",
       "5941           1.20        144.46      23090.47        202.76  production   \n",
       "5942           1.30        106.30      17537.08        155.70  production   \n",
       "\n",
       "     WELL_TYPE  \n",
       "0           OP  \n",
       "1           OP  \n",
       "2           OP  \n",
       "3           OP  \n",
       "4           OP  \n",
       "...        ...  \n",
       "5938        OP  \n",
       "5939        OP  \n",
       "5940        OP  \n",
       "5941        OP  \n",
       "5942        OP  \n",
       "\n",
       "[5943 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data csv\n",
    "all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "all_wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUTS: AVG_CHOKE_SIZE_P, AVG_WHP_P, AVG_WHT_P, BORE_OIL_VOL, BORE_GAS_VOL, BORE_WAT_VOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5943, 6)\n"
     ]
    }
   ],
   "source": [
    "#read in data for analysis \n",
    "X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = X_train.shape[1]\n",
    "number_hidden_nodes = 100\n",
    "\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(number_hidden_nodes, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "from keras import losses\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",\n",
    "              optimizer=\"adam\", metrics=[r_square, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping tuning #1\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10,verbose=0, mode='min')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping tuning #2\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_r_square', min_delta=0.000001, patience=5,verbose=0, mode='max')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperas Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scale data for create model function\n",
    "def data():\n",
    "    #read in data for analysis \n",
    "    all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "    X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "    y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "    #split into test and train data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # # Create a StandardScater model and fit it to the training data\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    y_scaler = StandardScaler().fit(y_train)\n",
    "    # # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    y_train_scaled = y_scaler.transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    \n",
    "    x_train = X_train_scaled.reshape(-1,6)\n",
    "    x_test = X_test_scaled.reshape(-1,6)\n",
    "    y_train = y_train_scaled.reshape(-1,1)\n",
    "    y_test = y_test_scaled.reshape(-1,1)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import losses\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import print_summary\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error, r2_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0,.5),\n",
      "        'Dense': hp.choice('Dense', [50,100,200,300]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0,.5),\n",
      "        'batch_size': hp.choice('batch_size', [64,128]),\n",
      "        'epochs': hp.choice('epochs', [50,100,150]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: #read in data for analysis \n",
      "   3: all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
      "   4: X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
      "   5: y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
      "   6: #split into test and train data\n",
      "   7: from sklearn.model_selection import train_test_split\n",
      "   8: X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
      "   9: from sklearn.preprocessing import StandardScaler\n",
      "  10: # # Create a StandardScater model and fit it to the training data\n",
      "  11: X_scaler = StandardScaler().fit(X_train)\n",
      "  12: y_scaler = StandardScaler().fit(y_train)\n",
      "  13: # # Transform the training and testing data using the X_scaler and y_scaler models\n",
      "  14: X_train_scaled = X_scaler.transform(X_train)\n",
      "  15: X_test_scaled = X_scaler.transform(X_test)\n",
      "  16: y_train_scaled = y_scaler.transform(y_train)\n",
      "  17: y_test_scaled = y_scaler.transform(y_test)\n",
      "  18: \n",
      "  19: x_train = X_train_scaled.reshape(-1,6)\n",
      "  20: x_test = X_test_scaled.reshape(-1,6)\n",
      "  21: y_train = y_train_scaled.reshape(-1,1)\n",
      "  22: y_test = y_test_scaled.reshape(-1,1)\n",
      "  23: \n",
      "  24: \n",
      "  25: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print(x_train.shape)\n",
      "   4:     model= Sequential() \n",
      "   5:     model.add(Dense(100, input_dim=x_train.shape[1], activation= 'relu'))\n",
      "   6:     model.add(Dropout(space['Dropout']))\n",
      "   7:     model.add(Dense(space['Dense'],activation= 'relu'))\n",
      "   8:     #model.add(Activation('relu'))\n",
      "   9:     model.add(Dropout(space['Dropout_1']))\n",
      "  10:     model.add(Dense(1, activation= 'linear'))\n",
      "  11: \n",
      "  12:     \n",
      "  13: ################################################\n",
      "  14: # CREDIT: https://github.com/keras-team/keras/issues/7947\n",
      "  15:     def rmse(y_true, y_pred):\n",
      "  16:         return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
      "  17: # mean squared error (mse) for regression  (only for Keras tensors)\n",
      "  18:     def mse(y_true, y_pred):\n",
      "  19:         return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
      "  20:     def r_square(y_true, y_pred):\n",
      "  21:         SS_res =  K.sum(K.square(y_true - y_pred)) \n",
      "  22:         SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
      "  23:         return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
      "  24: #############################################\n",
      "  25: \n",
      "  26:     model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
      "  27:     print_summary(model, line_length=None, positions=None, print_fn=None)\n",
      "  28:     result= model.fit(x_train, y_train,\n",
      "  29:                       batch_size=space['batch_size'],\n",
      "  30:                       epochs=space['epochs'],\n",
      "  31:                       verbose=2,\n",
      "  32:                       validation_split =0.15)\n",
      "  33:     validation_acc= np.min(result.history['val_loss'])\n",
      "  34:     print('Lowest Validation Loss:', validation_acc)\n",
      "  35:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
      "  36: \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_1\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_1 (Dense)              (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_1 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_2 (Dense)              (None, 100)               10100                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_2 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_3 (Dense)              (None, 1)                 101                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 10,901                                                                                                   \n",
      "Trainable params: 10,901                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/150                                                                                                            \n",
      " - 1s - loss: 0.6234 - r_square: 0.3063 - rmse: 0.6234 - val_loss: 0.4320 - val_r_square: 0.6205 - val_rmse: 0.4320    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150                                                                                                            \n",
      " - 0s - loss: 0.4801 - r_square: 0.5392 - rmse: 0.4801 - val_loss: 0.3496 - val_r_square: 0.7232 - val_rmse: 0.3496    \n",
      "\n",
      "Epoch 3/150                                                                                                            \n",
      " - 0s - loss: 0.4229 - r_square: 0.6229 - rmse: 0.4229 - val_loss: 0.3111 - val_r_square: 0.7720 - val_rmse: 0.3111    \n",
      "\n",
      "Epoch 4/150                                                                                                            \n",
      " - 0s - loss: 0.3962 - r_square: 0.6536 - rmse: 0.3962 - val_loss: 0.2884 - val_r_square: 0.7903 - val_rmse: 0.2884    \n",
      "\n",
      "Epoch 5/150                                                                                                            \n",
      " - 0s - loss: 0.3707 - r_square: 0.6858 - rmse: 0.3707 - val_loss: 0.2823 - val_r_square: 0.8010 - val_rmse: 0.2823    \n",
      "\n",
      "Epoch 6/150                                                                                                            \n",
      " - 0s - loss: 0.3563 - r_square: 0.7091 - rmse: 0.3563 - val_loss: 0.2580 - val_r_square: 0.8175 - val_rmse: 0.2580    \n",
      "\n",
      "Epoch 7/150                                                                                                            \n",
      " - 0s - loss: 0.3412 - r_square: 0.7134 - rmse: 0.3412 - val_loss: 0.2473 - val_r_square: 0.8264 - val_rmse: 0.2473    \n",
      "\n",
      "Epoch 8/150                                                                                                            \n",
      " - 0s - loss: 0.3339 - r_square: 0.7312 - rmse: 0.3339 - val_loss: 0.2385 - val_r_square: 0.8294 - val_rmse: 0.2385    \n",
      "\n",
      "Epoch 9/150                                                                                                            \n",
      " - 0s - loss: 0.3267 - r_square: 0.7355 - rmse: 0.3267 - val_loss: 0.2356 - val_r_square: 0.8374 - val_rmse: 0.2356    \n",
      "\n",
      "Epoch 10/150                                                                                                           \n",
      " - 0s - loss: 0.3184 - r_square: 0.7384 - rmse: 0.3184 - val_loss: 0.2355 - val_r_square: 0.8437 - val_rmse: 0.2355    \n",
      "\n",
      "Epoch 11/150                                                                                                           \n",
      " - 0s - loss: 0.3170 - r_square: 0.7424 - rmse: 0.3170 - val_loss: 0.2427 - val_r_square: 0.8411 - val_rmse: 0.2427    \n",
      "\n",
      "Epoch 12/150                                                                                                           \n",
      " - 0s - loss: 0.3085 - r_square: 0.7474 - rmse: 0.3085 - val_loss: 0.2181 - val_r_square: 0.8496 - val_rmse: 0.2181    \n",
      "\n",
      "Epoch 13/150                                                                                                           \n",
      " - 0s - loss: 0.2973 - r_square: 0.7610 - rmse: 0.2973 - val_loss: 0.2230 - val_r_square: 0.8507 - val_rmse: 0.2230    \n",
      "\n",
      "Epoch 14/150                                                                                                           \n",
      " - 0s - loss: 0.2917 - r_square: 0.7709 - rmse: 0.2917 - val_loss: 0.2284 - val_r_square: 0.8531 - val_rmse: 0.2284    \n",
      "\n",
      "Epoch 15/150                                                                                                           \n",
      " - 0s - loss: 0.2847 - r_square: 0.7726 - rmse: 0.2847 - val_loss: 0.2153 - val_r_square: 0.8586 - val_rmse: 0.2153    \n",
      "\n",
      "Epoch 16/150                                                                                                           \n",
      " - 0s - loss: 0.2813 - r_square: 0.7837 - rmse: 0.2813 - val_loss: 0.2152 - val_r_square: 0.8578 - val_rmse: 0.2152    \n",
      "\n",
      "Epoch 17/150                                                                                                           \n",
      " - 0s - loss: 0.2783 - r_square: 0.7793 - rmse: 0.2783 - val_loss: 0.2207 - val_r_square: 0.8584 - val_rmse: 0.2207    \n",
      "\n",
      "Epoch 18/150                                                                                                           \n",
      " - 0s - loss: 0.2771 - r_square: 0.7891 - rmse: 0.2771 - val_loss: 0.2008 - val_r_square: 0.8636 - val_rmse: 0.2008    \n",
      "\n",
      "Epoch 19/150                                                                                                           \n",
      " - 0s - loss: 0.2694 - r_square: 0.7836 - rmse: 0.2694 - val_loss: 0.2001 - val_r_square: 0.8643 - val_rmse: 0.2001    \n",
      "\n",
      "Epoch 20/150                                                                                                           \n",
      " - 0s - loss: 0.2663 - r_square: 0.7900 - rmse: 0.2663 - val_loss: 0.1942 - val_r_square: 0.8698 - val_rmse: 0.1942    \n",
      "\n",
      "Epoch 21/150                                                                                                           \n",
      " - 0s - loss: 0.2585 - r_square: 0.7982 - rmse: 0.2585 - val_loss: 0.1901 - val_r_square: 0.8694 - val_rmse: 0.1901    \n",
      "\n",
      "Epoch 22/150                                                                                                           \n",
      " - 0s - loss: 0.2646 - r_square: 0.7946 - rmse: 0.2646 - val_loss: 0.1939 - val_r_square: 0.8708 - val_rmse: 0.1939    \n",
      "\n",
      "Epoch 23/150                                                                                                           \n",
      " - 0s - loss: 0.2624 - r_square: 0.8004 - rmse: 0.2624 - val_loss: 0.1960 - val_r_square: 0.8715 - val_rmse: 0.1960    \n",
      "\n",
      "Epoch 24/150                                                                                                           \n",
      " - 0s - loss: 0.2566 - r_square: 0.8069 - rmse: 0.2566 - val_loss: 0.2073 - val_r_square: 0.8687 - val_rmse: 0.2073    \n",
      "\n",
      "Epoch 25/150                                                                                                           \n",
      " - 0s - loss: 0.2569 - r_square: 0.7968 - rmse: 0.2569 - val_loss: 0.1935 - val_r_square: 0.8749 - val_rmse: 0.1935    \n",
      "\n",
      "Epoch 26/150                                                                                                           \n",
      " - 0s - loss: 0.2511 - r_square: 0.8111 - rmse: 0.2511 - val_loss: 0.1980 - val_r_square: 0.8741 - val_rmse: 0.1980    \n",
      "\n",
      "Epoch 27/150                                                                                                           \n",
      " - 0s - loss: 0.2498 - r_square: 0.8075 - rmse: 0.2498 - val_loss: 0.1909 - val_r_square: 0.8767 - val_rmse: 0.1909    \n",
      "\n",
      "Epoch 28/150                                                                                                           \n",
      " - 0s - loss: 0.2452 - r_square: 0.8146 - rmse: 0.2452 - val_loss: 0.1799 - val_r_square: 0.8781 - val_rmse: 0.1799    \n",
      "\n",
      "Epoch 29/150                                                                                                           \n",
      " - 0s - loss: 0.2466 - r_square: 0.8131 - rmse: 0.2466 - val_loss: 0.2065 - val_r_square: 0.8725 - val_rmse: 0.2065    \n",
      "\n",
      "Epoch 30/150                                                                                                           \n",
      " - 0s - loss: 0.2479 - r_square: 0.8082 - rmse: 0.2479 - val_loss: 0.1806 - val_r_square: 0.8800 - val_rmse: 0.1806    \n",
      "\n",
      "Epoch 31/150                                                                                                           \n",
      " - 0s - loss: 0.2419 - r_square: 0.8147 - rmse: 0.2419 - val_loss: 0.1828 - val_r_square: 0.8807 - val_rmse: 0.1828    \n",
      "\n",
      "Epoch 32/150                                                                                                           \n",
      " - 0s - loss: 0.2427 - r_square: 0.8144 - rmse: 0.2427 - val_loss: 0.1904 - val_r_square: 0.8788 - val_rmse: 0.1904    \n",
      "\n",
      "Epoch 33/150                                                                                                           \n",
      " - 0s - loss: 0.2384 - r_square: 0.8256 - rmse: 0.2384 - val_loss: 0.1938 - val_r_square: 0.8775 - val_rmse: 0.1938    \n",
      "\n",
      "Epoch 34/150                                                                                                           \n",
      " - 0s - loss: 0.2366 - r_square: 0.8175 - rmse: 0.2366 - val_loss: 0.1913 - val_r_square: 0.8807 - val_rmse: 0.1913    \n",
      "\n",
      "Epoch 35/150                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2390 - r_square: 0.8195 - rmse: 0.2390 - val_loss: 0.1964 - val_r_square: 0.8780 - val_rmse: 0.1964    \n",
      "\n",
      "Epoch 36/150                                                                                                           \n",
      " - 0s - loss: 0.2357 - r_square: 0.8154 - rmse: 0.2357 - val_loss: 0.1830 - val_r_square: 0.8815 - val_rmse: 0.1830    \n",
      "\n",
      "Epoch 37/150                                                                                                           \n",
      " - 0s - loss: 0.2345 - r_square: 0.8169 - rmse: 0.2345 - val_loss: 0.1934 - val_r_square: 0.8781 - val_rmse: 0.1934    \n",
      "\n",
      "Epoch 38/150                                                                                                           \n",
      " - 0s - loss: 0.2292 - r_square: 0.8191 - rmse: 0.2292 - val_loss: 0.1816 - val_r_square: 0.8794 - val_rmse: 0.1816    \n",
      "\n",
      "Epoch 39/150                                                                                                           \n",
      " - 0s - loss: 0.2328 - r_square: 0.8266 - rmse: 0.2328 - val_loss: 0.1963 - val_r_square: 0.8810 - val_rmse: 0.1963    \n",
      "\n",
      "Epoch 40/150                                                                                                           \n",
      " - 0s - loss: 0.2317 - r_square: 0.8233 - rmse: 0.2317 - val_loss: 0.1746 - val_r_square: 0.8835 - val_rmse: 0.1746    \n",
      "\n",
      "Epoch 41/150                                                                                                           \n",
      " - 0s - loss: 0.2300 - r_square: 0.8299 - rmse: 0.2300 - val_loss: 0.1952 - val_r_square: 0.8810 - val_rmse: 0.1952    \n",
      "\n",
      "Epoch 42/150                                                                                                           \n",
      " - 0s - loss: 0.2298 - r_square: 0.8196 - rmse: 0.2298 - val_loss: 0.1908 - val_r_square: 0.8822 - val_rmse: 0.1908    \n",
      "\n",
      "Epoch 43/150                                                                                                           \n",
      " - 0s - loss: 0.2280 - r_square: 0.8290 - rmse: 0.2280 - val_loss: 0.1867 - val_r_square: 0.8824 - val_rmse: 0.1867    \n",
      "\n",
      "Epoch 44/150                                                                                                           \n",
      " - 0s - loss: 0.2325 - r_square: 0.8200 - rmse: 0.2325 - val_loss: 0.1785 - val_r_square: 0.8855 - val_rmse: 0.1785    \n",
      "\n",
      "Epoch 45/150                                                                                                           \n",
      " - 0s - loss: 0.2278 - r_square: 0.8239 - rmse: 0.2278 - val_loss: 0.1803 - val_r_square: 0.8835 - val_rmse: 0.1803    \n",
      "\n",
      "Epoch 46/150                                                                                                           \n",
      " - 0s - loss: 0.2274 - r_square: 0.8254 - rmse: 0.2274 - val_loss: 0.1883 - val_r_square: 0.8827 - val_rmse: 0.1883    \n",
      "\n",
      "Epoch 47/150                                                                                                           \n",
      " - 0s - loss: 0.2265 - r_square: 0.8228 - rmse: 0.2265 - val_loss: 0.1855 - val_r_square: 0.8804 - val_rmse: 0.1855    \n",
      "\n",
      "Epoch 48/150                                                                                                           \n",
      " - 0s - loss: 0.2248 - r_square: 0.8251 - rmse: 0.2248 - val_loss: 0.1793 - val_r_square: 0.8838 - val_rmse: 0.1793    \n",
      "\n",
      "Epoch 49/150                                                                                                           \n",
      " - 0s - loss: 0.2277 - r_square: 0.8274 - rmse: 0.2277 - val_loss: 0.1859 - val_r_square: 0.8833 - val_rmse: 0.1859    \n",
      "\n",
      "Epoch 50/150                                                                                                           \n",
      " - 0s - loss: 0.2260 - r_square: 0.8301 - rmse: 0.2260 - val_loss: 0.1849 - val_r_square: 0.8848 - val_rmse: 0.1849    \n",
      "\n",
      "Epoch 51/150                                                                                                           \n",
      " - 0s - loss: 0.2249 - r_square: 0.8185 - rmse: 0.2249 - val_loss: 0.1818 - val_r_square: 0.8857 - val_rmse: 0.1818    \n",
      "\n",
      "Epoch 52/150                                                                                                           \n",
      " - 0s - loss: 0.2254 - r_square: 0.8304 - rmse: 0.2254 - val_loss: 0.1989 - val_r_square: 0.8804 - val_rmse: 0.1989    \n",
      "\n",
      "Epoch 53/150                                                                                                           \n",
      " - 0s - loss: 0.2208 - r_square: 0.8307 - rmse: 0.2208 - val_loss: 0.1803 - val_r_square: 0.8865 - val_rmse: 0.1803    \n",
      "\n",
      "Epoch 54/150                                                                                                           \n",
      " - 0s - loss: 0.2213 - r_square: 0.8285 - rmse: 0.2213 - val_loss: 0.1981 - val_r_square: 0.8822 - val_rmse: 0.1981    \n",
      "\n",
      "Epoch 55/150                                                                                                           \n",
      " - 0s - loss: 0.2216 - r_square: 0.8363 - rmse: 0.2216 - val_loss: 0.1870 - val_r_square: 0.8859 - val_rmse: 0.1870    \n",
      "\n",
      "Epoch 56/150                                                                                                           \n",
      " - 0s - loss: 0.2230 - r_square: 0.8317 - rmse: 0.2230 - val_loss: 0.1862 - val_r_square: 0.8844 - val_rmse: 0.1862    \n",
      "\n",
      "Epoch 57/150                                                                                                           \n",
      " - 0s - loss: 0.2239 - r_square: 0.8324 - rmse: 0.2239 - val_loss: 0.1846 - val_r_square: 0.8860 - val_rmse: 0.1846    \n",
      "\n",
      "Epoch 58/150                                                                                                           \n",
      " - 0s - loss: 0.2223 - r_square: 0.8330 - rmse: 0.2223 - val_loss: 0.1744 - val_r_square: 0.8885 - val_rmse: 0.1744    \n",
      "\n",
      "Epoch 59/150                                                                                                           \n",
      " - 0s - loss: 0.2236 - r_square: 0.8293 - rmse: 0.2236 - val_loss: 0.1944 - val_r_square: 0.8826 - val_rmse: 0.1944    \n",
      "\n",
      "Epoch 60/150                                                                                                           \n",
      " - 0s - loss: 0.2187 - r_square: 0.8374 - rmse: 0.2187 - val_loss: 0.1707 - val_r_square: 0.8891 - val_rmse: 0.1707    \n",
      "\n",
      "Epoch 61/150                                                                                                           \n",
      " - 0s - loss: 0.2218 - r_square: 0.8299 - rmse: 0.2218 - val_loss: 0.1880 - val_r_square: 0.8857 - val_rmse: 0.1880    \n",
      "\n",
      "Epoch 62/150                                                                                                           \n",
      " - 0s - loss: 0.2199 - r_square: 0.8240 - rmse: 0.2199 - val_loss: 0.1798 - val_r_square: 0.8855 - val_rmse: 0.1798    \n",
      "\n",
      "Epoch 63/150                                                                                                           \n",
      " - 0s - loss: 0.2188 - r_square: 0.8348 - rmse: 0.2188 - val_loss: 0.1781 - val_r_square: 0.8873 - val_rmse: 0.1781    \n",
      "\n",
      "Epoch 64/150                                                                                                           \n",
      " - 0s - loss: 0.2201 - r_square: 0.8332 - rmse: 0.2201 - val_loss: 0.1844 - val_r_square: 0.8865 - val_rmse: 0.1844    \n",
      "\n",
      "Epoch 65/150                                                                                                           \n",
      " - 0s - loss: 0.2240 - r_square: 0.8328 - rmse: 0.2240 - val_loss: 0.1825 - val_r_square: 0.8882 - val_rmse: 0.1825    \n",
      "\n",
      "Epoch 66/150                                                                                                           \n",
      " - 0s - loss: 0.2176 - r_square: 0.8370 - rmse: 0.2176 - val_loss: 0.1793 - val_r_square: 0.8869 - val_rmse: 0.1793    \n",
      "\n",
      "Epoch 67/150                                                                                                           \n",
      " - 0s - loss: 0.2176 - r_square: 0.8369 - rmse: 0.2176 - val_loss: 0.1738 - val_r_square: 0.8892 - val_rmse: 0.1738    \n",
      "\n",
      "Epoch 68/150                                                                                                           \n",
      " - 0s - loss: 0.2205 - r_square: 0.8392 - rmse: 0.2205 - val_loss: 0.1854 - val_r_square: 0.8873 - val_rmse: 0.1854    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150                                                                                                           \n",
      " - 0s - loss: 0.2192 - r_square: 0.8414 - rmse: 0.2192 - val_loss: 0.1775 - val_r_square: 0.8888 - val_rmse: 0.1775    \n",
      "\n",
      "Epoch 70/150                                                                                                           \n",
      " - 0s - loss: 0.2174 - r_square: 0.8395 - rmse: 0.2174 - val_loss: 0.1830 - val_r_square: 0.8862 - val_rmse: 0.1830    \n",
      "\n",
      "Epoch 71/150                                                                                                           \n",
      " - 0s - loss: 0.2172 - r_square: 0.8357 - rmse: 0.2172 - val_loss: 0.1839 - val_r_square: 0.8884 - val_rmse: 0.1839    \n",
      "\n",
      "Epoch 72/150                                                                                                           \n",
      " - 0s - loss: 0.2161 - r_square: 0.8393 - rmse: 0.2161 - val_loss: 0.1757 - val_r_square: 0.8894 - val_rmse: 0.1757    \n",
      "\n",
      "Epoch 73/150                                                                                                           \n",
      " - 0s - loss: 0.2186 - r_square: 0.8337 - rmse: 0.2186 - val_loss: 0.1784 - val_r_square: 0.8879 - val_rmse: 0.1784    \n",
      "\n",
      "Epoch 74/150                                                                                                           \n",
      " - 0s - loss: 0.2154 - r_square: 0.8346 - rmse: 0.2154 - val_loss: 0.1798 - val_r_square: 0.8883 - val_rmse: 0.1798    \n",
      "\n",
      "Epoch 75/150                                                                                                           \n",
      " - 0s - loss: 0.2171 - r_square: 0.8350 - rmse: 0.2171 - val_loss: 0.1848 - val_r_square: 0.8885 - val_rmse: 0.1848    \n",
      "\n",
      "Epoch 76/150                                                                                                           \n",
      " - 0s - loss: 0.2170 - r_square: 0.8491 - rmse: 0.2170 - val_loss: 0.1817 - val_r_square: 0.8889 - val_rmse: 0.1817    \n",
      "\n",
      "Epoch 77/150                                                                                                           \n",
      " - 0s - loss: 0.2118 - r_square: 0.8430 - rmse: 0.2118 - val_loss: 0.1897 - val_r_square: 0.8832 - val_rmse: 0.1897    \n",
      "\n",
      "Epoch 78/150                                                                                                           \n",
      " - 0s - loss: 0.2168 - r_square: 0.8392 - rmse: 0.2168 - val_loss: 0.1641 - val_r_square: 0.8919 - val_rmse: 0.1641    \n",
      "\n",
      "Epoch 79/150                                                                                                           \n",
      " - 0s - loss: 0.2130 - r_square: 0.8391 - rmse: 0.2130 - val_loss: 0.1855 - val_r_square: 0.8862 - val_rmse: 0.1855    \n",
      "\n",
      "Epoch 80/150                                                                                                           \n",
      " - 0s - loss: 0.2084 - r_square: 0.8472 - rmse: 0.2084 - val_loss: 0.1767 - val_r_square: 0.8913 - val_rmse: 0.1767    \n",
      "\n",
      "Epoch 81/150                                                                                                           \n",
      " - 0s - loss: 0.2106 - r_square: 0.8419 - rmse: 0.2106 - val_loss: 0.1689 - val_r_square: 0.8926 - val_rmse: 0.1689    \n",
      "\n",
      "Epoch 82/150                                                                                                           \n",
      " - 0s - loss: 0.2134 - r_square: 0.8413 - rmse: 0.2134 - val_loss: 0.1773 - val_r_square: 0.8880 - val_rmse: 0.1773    \n",
      "\n",
      "Epoch 83/150                                                                                                           \n",
      " - 0s - loss: 0.2103 - r_square: 0.8428 - rmse: 0.2103 - val_loss: 0.1658 - val_r_square: 0.8924 - val_rmse: 0.1658    \n",
      "\n",
      "Epoch 84/150                                                                                                           \n",
      " - 0s - loss: 0.2151 - r_square: 0.8325 - rmse: 0.2151 - val_loss: 0.1791 - val_r_square: 0.8881 - val_rmse: 0.1791    \n",
      "\n",
      "Epoch 85/150                                                                                                           \n",
      " - 0s - loss: 0.2146 - r_square: 0.8396 - rmse: 0.2146 - val_loss: 0.1759 - val_r_square: 0.8918 - val_rmse: 0.1759    \n",
      "\n",
      "Epoch 86/150                                                                                                           \n",
      " - 0s - loss: 0.2114 - r_square: 0.8380 - rmse: 0.2114 - val_loss: 0.1726 - val_r_square: 0.8929 - val_rmse: 0.1726    \n",
      "\n",
      "Epoch 87/150                                                                                                           \n",
      " - 0s - loss: 0.2123 - r_square: 0.8422 - rmse: 0.2123 - val_loss: 0.1770 - val_r_square: 0.8913 - val_rmse: 0.1770    \n",
      "\n",
      "Epoch 88/150                                                                                                           \n",
      " - 0s - loss: 0.2105 - r_square: 0.8410 - rmse: 0.2105 - val_loss: 0.1669 - val_r_square: 0.8929 - val_rmse: 0.1669    \n",
      "\n",
      "Epoch 89/150                                                                                                           \n",
      " - 0s - loss: 0.2111 - r_square: 0.8382 - rmse: 0.2111 - val_loss: 0.1869 - val_r_square: 0.8889 - val_rmse: 0.1869    \n",
      "\n",
      "Epoch 90/150                                                                                                           \n",
      " - 0s - loss: 0.2090 - r_square: 0.8490 - rmse: 0.2090 - val_loss: 0.1710 - val_r_square: 0.8934 - val_rmse: 0.1710    \n",
      "\n",
      "Epoch 91/150                                                                                                           \n",
      " - 0s - loss: 0.2074 - r_square: 0.8503 - rmse: 0.2074 - val_loss: 0.1676 - val_r_square: 0.8928 - val_rmse: 0.1676    \n",
      "\n",
      "Epoch 92/150                                                                                                           \n",
      " - 0s - loss: 0.2066 - r_square: 0.8477 - rmse: 0.2066 - val_loss: 0.1749 - val_r_square: 0.8934 - val_rmse: 0.1749    \n",
      "\n",
      "Epoch 93/150                                                                                                           \n",
      " - 0s - loss: 0.2101 - r_square: 0.8436 - rmse: 0.2101 - val_loss: 0.1691 - val_r_square: 0.8940 - val_rmse: 0.1691    \n",
      "\n",
      "Epoch 94/150                                                                                                           \n",
      " - 0s - loss: 0.2119 - r_square: 0.8428 - rmse: 0.2119 - val_loss: 0.1789 - val_r_square: 0.8911 - val_rmse: 0.1789    \n",
      "\n",
      "Epoch 95/150                                                                                                           \n",
      " - 0s - loss: 0.2093 - r_square: 0.8408 - rmse: 0.2093 - val_loss: 0.1750 - val_r_square: 0.8936 - val_rmse: 0.1750    \n",
      "\n",
      "Epoch 96/150                                                                                                           \n",
      " - 0s - loss: 0.2087 - r_square: 0.8417 - rmse: 0.2087 - val_loss: 0.1765 - val_r_square: 0.8934 - val_rmse: 0.1765    \n",
      "\n",
      "Epoch 97/150                                                                                                           \n",
      " - 0s - loss: 0.2100 - r_square: 0.8441 - rmse: 0.2100 - val_loss: 0.1663 - val_r_square: 0.8949 - val_rmse: 0.1663    \n",
      "\n",
      "Epoch 98/150                                                                                                           \n",
      " - 0s - loss: 0.2089 - r_square: 0.8402 - rmse: 0.2089 - val_loss: 0.1684 - val_r_square: 0.8938 - val_rmse: 0.1684    \n",
      "\n",
      "Epoch 99/150                                                                                                           \n",
      " - 0s - loss: 0.2057 - r_square: 0.8466 - rmse: 0.2057 - val_loss: 0.1773 - val_r_square: 0.8924 - val_rmse: 0.1773    \n",
      "\n",
      "Epoch 100/150                                                                                                          \n",
      " - 0s - loss: 0.2116 - r_square: 0.8442 - rmse: 0.2116 - val_loss: 0.1635 - val_r_square: 0.8954 - val_rmse: 0.1635    \n",
      "\n",
      "Epoch 101/150                                                                                                          \n",
      " - 0s - loss: 0.2068 - r_square: 0.8456 - rmse: 0.2068 - val_loss: 0.1782 - val_r_square: 0.8905 - val_rmse: 0.1782    \n",
      "\n",
      "Epoch 102/150                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2091 - r_square: 0.8475 - rmse: 0.2091 - val_loss: 0.1617 - val_r_square: 0.8939 - val_rmse: 0.1617    \n",
      "\n",
      "Epoch 103/150                                                                                                          \n",
      " - 0s - loss: 0.2097 - r_square: 0.8477 - rmse: 0.2097 - val_loss: 0.1710 - val_r_square: 0.8917 - val_rmse: 0.1710    \n",
      "\n",
      "Epoch 104/150                                                                                                          \n",
      " - 0s - loss: 0.2056 - r_square: 0.8509 - rmse: 0.2056 - val_loss: 0.1822 - val_r_square: 0.8921 - val_rmse: 0.1822    \n",
      "\n",
      "Epoch 105/150                                                                                                          \n",
      " - 0s - loss: 0.2088 - r_square: 0.8454 - rmse: 0.2088 - val_loss: 0.1797 - val_r_square: 0.8912 - val_rmse: 0.1797    \n",
      "\n",
      "Epoch 106/150                                                                                                          \n",
      " - 0s - loss: 0.2060 - r_square: 0.8471 - rmse: 0.2060 - val_loss: 0.1792 - val_r_square: 0.8933 - val_rmse: 0.1792    \n",
      "\n",
      "Epoch 107/150                                                                                                          \n",
      " - 0s - loss: 0.2042 - r_square: 0.8429 - rmse: 0.2042 - val_loss: 0.1696 - val_r_square: 0.8931 - val_rmse: 0.1696    \n",
      "\n",
      "Epoch 108/150                                                                                                          \n",
      " - 0s - loss: 0.2055 - r_square: 0.8451 - rmse: 0.2055 - val_loss: 0.1675 - val_r_square: 0.8963 - val_rmse: 0.1675    \n",
      "\n",
      "Epoch 109/150                                                                                                          \n",
      " - 0s - loss: 0.2018 - r_square: 0.8508 - rmse: 0.2018 - val_loss: 0.1723 - val_r_square: 0.8953 - val_rmse: 0.1723    \n",
      "\n",
      "Epoch 110/150                                                                                                          \n",
      " - 0s - loss: 0.2055 - r_square: 0.8452 - rmse: 0.2055 - val_loss: 0.1748 - val_r_square: 0.8927 - val_rmse: 0.1748    \n",
      "\n",
      "Epoch 111/150                                                                                                          \n",
      " - 0s - loss: 0.2029 - r_square: 0.8488 - rmse: 0.2029 - val_loss: 0.1720 - val_r_square: 0.8948 - val_rmse: 0.1720    \n",
      "\n",
      "Epoch 112/150                                                                                                          \n",
      " - 0s - loss: 0.2062 - r_square: 0.8405 - rmse: 0.2062 - val_loss: 0.1658 - val_r_square: 0.8959 - val_rmse: 0.1658    \n",
      "\n",
      "Epoch 113/150                                                                                                          \n",
      " - 0s - loss: 0.2053 - r_square: 0.8440 - rmse: 0.2053 - val_loss: 0.1688 - val_r_square: 0.8965 - val_rmse: 0.1688    \n",
      "\n",
      "Epoch 114/150                                                                                                          \n",
      " - 0s - loss: 0.2023 - r_square: 0.8463 - rmse: 0.2023 - val_loss: 0.1642 - val_r_square: 0.8942 - val_rmse: 0.1642    \n",
      "\n",
      "Epoch 115/150                                                                                                          \n",
      " - 0s - loss: 0.2077 - r_square: 0.8401 - rmse: 0.2077 - val_loss: 0.1814 - val_r_square: 0.8911 - val_rmse: 0.1814    \n",
      "\n",
      "Epoch 116/150                                                                                                          \n",
      " - 0s - loss: 0.2068 - r_square: 0.8443 - rmse: 0.2068 - val_loss: 0.1625 - val_r_square: 0.8984 - val_rmse: 0.1625    \n",
      "\n",
      "Epoch 117/150                                                                                                          \n",
      " - 0s - loss: 0.2053 - r_square: 0.8464 - rmse: 0.2053 - val_loss: 0.1639 - val_r_square: 0.8964 - val_rmse: 0.1639    \n",
      "\n",
      "Epoch 118/150                                                                                                          \n",
      " - 0s - loss: 0.2039 - r_square: 0.8369 - rmse: 0.2039 - val_loss: 0.1729 - val_r_square: 0.8953 - val_rmse: 0.1729    \n",
      "\n",
      "Epoch 119/150                                                                                                          \n",
      " - 0s - loss: 0.2017 - r_square: 0.8504 - rmse: 0.2017 - val_loss: 0.1689 - val_r_square: 0.8956 - val_rmse: 0.1689    \n",
      "\n",
      "Epoch 120/150                                                                                                          \n",
      " - 0s - loss: 0.2034 - r_square: 0.8473 - rmse: 0.2034 - val_loss: 0.1811 - val_r_square: 0.8933 - val_rmse: 0.1811    \n",
      "\n",
      "Epoch 121/150                                                                                                          \n",
      " - 0s - loss: 0.2046 - r_square: 0.8421 - rmse: 0.2046 - val_loss: 0.1632 - val_r_square: 0.8962 - val_rmse: 0.1632    \n",
      "\n",
      "Epoch 122/150                                                                                                          \n",
      " - 0s - loss: 0.2024 - r_square: 0.8470 - rmse: 0.2024 - val_loss: 0.1750 - val_r_square: 0.8958 - val_rmse: 0.1750    \n",
      "\n",
      "Epoch 123/150                                                                                                          \n",
      " - 0s - loss: 0.2033 - r_square: 0.8491 - rmse: 0.2033 - val_loss: 0.1756 - val_r_square: 0.8957 - val_rmse: 0.1756    \n",
      "\n",
      "Epoch 124/150                                                                                                          \n",
      " - 0s - loss: 0.2022 - r_square: 0.8464 - rmse: 0.2022 - val_loss: 0.1736 - val_r_square: 0.8960 - val_rmse: 0.1736    \n",
      "\n",
      "Epoch 125/150                                                                                                          \n",
      " - 0s - loss: 0.2043 - r_square: 0.8554 - rmse: 0.2043 - val_loss: 0.1645 - val_r_square: 0.8968 - val_rmse: 0.1645    \n",
      "\n",
      "Epoch 126/150                                                                                                          \n",
      " - 0s - loss: 0.2008 - r_square: 0.8559 - rmse: 0.2008 - val_loss: 0.1690 - val_r_square: 0.8965 - val_rmse: 0.1690    \n",
      "\n",
      "Epoch 127/150                                                                                                          \n",
      " - 0s - loss: 0.2054 - r_square: 0.8440 - rmse: 0.2054 - val_loss: 0.1768 - val_r_square: 0.8968 - val_rmse: 0.1768    \n",
      "\n",
      "Epoch 128/150                                                                                                          \n",
      " - 0s - loss: 0.2038 - r_square: 0.8444 - rmse: 0.2038 - val_loss: 0.1717 - val_r_square: 0.8992 - val_rmse: 0.1717    \n",
      "\n",
      "Epoch 129/150                                                                                                          \n",
      " - 0s - loss: 0.2077 - r_square: 0.8465 - rmse: 0.2077 - val_loss: 0.1673 - val_r_square: 0.8974 - val_rmse: 0.1673    \n",
      "\n",
      "Epoch 130/150                                                                                                          \n",
      " - 0s - loss: 0.2051 - r_square: 0.8437 - rmse: 0.2051 - val_loss: 0.1681 - val_r_square: 0.9003 - val_rmse: 0.1681    \n",
      "\n",
      "Epoch 131/150                                                                                                          \n",
      " - 0s - loss: 0.2021 - r_square: 0.8431 - rmse: 0.2021 - val_loss: 0.1571 - val_r_square: 0.8989 - val_rmse: 0.1571    \n",
      "\n",
      "Epoch 132/150                                                                                                          \n",
      " - 0s - loss: 0.2039 - r_square: 0.8476 - rmse: 0.2039 - val_loss: 0.1757 - val_r_square: 0.8955 - val_rmse: 0.1757    \n",
      "\n",
      "Epoch 133/150                                                                                                          \n",
      " - 0s - loss: 0.2021 - r_square: 0.8450 - rmse: 0.2021 - val_loss: 0.1723 - val_r_square: 0.8988 - val_rmse: 0.1723    \n",
      "\n",
      "Epoch 134/150                                                                                                          \n",
      " - 0s - loss: 0.1992 - r_square: 0.8551 - rmse: 0.1992 - val_loss: 0.1770 - val_r_square: 0.8938 - val_rmse: 0.1770    \n",
      "\n",
      "Epoch 135/150                                                                                                          \n",
      " - 0s - loss: 0.2022 - r_square: 0.8548 - rmse: 0.2022 - val_loss: 0.1740 - val_r_square: 0.8970 - val_rmse: 0.1740    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150                                                                                                          \n",
      " - 0s - loss: 0.2028 - r_square: 0.8490 - rmse: 0.2028 - val_loss: 0.1589 - val_r_square: 0.8978 - val_rmse: 0.1589    \n",
      "\n",
      "Epoch 137/150                                                                                                          \n",
      " - 0s - loss: 0.1997 - r_square: 0.8552 - rmse: 0.1997 - val_loss: 0.1660 - val_r_square: 0.8981 - val_rmse: 0.1660    \n",
      "\n",
      "Epoch 138/150                                                                                                          \n",
      " - 0s - loss: 0.1960 - r_square: 0.8543 - rmse: 0.1960 - val_loss: 0.1666 - val_r_square: 0.8981 - val_rmse: 0.1666    \n",
      "\n",
      "Epoch 139/150                                                                                                          \n",
      " - 0s - loss: 0.2002 - r_square: 0.8555 - rmse: 0.2002 - val_loss: 0.1694 - val_r_square: 0.8987 - val_rmse: 0.1694    \n",
      "\n",
      "Epoch 140/150                                                                                                          \n",
      " - 0s - loss: 0.2030 - r_square: 0.8523 - rmse: 0.2030 - val_loss: 0.1644 - val_r_square: 0.8993 - val_rmse: 0.1644    \n",
      "\n",
      "Epoch 141/150                                                                                                          \n",
      " - 0s - loss: 0.2045 - r_square: 0.8458 - rmse: 0.2045 - val_loss: 0.1657 - val_r_square: 0.8999 - val_rmse: 0.1657    \n",
      "\n",
      "Epoch 142/150                                                                                                          \n",
      " - 0s - loss: 0.2036 - r_square: 0.8528 - rmse: 0.2036 - val_loss: 0.1626 - val_r_square: 0.9006 - val_rmse: 0.1626    \n",
      "\n",
      "Epoch 143/150                                                                                                          \n",
      " - 0s - loss: 0.2035 - r_square: 0.8450 - rmse: 0.2035 - val_loss: 0.1800 - val_r_square: 0.8938 - val_rmse: 0.1800    \n",
      "\n",
      "Epoch 144/150                                                                                                          \n",
      " - 0s - loss: 0.1990 - r_square: 0.8499 - rmse: 0.1990 - val_loss: 0.1697 - val_r_square: 0.8953 - val_rmse: 0.1697    \n",
      "\n",
      "Epoch 145/150                                                                                                          \n",
      " - 0s - loss: 0.1983 - r_square: 0.8527 - rmse: 0.1983 - val_loss: 0.1691 - val_r_square: 0.8977 - val_rmse: 0.1691    \n",
      "\n",
      "Epoch 146/150                                                                                                          \n",
      " - 0s - loss: 0.1984 - r_square: 0.8533 - rmse: 0.1984 - val_loss: 0.1712 - val_r_square: 0.8973 - val_rmse: 0.1712    \n",
      "\n",
      "Epoch 147/150                                                                                                          \n",
      " - 0s - loss: 0.1963 - r_square: 0.8545 - rmse: 0.1963 - val_loss: 0.1641 - val_r_square: 0.8973 - val_rmse: 0.1641    \n",
      "\n",
      "Epoch 148/150                                                                                                          \n",
      " - 0s - loss: 0.2038 - r_square: 0.8495 - rmse: 0.2038 - val_loss: 0.1651 - val_r_square: 0.9000 - val_rmse: 0.1651    \n",
      "\n",
      "Epoch 149/150                                                                                                          \n",
      " - 0s - loss: 0.1978 - r_square: 0.8475 - rmse: 0.1978 - val_loss: 0.1603 - val_r_square: 0.9024 - val_rmse: 0.1603    \n",
      "\n",
      "Epoch 150/150                                                                                                          \n",
      " - 0s - loss: 0.1980 - r_square: 0.8556 - rmse: 0.1980 - val_loss: 0.1687 - val_r_square: 0.9003 - val_rmse: 0.1687    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.15714073896140796                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_2\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_4 (Dense)              (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_3 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_5 (Dense)              (None, 200)               20200                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_4 (Dropout)          (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_6 (Dense)              (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 21,101                                                                                                   \n",
      "Trainable params: 21,101                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 1s - loss: 0.5811 - r_square: 0.3945 - rmse: 0.5811 - val_loss: 0.3848 - val_r_square: 0.6776 - val_rmse: 0.3848    \n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.4478 - r_square: 0.5836 - rmse: 0.4478 - val_loss: 0.3010 - val_r_square: 0.7671 - val_rmse: 0.3010    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.3933 - r_square: 0.6554 - rmse: 0.3933 - val_loss: 0.2870 - val_r_square: 0.7878 - val_rmse: 0.2870    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.3663 - r_square: 0.7006 - rmse: 0.3663 - val_loss: 0.2521 - val_r_square: 0.8131 - val_rmse: 0.2521    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.3367 - r_square: 0.7183 - rmse: 0.3367 - val_loss: 0.2433 - val_r_square: 0.8233 - val_rmse: 0.2433    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.3220 - r_square: 0.7203 - rmse: 0.3220 - val_loss: 0.2486 - val_r_square: 0.8282 - val_rmse: 0.2486    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.3205 - r_square: 0.7451 - rmse: 0.3205 - val_loss: 0.2355 - val_r_square: 0.8357 - val_rmse: 0.2355    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.3074 - r_square: 0.7493 - rmse: 0.3074 - val_loss: 0.2245 - val_r_square: 0.8401 - val_rmse: 0.2245    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.2970 - r_square: 0.7745 - rmse: 0.2970 - val_loss: 0.2247 - val_r_square: 0.8425 - val_rmse: 0.2247    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.2907 - r_square: 0.7800 - rmse: 0.2907 - val_loss: 0.2326 - val_r_square: 0.8479 - val_rmse: 0.2326    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.2877 - r_square: 0.7751 - rmse: 0.2877 - val_loss: 0.2295 - val_r_square: 0.8482 - val_rmse: 0.2295    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.2822 - r_square: 0.7801 - rmse: 0.2822 - val_loss: 0.2172 - val_r_square: 0.8569 - val_rmse: 0.2172    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.2760 - r_square: 0.7922 - rmse: 0.2760 - val_loss: 0.2048 - val_r_square: 0.8613 - val_rmse: 0.2048    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.2682 - r_square: 0.8018 - rmse: 0.2682 - val_loss: 0.2240 - val_r_square: 0.8558 - val_rmse: 0.2240    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.2711 - r_square: 0.7934 - rmse: 0.2711 - val_loss: 0.2223 - val_r_square: 0.8562 - val_rmse: 0.2223    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.2640 - r_square: 0.8056 - rmse: 0.2640 - val_loss: 0.2119 - val_r_square: 0.8638 - val_rmse: 0.2119    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.2572 - r_square: 0.8051 - rmse: 0.2572 - val_loss: 0.2152 - val_r_square: 0.8641 - val_rmse: 0.2152    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.2590 - r_square: 0.8081 - rmse: 0.2590 - val_loss: 0.2219 - val_r_square: 0.8557 - val_rmse: 0.2219    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.2592 - r_square: 0.8022 - rmse: 0.2592 - val_loss: 0.2276 - val_r_square: 0.8577 - val_rmse: 0.2276    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.2517 - r_square: 0.8191 - rmse: 0.2517 - val_loss: 0.2208 - val_r_square: 0.8611 - val_rmse: 0.2208    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.2598 - r_square: 0.8000 - rmse: 0.2598 - val_loss: 0.2178 - val_r_square: 0.8630 - val_rmse: 0.2178    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.2483 - r_square: 0.8148 - rmse: 0.2483 - val_loss: 0.1989 - val_r_square: 0.8714 - val_rmse: 0.1989    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.2539 - r_square: 0.8162 - rmse: 0.2539 - val_loss: 0.2127 - val_r_square: 0.8671 - val_rmse: 0.2127    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.2472 - r_square: 0.8190 - rmse: 0.2472 - val_loss: 0.2207 - val_r_square: 0.8623 - val_rmse: 0.2207    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.2474 - r_square: 0.8141 - rmse: 0.2474 - val_loss: 0.2066 - val_r_square: 0.8695 - val_rmse: 0.2066    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.2415 - r_square: 0.8239 - rmse: 0.2415 - val_loss: 0.1997 - val_r_square: 0.8740 - val_rmse: 0.1997    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.2415 - r_square: 0.7991 - rmse: 0.2415 - val_loss: 0.1928 - val_r_square: 0.8730 - val_rmse: 0.1928    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.2380 - r_square: 0.8333 - rmse: 0.2380 - val_loss: 0.1905 - val_r_square: 0.8748 - val_rmse: 0.1905    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n",
      " - 0s - loss: 0.2393 - r_square: 0.8255 - rmse: 0.2393 - val_loss: 0.2159 - val_r_square: 0.8688 - val_rmse: 0.2159    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.2411 - r_square: 0.8230 - rmse: 0.2411 - val_loss: 0.2005 - val_r_square: 0.8717 - val_rmse: 0.2005    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.2401 - r_square: 0.8217 - rmse: 0.2401 - val_loss: 0.2121 - val_r_square: 0.8694 - val_rmse: 0.2121    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.2412 - r_square: 0.8164 - rmse: 0.2412 - val_loss: 0.1836 - val_r_square: 0.8808 - val_rmse: 0.1836    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.2358 - r_square: 0.8298 - rmse: 0.2358 - val_loss: 0.1977 - val_r_square: 0.8745 - val_rmse: 0.1977    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.2327 - r_square: 0.8369 - rmse: 0.2327 - val_loss: 0.1883 - val_r_square: 0.8782 - val_rmse: 0.1883    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.2339 - r_square: 0.8408 - rmse: 0.2339 - val_loss: 0.1945 - val_r_square: 0.8778 - val_rmse: 0.1945    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.2315 - r_square: 0.8389 - rmse: 0.2315 - val_loss: 0.1997 - val_r_square: 0.8771 - val_rmse: 0.1997    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.2303 - r_square: 0.8319 - rmse: 0.2303 - val_loss: 0.2084 - val_r_square: 0.8738 - val_rmse: 0.2084    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.2310 - r_square: 0.8399 - rmse: 0.2310 - val_loss: 0.1981 - val_r_square: 0.8751 - val_rmse: 0.1981    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.2317 - r_square: 0.8306 - rmse: 0.2317 - val_loss: 0.2087 - val_r_square: 0.8736 - val_rmse: 0.2087    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.2340 - r_square: 0.8318 - rmse: 0.2340 - val_loss: 0.2019 - val_r_square: 0.8709 - val_rmse: 0.2019    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.2309 - r_square: 0.8291 - rmse: 0.2309 - val_loss: 0.2001 - val_r_square: 0.8749 - val_rmse: 0.2001    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2254 - r_square: 0.8394 - rmse: 0.2254 - val_loss: 0.2017 - val_r_square: 0.8761 - val_rmse: 0.2017    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.2249 - r_square: 0.8382 - rmse: 0.2249 - val_loss: 0.2145 - val_r_square: 0.8709 - val_rmse: 0.2145    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.2321 - r_square: 0.8327 - rmse: 0.2321 - val_loss: 0.2029 - val_r_square: 0.8751 - val_rmse: 0.2029    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.2268 - r_square: 0.8432 - rmse: 0.2268 - val_loss: 0.1967 - val_r_square: 0.8752 - val_rmse: 0.1967    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.2284 - r_square: 0.8374 - rmse: 0.2284 - val_loss: 0.1909 - val_r_square: 0.8792 - val_rmse: 0.1909    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.2288 - r_square: 0.8161 - rmse: 0.2288 - val_loss: 0.1853 - val_r_square: 0.8793 - val_rmse: 0.1853    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.2259 - r_square: 0.8386 - rmse: 0.2259 - val_loss: 0.1877 - val_r_square: 0.8776 - val_rmse: 0.1877    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.2252 - r_square: 0.8332 - rmse: 0.2252 - val_loss: 0.1917 - val_r_square: 0.8825 - val_rmse: 0.1917    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.2210 - r_square: 0.8373 - rmse: 0.2210 - val_loss: 0.1878 - val_r_square: 0.8800 - val_rmse: 0.1878    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.1836419552787359                                                                                                     \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_3\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_7 (Dense)              (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_5 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_8 (Dense)              (None, 300)               30300                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_6 (Dropout)          (None, 300)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_9 (Dense)              (None, 1)                 301                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 31,301                                                                                                   \n",
      "Trainable params: 31,301                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 1s - loss: 0.5274 - r_square: 0.4670 - rmse: 0.5274 - val_loss: 0.3523 - val_r_square: 0.7248 - val_rmse: 0.3523    \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.3983 - r_square: 0.6622 - rmse: 0.3983 - val_loss: 0.2849 - val_r_square: 0.7830 - val_rmse: 0.2849    \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.3691 - r_square: 0.6813 - rmse: 0.3691 - val_loss: 0.2579 - val_r_square: 0.8009 - val_rmse: 0.2579    \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.3468 - r_square: 0.7185 - rmse: 0.3468 - val_loss: 0.2577 - val_r_square: 0.8069 - val_rmse: 0.2577    \n",
      "\n",
      "Epoch 5/100                                                                                                            \n",
      " - 0s - loss: 0.3303 - r_square: 0.7409 - rmse: 0.3303 - val_loss: 0.2546 - val_r_square: 0.8186 - val_rmse: 0.2546    \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.3213 - r_square: 0.7406 - rmse: 0.3213 - val_loss: 0.2491 - val_r_square: 0.8261 - val_rmse: 0.2491    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.3070 - r_square: 0.7570 - rmse: 0.3070 - val_loss: 0.2820 - val_r_square: 0.8152 - val_rmse: 0.2820    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.2995 - r_square: 0.7702 - rmse: 0.2995 - val_loss: 0.2586 - val_r_square: 0.8285 - val_rmse: 0.2586    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.2919 - r_square: 0.7633 - rmse: 0.2919 - val_loss: 0.2454 - val_r_square: 0.8389 - val_rmse: 0.2454    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.2845 - r_square: 0.7826 - rmse: 0.2845 - val_loss: 0.2554 - val_r_square: 0.8380 - val_rmse: 0.2554    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.2741 - r_square: 0.7925 - rmse: 0.2741 - val_loss: 0.2535 - val_r_square: 0.8387 - val_rmse: 0.2535    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.2702 - r_square: 0.7908 - rmse: 0.2702 - val_loss: 0.2446 - val_r_square: 0.8501 - val_rmse: 0.2446    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.2567 - r_square: 0.8085 - rmse: 0.2567 - val_loss: 0.2464 - val_r_square: 0.8502 - val_rmse: 0.2464    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.2560 - r_square: 0.8077 - rmse: 0.2560 - val_loss: 0.2383 - val_r_square: 0.8534 - val_rmse: 0.2383    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2507 - r_square: 0.8172 - rmse: 0.2507 - val_loss: 0.2559 - val_r_square: 0.8381 - val_rmse: 0.2559    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.2436 - r_square: 0.8251 - rmse: 0.2436 - val_loss: 0.2431 - val_r_square: 0.8500 - val_rmse: 0.2431    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.2424 - r_square: 0.8168 - rmse: 0.2424 - val_loss: 0.2413 - val_r_square: 0.8526 - val_rmse: 0.2413    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.2357 - r_square: 0.8154 - rmse: 0.2357 - val_loss: 0.2609 - val_r_square: 0.8420 - val_rmse: 0.2609    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.2370 - r_square: 0.8273 - rmse: 0.2370 - val_loss: 0.2557 - val_r_square: 0.8404 - val_rmse: 0.2557    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.2334 - r_square: 0.8273 - rmse: 0.2334 - val_loss: 0.2681 - val_r_square: 0.8391 - val_rmse: 0.2681    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.2293 - r_square: 0.8392 - rmse: 0.2293 - val_loss: 0.2420 - val_r_square: 0.8506 - val_rmse: 0.2420    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.2318 - r_square: 0.8297 - rmse: 0.2318 - val_loss: 0.2580 - val_r_square: 0.8451 - val_rmse: 0.2580    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.2321 - r_square: 0.8283 - rmse: 0.2321 - val_loss: 0.2467 - val_r_square: 0.8530 - val_rmse: 0.2467    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.2237 - r_square: 0.8369 - rmse: 0.2237 - val_loss: 0.2513 - val_r_square: 0.8485 - val_rmse: 0.2513    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.2225 - r_square: 0.8250 - rmse: 0.2225 - val_loss: 0.2731 - val_r_square: 0.8401 - val_rmse: 0.2731    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.2239 - r_square: 0.8385 - rmse: 0.2239 - val_loss: 0.2557 - val_r_square: 0.8478 - val_rmse: 0.2557    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.2209 - r_square: 0.8398 - rmse: 0.2209 - val_loss: 0.2546 - val_r_square: 0.8444 - val_rmse: 0.2546    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.2172 - r_square: 0.8412 - rmse: 0.2172 - val_loss: 0.2688 - val_r_square: 0.8367 - val_rmse: 0.2688    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.2183 - r_square: 0.8406 - rmse: 0.2183 - val_loss: 0.2587 - val_r_square: 0.8453 - val_rmse: 0.2587    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.2153 - r_square: 0.8461 - rmse: 0.2153 - val_loss: 0.2486 - val_r_square: 0.8517 - val_rmse: 0.2486    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.2166 - r_square: 0.8431 - rmse: 0.2166 - val_loss: 0.2561 - val_r_square: 0.8429 - val_rmse: 0.2561    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.2183 - r_square: 0.8415 - rmse: 0.2183 - val_loss: 0.2788 - val_r_square: 0.8279 - val_rmse: 0.2788    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.2149 - r_square: 0.8371 - rmse: 0.2149 - val_loss: 0.2594 - val_r_square: 0.8402 - val_rmse: 0.2594    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.2150 - r_square: 0.8435 - rmse: 0.2150 - val_loss: 0.2692 - val_r_square: 0.8359 - val_rmse: 0.2692    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.2123 - r_square: 0.8412 - rmse: 0.2123 - val_loss: 0.2636 - val_r_square: 0.8373 - val_rmse: 0.2636    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.2088 - r_square: 0.8480 - rmse: 0.2088 - val_loss: 0.2535 - val_r_square: 0.8459 - val_rmse: 0.2535    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.2055 - r_square: 0.8475 - rmse: 0.2055 - val_loss: 0.2538 - val_r_square: 0.8483 - val_rmse: 0.2538    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.2065 - r_square: 0.8493 - rmse: 0.2065 - val_loss: 0.2705 - val_r_square: 0.8272 - val_rmse: 0.2705    \n",
      "\n",
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.2090 - r_square: 0.8472 - rmse: 0.2090 - val_loss: 0.2498 - val_r_square: 0.8515 - val_rmse: 0.2498    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.2092 - r_square: 0.8462 - rmse: 0.2092 - val_loss: 0.2488 - val_r_square: 0.8520 - val_rmse: 0.2488    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.2094 - r_square: 0.8461 - rmse: 0.2094 - val_loss: 0.2563 - val_r_square: 0.8417 - val_rmse: 0.2563    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.2054 - r_square: 0.8500 - rmse: 0.2054 - val_loss: 0.2575 - val_r_square: 0.8431 - val_rmse: 0.2575    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.2080 - r_square: 0.8473 - rmse: 0.2080 - val_loss: 0.2625 - val_r_square: 0.8413 - val_rmse: 0.2625    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.2049 - r_square: 0.8450 - rmse: 0.2049 - val_loss: 0.2643 - val_r_square: 0.8410 - val_rmse: 0.2643    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.1994 - r_square: 0.8583 - rmse: 0.1994 - val_loss: 0.2735 - val_r_square: 0.8268 - val_rmse: 0.2735    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.2029 - r_square: 0.8450 - rmse: 0.2029 - val_loss: 0.2700 - val_r_square: 0.8353 - val_rmse: 0.2700    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.2023 - r_square: 0.8564 - rmse: 0.2023 - val_loss: 0.2674 - val_r_square: 0.8378 - val_rmse: 0.2674    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.2016 - r_square: 0.8496 - rmse: 0.2016 - val_loss: 0.2812 - val_r_square: 0.8210 - val_rmse: 0.2812    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.2030 - r_square: 0.8598 - rmse: 0.2030 - val_loss: 0.2605 - val_r_square: 0.8409 - val_rmse: 0.2605    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.2003 - r_square: 0.8507 - rmse: 0.2003 - val_loss: 0.2807 - val_r_square: 0.8274 - val_rmse: 0.2807    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.1963 - r_square: 0.8517 - rmse: 0.1963 - val_loss: 0.2833 - val_r_square: 0.8213 - val_rmse: 0.2833    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.2005 - r_square: 0.8511 - rmse: 0.2005 - val_loss: 0.2766 - val_r_square: 0.8291 - val_rmse: 0.2766    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.1985 - r_square: 0.8563 - rmse: 0.1985 - val_loss: 0.2765 - val_r_square: 0.8271 - val_rmse: 0.2765    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.1988 - r_square: 0.8482 - rmse: 0.1988 - val_loss: 0.2696 - val_r_square: 0.8310 - val_rmse: 0.2696    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.1941 - r_square: 0.8591 - rmse: 0.1941 - val_loss: 0.2553 - val_r_square: 0.8385 - val_rmse: 0.2553    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.2013 - r_square: 0.8467 - rmse: 0.2013 - val_loss: 0.2669 - val_r_square: 0.8351 - val_rmse: 0.2669    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.1971 - r_square: 0.8618 - rmse: 0.1971 - val_loss: 0.2762 - val_r_square: 0.8242 - val_rmse: 0.2762    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.1935 - r_square: 0.8562 - rmse: 0.1935 - val_loss: 0.2683 - val_r_square: 0.8367 - val_rmse: 0.2683    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.1950 - r_square: 0.8529 - rmse: 0.1950 - val_loss: 0.2631 - val_r_square: 0.8352 - val_rmse: 0.2631    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.1946 - r_square: 0.8655 - rmse: 0.1946 - val_loss: 0.2703 - val_r_square: 0.8329 - val_rmse: 0.2703    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.1926 - r_square: 0.8532 - rmse: 0.1926 - val_loss: 0.2689 - val_r_square: 0.8344 - val_rmse: 0.2689    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.1923 - r_square: 0.8594 - rmse: 0.1923 - val_loss: 0.2615 - val_r_square: 0.8386 - val_rmse: 0.2615    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.1911 - r_square: 0.8576 - rmse: 0.1911 - val_loss: 0.2625 - val_r_square: 0.8377 - val_rmse: 0.2625    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.1949 - r_square: 0.8600 - rmse: 0.1949 - val_loss: 0.2624 - val_r_square: 0.8414 - val_rmse: 0.2624    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.1937 - r_square: 0.8557 - rmse: 0.1937 - val_loss: 0.2728 - val_r_square: 0.8315 - val_rmse: 0.2728    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.1908 - r_square: 0.8568 - rmse: 0.1908 - val_loss: 0.2633 - val_r_square: 0.8397 - val_rmse: 0.2633    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.1911 - r_square: 0.8628 - rmse: 0.1911 - val_loss: 0.2754 - val_r_square: 0.8314 - val_rmse: 0.2754    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.1915 - r_square: 0.8595 - rmse: 0.1915 - val_loss: 0.2607 - val_r_square: 0.8444 - val_rmse: 0.2607    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.1898 - r_square: 0.8609 - rmse: 0.1898 - val_loss: 0.2675 - val_r_square: 0.8332 - val_rmse: 0.2675    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.1897 - r_square: 0.8607 - rmse: 0.1897 - val_loss: 0.2517 - val_r_square: 0.8467 - val_rmse: 0.2517    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.1859 - r_square: 0.8651 - rmse: 0.1859 - val_loss: 0.2645 - val_r_square: 0.8415 - val_rmse: 0.2645    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n",
      " - 0s - loss: 0.1899 - r_square: 0.8575 - rmse: 0.1899 - val_loss: 0.2742 - val_r_square: 0.8310 - val_rmse: 0.2742    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.1855 - r_square: 0.8681 - rmse: 0.1855 - val_loss: 0.2610 - val_r_square: 0.8385 - val_rmse: 0.2610    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.1872 - r_square: 0.8611 - rmse: 0.1872 - val_loss: 0.2543 - val_r_square: 0.8480 - val_rmse: 0.2543    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.1882 - r_square: 0.8652 - rmse: 0.1882 - val_loss: 0.2598 - val_r_square: 0.8392 - val_rmse: 0.2598    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.1899 - r_square: 0.8630 - rmse: 0.1899 - val_loss: 0.2733 - val_r_square: 0.8313 - val_rmse: 0.2733    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.1883 - r_square: 0.8604 - rmse: 0.1883 - val_loss: 0.2640 - val_r_square: 0.8381 - val_rmse: 0.2640    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.1875 - r_square: 0.8601 - rmse: 0.1875 - val_loss: 0.2530 - val_r_square: 0.8470 - val_rmse: 0.2530    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.1888 - r_square: 0.8547 - rmse: 0.1888 - val_loss: 0.2643 - val_r_square: 0.8369 - val_rmse: 0.2643    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.1858 - r_square: 0.8662 - rmse: 0.1858 - val_loss: 0.2541 - val_r_square: 0.8460 - val_rmse: 0.2541    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.1856 - r_square: 0.8646 - rmse: 0.1856 - val_loss: 0.2517 - val_r_square: 0.8469 - val_rmse: 0.2517    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.1888 - r_square: 0.8569 - rmse: 0.1888 - val_loss: 0.2575 - val_r_square: 0.8431 - val_rmse: 0.2575    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.1882 - r_square: 0.8602 - rmse: 0.1882 - val_loss: 0.2736 - val_r_square: 0.8310 - val_rmse: 0.2736    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.1834 - r_square: 0.8612 - rmse: 0.1834 - val_loss: 0.2588 - val_r_square: 0.8413 - val_rmse: 0.2588    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.1871 - r_square: 0.8628 - rmse: 0.1871 - val_loss: 0.2627 - val_r_square: 0.8404 - val_rmse: 0.2627    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.1838 - r_square: 0.8666 - rmse: 0.1838 - val_loss: 0.2663 - val_r_square: 0.8377 - val_rmse: 0.2663    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.1866 - r_square: 0.8630 - rmse: 0.1866 - val_loss: 0.2568 - val_r_square: 0.8389 - val_rmse: 0.2568    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.1852 - r_square: 0.8681 - rmse: 0.1852 - val_loss: 0.2450 - val_r_square: 0.8486 - val_rmse: 0.2450    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.1849 - r_square: 0.8718 - rmse: 0.1849 - val_loss: 0.2686 - val_r_square: 0.8352 - val_rmse: 0.2686    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.1812 - r_square: 0.8689 - rmse: 0.1812 - val_loss: 0.2534 - val_r_square: 0.8423 - val_rmse: 0.2534    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.1866 - r_square: 0.8712 - rmse: 0.1866 - val_loss: 0.2634 - val_r_square: 0.8399 - val_rmse: 0.2634    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.1840 - r_square: 0.8674 - rmse: 0.1840 - val_loss: 0.2629 - val_r_square: 0.8326 - val_rmse: 0.2629    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.1843 - r_square: 0.8621 - rmse: 0.1843 - val_loss: 0.2673 - val_r_square: 0.8354 - val_rmse: 0.2673    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.1788 - r_square: 0.8680 - rmse: 0.1788 - val_loss: 0.2537 - val_r_square: 0.8425 - val_rmse: 0.2537    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.1818 - r_square: 0.8667 - rmse: 0.1818 - val_loss: 0.2682 - val_r_square: 0.8261 - val_rmse: 0.2682    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.1821 - r_square: 0.8661 - rmse: 0.1821 - val_loss: 0.2533 - val_r_square: 0.8414 - val_rmse: 0.2533    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.1807 - r_square: 0.8717 - rmse: 0.1807 - val_loss: 0.2354 - val_r_square: 0.8570 - val_rmse: 0.2354    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.1799 - r_square: 0.8639 - rmse: 0.1799 - val_loss: 0.2491 - val_r_square: 0.8468 - val_rmse: 0.2491    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.1779 - r_square: 0.8725 - rmse: 0.1779 - val_loss: 0.2709 - val_r_square: 0.8333 - val_rmse: 0.2709    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.1793 - r_square: 0.8640 - rmse: 0.1793 - val_loss: 0.2579 - val_r_square: 0.8417 - val_rmse: 0.2579    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.23535623304512468                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_4\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_10 (Dense)             (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_7 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_11 (Dense)             (None, 50)                5050                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_8 (Dropout)          (None, 50)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_12 (Dense)             (None, 1)                 51                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 5,801                                                                                                    \n",
      "Trainable params: 5,801                                                                                                \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 1s - loss: 0.6823 - r_square: 0.2153 - rmse: 0.6823 - val_loss: 0.4882 - val_r_square: 0.5358 - val_rmse: 0.4882    \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.5220 - r_square: 0.4737 - rmse: 0.5220 - val_loss: 0.3940 - val_r_square: 0.6880 - val_rmse: 0.3940    \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.4578 - r_square: 0.5736 - rmse: 0.4578 - val_loss: 0.3361 - val_r_square: 0.7562 - val_rmse: 0.3361    \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.4232 - r_square: 0.6170 - rmse: 0.4232 - val_loss: 0.3108 - val_r_square: 0.7807 - val_rmse: 0.3108    \n",
      "\n",
      "Epoch 5/100                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4054 - r_square: 0.6435 - rmse: 0.4054 - val_loss: 0.2988 - val_r_square: 0.7916 - val_rmse: 0.2988    \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.3809 - r_square: 0.6800 - rmse: 0.3809 - val_loss: 0.2890 - val_r_square: 0.7937 - val_rmse: 0.2890    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.3759 - r_square: 0.6819 - rmse: 0.3759 - val_loss: 0.2761 - val_r_square: 0.8095 - val_rmse: 0.2761    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.3659 - r_square: 0.6878 - rmse: 0.3659 - val_loss: 0.2797 - val_r_square: 0.8002 - val_rmse: 0.2797    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.3599 - r_square: 0.6986 - rmse: 0.3599 - val_loss: 0.2651 - val_r_square: 0.8064 - val_rmse: 0.2651    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.3482 - r_square: 0.7097 - rmse: 0.3482 - val_loss: 0.2561 - val_r_square: 0.8217 - val_rmse: 0.2561    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.3432 - r_square: 0.7205 - rmse: 0.3432 - val_loss: 0.2517 - val_r_square: 0.8250 - val_rmse: 0.2517    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.3294 - r_square: 0.7324 - rmse: 0.3294 - val_loss: 0.2535 - val_r_square: 0.8275 - val_rmse: 0.2535    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.3357 - r_square: 0.7249 - rmse: 0.3357 - val_loss: 0.2555 - val_r_square: 0.8262 - val_rmse: 0.2555    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.3207 - r_square: 0.7299 - rmse: 0.3207 - val_loss: 0.2476 - val_r_square: 0.8292 - val_rmse: 0.2476    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n",
      " - 0s - loss: 0.3179 - r_square: 0.7451 - rmse: 0.3179 - val_loss: 0.2450 - val_r_square: 0.8308 - val_rmse: 0.2450    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.3148 - r_square: 0.7478 - rmse: 0.3148 - val_loss: 0.2470 - val_r_square: 0.8369 - val_rmse: 0.2470    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.3064 - r_square: 0.7495 - rmse: 0.3064 - val_loss: 0.2366 - val_r_square: 0.8410 - val_rmse: 0.2366    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.3060 - r_square: 0.7574 - rmse: 0.3060 - val_loss: 0.2428 - val_r_square: 0.8382 - val_rmse: 0.2428    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.3028 - r_square: 0.7590 - rmse: 0.3028 - val_loss: 0.2307 - val_r_square: 0.8468 - val_rmse: 0.2307    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.2994 - r_square: 0.7494 - rmse: 0.2994 - val_loss: 0.2284 - val_r_square: 0.8469 - val_rmse: 0.2284    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.2978 - r_square: 0.7589 - rmse: 0.2978 - val_loss: 0.2295 - val_r_square: 0.8466 - val_rmse: 0.2295    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.2901 - r_square: 0.7605 - rmse: 0.2901 - val_loss: 0.2261 - val_r_square: 0.8465 - val_rmse: 0.2261    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.2864 - r_square: 0.7734 - rmse: 0.2864 - val_loss: 0.2135 - val_r_square: 0.8527 - val_rmse: 0.2135    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.2834 - r_square: 0.7834 - rmse: 0.2834 - val_loss: 0.2195 - val_r_square: 0.8536 - val_rmse: 0.2195    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.2853 - r_square: 0.7743 - rmse: 0.2853 - val_loss: 0.2190 - val_r_square: 0.8590 - val_rmse: 0.2190    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.2770 - r_square: 0.7840 - rmse: 0.2770 - val_loss: 0.2127 - val_r_square: 0.8603 - val_rmse: 0.2127    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.2800 - r_square: 0.7807 - rmse: 0.2800 - val_loss: 0.2175 - val_r_square: 0.8600 - val_rmse: 0.2175    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.2753 - r_square: 0.7762 - rmse: 0.2753 - val_loss: 0.2098 - val_r_square: 0.8594 - val_rmse: 0.2098    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.2720 - r_square: 0.7947 - rmse: 0.2720 - val_loss: 0.2119 - val_r_square: 0.8615 - val_rmse: 0.2119    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.2745 - r_square: 0.7858 - rmse: 0.2745 - val_loss: 0.2093 - val_r_square: 0.8612 - val_rmse: 0.2093    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.2722 - r_square: 0.7869 - rmse: 0.2722 - val_loss: 0.2050 - val_r_square: 0.8655 - val_rmse: 0.2050    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.2693 - r_square: 0.7923 - rmse: 0.2693 - val_loss: 0.2090 - val_r_square: 0.8623 - val_rmse: 0.2090    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.2676 - r_square: 0.7954 - rmse: 0.2676 - val_loss: 0.2049 - val_r_square: 0.8649 - val_rmse: 0.2049    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.2732 - r_square: 0.7877 - rmse: 0.2732 - val_loss: 0.2146 - val_r_square: 0.8605 - val_rmse: 0.2146    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.2620 - r_square: 0.7994 - rmse: 0.2620 - val_loss: 0.2031 - val_r_square: 0.8667 - val_rmse: 0.2031    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.2643 - r_square: 0.7930 - rmse: 0.2643 - val_loss: 0.2075 - val_r_square: 0.8663 - val_rmse: 0.2075    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.2616 - r_square: 0.7966 - rmse: 0.2616 - val_loss: 0.2024 - val_r_square: 0.8659 - val_rmse: 0.2024    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.2675 - r_square: 0.7932 - rmse: 0.2675 - val_loss: 0.2166 - val_r_square: 0.8591 - val_rmse: 0.2166    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.2589 - r_square: 0.8057 - rmse: 0.2589 - val_loss: 0.1955 - val_r_square: 0.8697 - val_rmse: 0.1955    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.2595 - r_square: 0.7977 - rmse: 0.2595 - val_loss: 0.2105 - val_r_square: 0.8661 - val_rmse: 0.2105    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.2572 - r_square: 0.8001 - rmse: 0.2572 - val_loss: 0.1942 - val_r_square: 0.8702 - val_rmse: 0.1942    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.2533 - r_square: 0.8038 - rmse: 0.2533 - val_loss: 0.2083 - val_r_square: 0.8648 - val_rmse: 0.2083    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.2538 - r_square: 0.8045 - rmse: 0.2538 - val_loss: 0.1983 - val_r_square: 0.8675 - val_rmse: 0.1983    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.2521 - r_square: 0.8117 - rmse: 0.2521 - val_loss: 0.2021 - val_r_square: 0.8651 - val_rmse: 0.2021    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.2541 - r_square: 0.8025 - rmse: 0.2541 - val_loss: 0.2004 - val_r_square: 0.8690 - val_rmse: 0.2004    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.2539 - r_square: 0.8120 - rmse: 0.2539 - val_loss: 0.2011 - val_r_square: 0.8697 - val_rmse: 0.2011    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.2557 - r_square: 0.8080 - rmse: 0.2557 - val_loss: 0.2028 - val_r_square: 0.8648 - val_rmse: 0.2028    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.2522 - r_square: 0.8076 - rmse: 0.2522 - val_loss: 0.2044 - val_r_square: 0.8696 - val_rmse: 0.2044    \n",
      "\n",
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.2522 - r_square: 0.8119 - rmse: 0.2522 - val_loss: 0.2028 - val_r_square: 0.8704 - val_rmse: 0.2028    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.2507 - r_square: 0.8072 - rmse: 0.2507 - val_loss: 0.1955 - val_r_square: 0.8695 - val_rmse: 0.1955    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.2431 - r_square: 0.8139 - rmse: 0.2431 - val_loss: 0.2142 - val_r_square: 0.8684 - val_rmse: 0.2142    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.2472 - r_square: 0.8152 - rmse: 0.2472 - val_loss: 0.2044 - val_r_square: 0.8674 - val_rmse: 0.2044    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.2521 - r_square: 0.8126 - rmse: 0.2521 - val_loss: 0.1993 - val_r_square: 0.8704 - val_rmse: 0.1993    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.2469 - r_square: 0.8166 - rmse: 0.2469 - val_loss: 0.2013 - val_r_square: 0.8728 - val_rmse: 0.2013    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.2480 - r_square: 0.8119 - rmse: 0.2480 - val_loss: 0.1929 - val_r_square: 0.8712 - val_rmse: 0.1929    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.2444 - r_square: 0.8148 - rmse: 0.2444 - val_loss: 0.1811 - val_r_square: 0.8780 - val_rmse: 0.1811    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.2470 - r_square: 0.8062 - rmse: 0.2470 - val_loss: 0.2095 - val_r_square: 0.8649 - val_rmse: 0.2095    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.2423 - r_square: 0.8096 - rmse: 0.2423 - val_loss: 0.1985 - val_r_square: 0.8720 - val_rmse: 0.1985    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.2464 - r_square: 0.8135 - rmse: 0.2464 - val_loss: 0.1953 - val_r_square: 0.8741 - val_rmse: 0.1953    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.2453 - r_square: 0.8160 - rmse: 0.2453 - val_loss: 0.2067 - val_r_square: 0.8708 - val_rmse: 0.2067    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.2407 - r_square: 0.8138 - rmse: 0.2407 - val_loss: 0.1912 - val_r_square: 0.8761 - val_rmse: 0.1912    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.2482 - r_square: 0.8129 - rmse: 0.2482 - val_loss: 0.1947 - val_r_square: 0.8744 - val_rmse: 0.1947    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.2404 - r_square: 0.8177 - rmse: 0.2404 - val_loss: 0.1973 - val_r_square: 0.8758 - val_rmse: 0.1973    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.2393 - r_square: 0.8197 - rmse: 0.2393 - val_loss: 0.2056 - val_r_square: 0.8719 - val_rmse: 0.2056    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.2403 - r_square: 0.8172 - rmse: 0.2403 - val_loss: 0.2059 - val_r_square: 0.8691 - val_rmse: 0.2059    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.2432 - r_square: 0.8160 - rmse: 0.2432 - val_loss: 0.1980 - val_r_square: 0.8727 - val_rmse: 0.1980    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.2368 - r_square: 0.8255 - rmse: 0.2368 - val_loss: 0.1998 - val_r_square: 0.8713 - val_rmse: 0.1998    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.2400 - r_square: 0.8178 - rmse: 0.2400 - val_loss: 0.1858 - val_r_square: 0.8763 - val_rmse: 0.1858    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.2351 - r_square: 0.8137 - rmse: 0.2351 - val_loss: 0.1935 - val_r_square: 0.8705 - val_rmse: 0.1935    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.2423 - r_square: 0.8118 - rmse: 0.2423 - val_loss: 0.1948 - val_r_square: 0.8750 - val_rmse: 0.1948    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.2421 - r_square: 0.8208 - rmse: 0.2421 - val_loss: 0.1917 - val_r_square: 0.8781 - val_rmse: 0.1917    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2345 - r_square: 0.8204 - rmse: 0.2345 - val_loss: 0.1880 - val_r_square: 0.8763 - val_rmse: 0.1880    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.2338 - r_square: 0.8249 - rmse: 0.2338 - val_loss: 0.1869 - val_r_square: 0.8779 - val_rmse: 0.1869    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.2353 - r_square: 0.8229 - rmse: 0.2353 - val_loss: 0.1791 - val_r_square: 0.8789 - val_rmse: 0.1791    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.2375 - r_square: 0.8233 - rmse: 0.2375 - val_loss: 0.1842 - val_r_square: 0.8744 - val_rmse: 0.1842    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.2386 - r_square: 0.8179 - rmse: 0.2386 - val_loss: 0.2104 - val_r_square: 0.8697 - val_rmse: 0.2104    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.2386 - r_square: 0.8161 - rmse: 0.2386 - val_loss: 0.1857 - val_r_square: 0.8775 - val_rmse: 0.1857    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.2375 - r_square: 0.8211 - rmse: 0.2375 - val_loss: 0.1975 - val_r_square: 0.8726 - val_rmse: 0.1975    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.2362 - r_square: 0.8192 - rmse: 0.2362 - val_loss: 0.1897 - val_r_square: 0.8739 - val_rmse: 0.1897    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.2298 - r_square: 0.8291 - rmse: 0.2298 - val_loss: 0.1862 - val_r_square: 0.8732 - val_rmse: 0.1862    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.2351 - r_square: 0.8203 - rmse: 0.2351 - val_loss: 0.1895 - val_r_square: 0.8735 - val_rmse: 0.1895    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n",
      " - 0s - loss: 0.2379 - r_square: 0.8218 - rmse: 0.2379 - val_loss: 0.1871 - val_r_square: 0.8790 - val_rmse: 0.1871    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.2321 - r_square: 0.8321 - rmse: 0.2321 - val_loss: 0.1873 - val_r_square: 0.8764 - val_rmse: 0.1873    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.2386 - r_square: 0.8243 - rmse: 0.2386 - val_loss: 0.1922 - val_r_square: 0.8800 - val_rmse: 0.1922    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.2368 - r_square: 0.8232 - rmse: 0.2368 - val_loss: 0.2018 - val_r_square: 0.8774 - val_rmse: 0.2018    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.2349 - r_square: 0.8265 - rmse: 0.2349 - val_loss: 0.1947 - val_r_square: 0.8748 - val_rmse: 0.1947    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.2339 - r_square: 0.8294 - rmse: 0.2339 - val_loss: 0.1965 - val_r_square: 0.8734 - val_rmse: 0.1965    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.2355 - r_square: 0.8191 - rmse: 0.2355 - val_loss: 0.1976 - val_r_square: 0.8742 - val_rmse: 0.1976    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.2340 - r_square: 0.8279 - rmse: 0.2340 - val_loss: 0.1880 - val_r_square: 0.8803 - val_rmse: 0.1880    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.2300 - r_square: 0.8331 - rmse: 0.2300 - val_loss: 0.1901 - val_r_square: 0.8785 - val_rmse: 0.1901    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.2281 - r_square: 0.8290 - rmse: 0.2281 - val_loss: 0.1873 - val_r_square: 0.8788 - val_rmse: 0.1873    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.2341 - r_square: 0.8335 - rmse: 0.2341 - val_loss: 0.1983 - val_r_square: 0.8697 - val_rmse: 0.1983    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.2303 - r_square: 0.8234 - rmse: 0.2303 - val_loss: 0.1981 - val_r_square: 0.8727 - val_rmse: 0.1981    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.2287 - r_square: 0.8319 - rmse: 0.2287 - val_loss: 0.1926 - val_r_square: 0.8744 - val_rmse: 0.1926    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.2334 - r_square: 0.8254 - rmse: 0.2334 - val_loss: 0.1880 - val_r_square: 0.8760 - val_rmse: 0.1880    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.2317 - r_square: 0.8221 - rmse: 0.2317 - val_loss: 0.2038 - val_r_square: 0.8729 - val_rmse: 0.2038    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.2273 - r_square: 0.8340 - rmse: 0.2273 - val_loss: 0.1987 - val_r_square: 0.8742 - val_rmse: 0.1987    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.2320 - r_square: 0.8239 - rmse: 0.2320 - val_loss: 0.2012 - val_r_square: 0.8687 - val_rmse: 0.2012    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.2313 - r_square: 0.8279 - rmse: 0.2313 - val_loss: 0.1899 - val_r_square: 0.8790 - val_rmse: 0.1899    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.2325 - r_square: 0.8280 - rmse: 0.2325 - val_loss: 0.1937 - val_r_square: 0.8740 - val_rmse: 0.1937    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.17908111579927807                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_5\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_13 (Dense)             (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_9 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_14 (Dense)             (None, 100)               10100                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_10 (Dropout)         (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_15 (Dense)             (None, 1)                 101                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 10,901                                                                                                   \n",
      "Trainable params: 10,901                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 0s - loss: 0.5665 - r_square: 0.4070 - rmse: 0.5665 - val_loss: 0.4060 - val_r_square: 0.6734 - val_rmse: 0.4060    \n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.3852 - r_square: 0.6512 - rmse: 0.3852 - val_loss: 0.2936 - val_r_square: 0.7847 - val_rmse: 0.2936    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.3129 - r_square: 0.7372 - rmse: 0.3129 - val_loss: 0.2405 - val_r_square: 0.8201 - val_rmse: 0.2405    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.2751 - r_square: 0.7767 - rmse: 0.2751 - val_loss: 0.2266 - val_r_square: 0.8353 - val_rmse: 0.2266    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.2563 - r_square: 0.7917 - rmse: 0.2563 - val_loss: 0.2084 - val_r_square: 0.8413 - val_rmse: 0.2084    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.2443 - r_square: 0.7972 - rmse: 0.2443 - val_loss: 0.2052 - val_r_square: 0.8361 - val_rmse: 0.2052    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.2362 - r_square: 0.8093 - rmse: 0.2362 - val_loss: 0.1995 - val_r_square: 0.8507 - val_rmse: 0.1995    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.2278 - r_square: 0.8087 - rmse: 0.2278 - val_loss: 0.1914 - val_r_square: 0.8511 - val_rmse: 0.1914    \n",
      "\n",
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.2222 - r_square: 0.8194 - rmse: 0.2222 - val_loss: 0.1859 - val_r_square: 0.8526 - val_rmse: 0.1859    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.2180 - r_square: 0.8205 - rmse: 0.2180 - val_loss: 0.1847 - val_r_square: 0.8532 - val_rmse: 0.1847    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.2158 - r_square: 0.8264 - rmse: 0.2158 - val_loss: 0.1816 - val_r_square: 0.8499 - val_rmse: 0.1816    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.2119 - r_square: 0.8210 - rmse: 0.2119 - val_loss: 0.1765 - val_r_square: 0.8614 - val_rmse: 0.1765    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.2055 - r_square: 0.8287 - rmse: 0.2055 - val_loss: 0.1684 - val_r_square: 0.8640 - val_rmse: 0.1684    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.2015 - r_square: 0.8299 - rmse: 0.2015 - val_loss: 0.1699 - val_r_square: 0.8635 - val_rmse: 0.1699    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.1996 - r_square: 0.8295 - rmse: 0.1996 - val_loss: 0.1808 - val_r_square: 0.8646 - val_rmse: 0.1808    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.2007 - r_square: 0.8355 - rmse: 0.2007 - val_loss: 0.1701 - val_r_square: 0.8729 - val_rmse: 0.1701    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.1892 - r_square: 0.8517 - rmse: 0.1892 - val_loss: 0.1664 - val_r_square: 0.8752 - val_rmse: 0.1664    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.1936 - r_square: 0.8388 - rmse: 0.1936 - val_loss: 0.1616 - val_r_square: 0.8760 - val_rmse: 0.1616    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.1918 - r_square: 0.8410 - rmse: 0.1918 - val_loss: 0.1565 - val_r_square: 0.8749 - val_rmse: 0.1565    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.1922 - r_square: 0.8460 - rmse: 0.1922 - val_loss: 0.1569 - val_r_square: 0.8802 - val_rmse: 0.1569    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.1848 - r_square: 0.8386 - rmse: 0.1848 - val_loss: 0.1519 - val_r_square: 0.8833 - val_rmse: 0.1519    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.1867 - r_square: 0.8405 - rmse: 0.1867 - val_loss: 0.1558 - val_r_square: 0.8813 - val_rmse: 0.1558    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.1844 - r_square: 0.8446 - rmse: 0.1844 - val_loss: 0.1523 - val_r_square: 0.8801 - val_rmse: 0.1523    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.1848 - r_square: 0.8480 - rmse: 0.1848 - val_loss: 0.1528 - val_r_square: 0.8854 - val_rmse: 0.1528    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.1835 - r_square: 0.8564 - rmse: 0.1835 - val_loss: 0.1533 - val_r_square: 0.8867 - val_rmse: 0.1533    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.1775 - r_square: 0.8427 - rmse: 0.1775 - val_loss: 0.1572 - val_r_square: 0.8857 - val_rmse: 0.1572    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.1800 - r_square: 0.8516 - rmse: 0.1800 - val_loss: 0.1495 - val_r_square: 0.8881 - val_rmse: 0.1495    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.1780 - r_square: 0.8554 - rmse: 0.1780 - val_loss: 0.1471 - val_r_square: 0.8877 - val_rmse: 0.1471    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1776 - r_square: 0.8523 - rmse: 0.1776 - val_loss: 0.1473 - val_r_square: 0.8880 - val_rmse: 0.1473    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.1751 - r_square: 0.8531 - rmse: 0.1751 - val_loss: 0.1579 - val_r_square: 0.8901 - val_rmse: 0.1579    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.1737 - r_square: 0.8557 - rmse: 0.1737 - val_loss: 0.1432 - val_r_square: 0.8909 - val_rmse: 0.1432    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.1761 - r_square: 0.8508 - rmse: 0.1761 - val_loss: 0.1418 - val_r_square: 0.8916 - val_rmse: 0.1418    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.1708 - r_square: 0.8579 - rmse: 0.1708 - val_loss: 0.1461 - val_r_square: 0.8919 - val_rmse: 0.1461    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.1721 - r_square: 0.8517 - rmse: 0.1721 - val_loss: 0.1431 - val_r_square: 0.8928 - val_rmse: 0.1431    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.1717 - r_square: 0.8613 - rmse: 0.1717 - val_loss: 0.1469 - val_r_square: 0.8953 - val_rmse: 0.1469    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.1698 - r_square: 0.8565 - rmse: 0.1698 - val_loss: 0.1486 - val_r_square: 0.8948 - val_rmse: 0.1486    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.1738 - r_square: 0.8555 - rmse: 0.1738 - val_loss: 0.1380 - val_r_square: 0.8968 - val_rmse: 0.1380    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.1694 - r_square: 0.8572 - rmse: 0.1694 - val_loss: 0.1461 - val_r_square: 0.8937 - val_rmse: 0.1461    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.1673 - r_square: 0.8563 - rmse: 0.1673 - val_loss: 0.1474 - val_r_square: 0.8911 - val_rmse: 0.1474    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.1704 - r_square: 0.8538 - rmse: 0.1704 - val_loss: 0.1501 - val_r_square: 0.8920 - val_rmse: 0.1501    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.1682 - r_square: 0.8575 - rmse: 0.1682 - val_loss: 0.1416 - val_r_square: 0.8989 - val_rmse: 0.1416    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n",
      " - 0s - loss: 0.1648 - r_square: 0.8538 - rmse: 0.1648 - val_loss: 0.1443 - val_r_square: 0.8980 - val_rmse: 0.1443    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.1608 - r_square: 0.8650 - rmse: 0.1608 - val_loss: 0.1407 - val_r_square: 0.8943 - val_rmse: 0.1407    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.1630 - r_square: 0.8608 - rmse: 0.1630 - val_loss: 0.1398 - val_r_square: 0.8968 - val_rmse: 0.1398    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.1649 - r_square: 0.8608 - rmse: 0.1649 - val_loss: 0.1397 - val_r_square: 0.8960 - val_rmse: 0.1397    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.1632 - r_square: 0.8673 - rmse: 0.1632 - val_loss: 0.1397 - val_r_square: 0.8985 - val_rmse: 0.1397    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.1628 - r_square: 0.8586 - rmse: 0.1628 - val_loss: 0.1356 - val_r_square: 0.8990 - val_rmse: 0.1356    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.1630 - r_square: 0.8670 - rmse: 0.1630 - val_loss: 0.1351 - val_r_square: 0.8976 - val_rmse: 0.1351    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.1654 - r_square: 0.8721 - rmse: 0.1654 - val_loss: 0.1435 - val_r_square: 0.8910 - val_rmse: 0.1435    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.1628 - r_square: 0.8669 - rmse: 0.1628 - val_loss: 0.1386 - val_r_square: 0.8980 - val_rmse: 0.1386    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.13513812866000674                                                                                                    \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [02:01<00:00, 24.31s/trial, best loss: -0.23535623304512468]\n",
      "1486/1486 [==============================] - 0s 36us/step\n",
      "Evaluate: 0.26522833612292485\n",
      "Best Performing Model: {'Dense': 300, 'Dropout': 0.48790925917284717, 'Dropout_1': 0.144331267951273, 'batch_size': 64, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#defining the create model function\n",
    "exec('from __future__ import absolute_import, division, print_function')\n",
    "from hyperas.distributions import uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras import backend as K\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    print(x_train.shape)\n",
    "    model= Sequential() \n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], activation= 'relu'))\n",
    "    model.add(Dropout({{uniform(0,.5)}}))\n",
    "    model.add(Dense({{choice([50,100,200,300])}},activation= 'relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0,.5)}}))\n",
    "    model.add(Dense(1, activation= 'linear'))\n",
    "\n",
    "    \n",
    "################################################\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "    def rmse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "    def mse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "    def r_square(y_true, y_pred):\n",
    "        SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "        SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "        return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "#############################################\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
    "    from keras.utils import print_summary\n",
    "    print_summary(model, line_length=None, positions=None, print_fn=None)\n",
    "    result= model.fit(x_train, y_train,\n",
    "                      batch_size={{choice([64,128])}},\n",
    "                      epochs={{choice([50,100,150])}},\n",
    "                      verbose=2,\n",
    "                      validation_split =0.15)\n",
    "    validation_acc= np.min(result.history['val_loss'])\n",
    "    print('Lowest Validation Loss:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
    "\n",
    "#finding the best model\n",
    "best_run, best_model= optim.minimize(model=create_model,\n",
    "                                     data=data,\n",
    "                                     algo=tpe.suggest,\n",
    "                                     max_evals=5,\n",
    "                                     trials=Trials(),\n",
    "                                     eval_space=True,\n",
    "                                     notebook_name='NeuralAnalysis')\n",
    "score= best_model.evaluate(X_test_scaled,y_test_scaled, batch_size= 64)\n",
    "\n",
    "predictions_test = best_model.predict(X_test_scaled)\n",
    "predictions_train = best_model.predict(X_train_scaled)\n",
    "\n",
    "#print best model results\n",
    "print('Evaluate:', score[0])\n",
    "#print('Predictions:', predictions[:6])\n",
    "print('Best Performing Model:', best_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "[0.26522833419760655, 0.836928129196167, 0.2652283310890198]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test, verbose=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using model to predict y values\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "predictions1 = best_model.predict(X_train_scaled)\n",
    "# predictions1\n",
    "#predictions= test\n",
    "#predictions1= train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2de7wcVZXvf+v0gYQkmJAQxHAEYRIh5BACJLwlgSSIoANioiAioDPp0A2MeL0CcseLOjqI44wm6SQneBGVhAEfDBhw0MAkAYVJgpKXAU7UMBwTAYM5gOGR7rPuH/XatWtXV3V3dZ/q7vX9fPrT3fXYe9euqrXXXnvttYmZIQiCILQ+HYNdAEEQBKExiMAXBEFoE0TgC4IgtAki8AVBENoEEfiCIAhtggh8QRCENkEEvtAwiOgWIrprsMtRK0T0HiJiIuocxDL8jIiuCNmXWPmI6E4i+qcqzptBRH215i8kiwj8FoaIdhDRi0Q0XNn2d0S0ehCLZcQWEExEBW3740R0Zcw0mIjG16WAVWJf1wARvU5ErxHRs0R0Va3pMvMHmPl7SZSxWojoSiIq2df2KhE9TUQfrCKdqhoVoXJE4Lc+nQD+od6ZJKTt/hXAJ4noPQmkVReqvM6dzDwCwDsAXA/gdiI6OtmSDRpP2Nc2CsD/A3AvEY0e5DIJIYjAb32+AeBzRDTKtJOIjiGiXxDRK7b2+VFl32oi+jvl/5VE9Ljyn4koT0S9AHrtbd8mohdsje8pInpfBWXdA+BOAP837AAi+hQRbSOivxDRw0R0hL19rX3IRlvj/BgRrSGij9j7z7TLe779fxYRPW3/7iCi/0NEzxPRS0T0fSIaae9zzCOfJqL/AfCooUwfsXtT3eUuji0eAvAKgMlK3jcS0e+IaDcRuQKTiIYS0V329j1EtJ6I3mnvc+8NEWWI6F+I6M9E9HsAF2jl20FEs5T/PtMaEf2QiP5ERP1EtJaIJpW7jpBrGwBwB4ADABxlqKOJdpn3ENFWIvpbe/s8AJcB+Lx9335aad5CfETgtz4bAKwG8Dl9h23q+QWAFQAOAXApgMUVvvAXATgFwLH2//UApgAYbaf7QyIaWkF6XwXwEZMGTEQXAfgCgIsBjAXwGIC7AYCZz7IPO56ZRzDzPQDWAJhhbz8LwO8BTFf+r7F/X2l/zoYlrEYAWKRlPx3ARADv18p0FYCvA5jFzFvKXZgt3P8WwMEAttubr4NVh9MBjAPwFwCOWesKACMBvBvAGADzAbxhSPrvAXwQwAkApgKYU64cBn4GYAKsZ+DXAJZXeL7T8/k7AK/DbvyVffsB+CmAn9t5XAtgOREdzczL7Pxus+/bhyrNW4iPCPz24IsAriWisdr2DwLYwczfZeYiM/8awI9RmcD4Z2Z+hZnfAABmvouZd9vpfRPAEACxzRfM/CcASwF82bA7a+e3jZmLAL4GYIqj5RtYA7+A/2fl/3R4Av8yAP/KzL9n5tcB3ATgEs18cwsz/9W5TpvPAPjfAGYw83aEM46I9sAS1vcB+Cwz/0a5ppuZuY+Z3wJwC4A5dt77YAn68cxcYuanmPlVQ/ofBfAtZn6BmV+xrzM2zHwHM7+m5H+808OJwan2tf0JlsLwYWbu14+B1YjeysxvM/OjAFbaxwsNRAR+G2BrnisB3KjtOgLAKXY3e4/94l4G4NAKkn9B/UNE/8s2ufTb6Y2EpdFWwtcBvJ+IjjeU99tKWV8BQAAOC0nnCQDvtc0gUwB8H8C7iehgACcDcMxA4wA8r5z3PKyxj3eGXafN/wZQYOYob5SdzDwKlg1/AYBztGu6T7mmbQBKdt4/APAwgH8nop1EdJutLeuM08r3vOEYI7Y56FbbpPQqgB32rrj37ElmHsXMBzPzqcy8Kqx8ttlHLWPYfRPqhAj89uH/wur6qy/ZCwDW2C+s8xnBzFfb+/8KYJhyvKkhcMOt2vb6G2BpnAfZQq4fllCODTPvBvAtAF/Rdr0AIKuV9wBm/lVIOnsBPAVr0HoLM78N4FcAPgvgd8z8Z/vQnbAEr8PhAIoAXjRdp8K5AP6PM04Q47reglU/x9nmKeeaPqBd01Bm/iMz72PmLzHzsQBOh9Uj+6Qh6V2wzD5q+VXK3cePA7gQwCxYjfN77O0V3bMIdsJqaFV5cziAP9q/JWRvgxCB3ybYJod7YNmMHVbC0oAvJ6L97M80Ippo738awMVENIwsd8dPR2RzICxB+TKATiL6Iiytthr+FZaQm6hsWwrgJmeMgYhGEtFcZf+LCA4YrgFwDTzzzWrtP2CNA1xPREcS0QhYpqJ7bLNRObYCOA9AwRmEjMJudL4Jy8zmXNNXlcHnsUR0of37bCI6jogyAF6FZeIpGZK9F8B1RNRFRAch2JN7GpaJaj8i0m38BwJ4C8BuWI3C1+JcR4X8N6xG5/N2GWYA+BCAf7f3m+6bUAdE4LcXXwbg+uQz82uwtNRLYGlhf4JlThliH/JvAN6G9UJ+D9GDeQ/DGgB8DlaX/U2YTSGR2Lbq22AN/jrb7rPL9++2+WELgA8op90C4Hu2ecTxNloDS6itDfkPWN4lP7C3/cEu97Uxy7kRluZ9OxF9IOp4Jb/DiehDAL4N4AEAPyei1wA8CWsQHLA08R/BEvbb7LKbJq7dDqvuN8IadP2Jtv8fAfwNrAHhL8EaTHf4Pqx79UcAv7XzTxS7kftbWPfqzwAWA/gkMz9jH/L/ABxr37f/SDp/wYNkARRBEIT2QDR8QRCENqFmgU9E7yai/7I9M7YSUWBWJ1ksIKLtRLSJiE6sNV9BEAShMpKYDl8E8L+Y+ddEdCCAp4joF8z8W+WYD8Ca2DEBln1yCTw7pSAIgtAAatbwmXmXPWHHGQTchqB/7YUAvm9PLX8SwCgieleteQuCIAjxSTS8K1lBr06A5Yalchj83hp99rZdhjTmAZgHAMOHDz/pmGOOSbKIgiAILc1TTz31Z2bWZ9UDSFDg2/7LPwbwGcP0b9MkDqN7kB1bYxkATJ06lTds2JBUEQVBEFoeIgqdaZ2Il4493fvHAJYzs+4DDFgavToTsAuW37cgCILQIJLw0iFYEye2MfO/hhz2AKw450REpwLoZ+aAOUcQBEGoH0mYdM4AcDmAzWTHF4cVwvZwAGDmpQAeAnA+rJCwewHUvOKPIAiCUBk1C3xmfhwRgZbYms6brzUvQRAGh3379qGvrw9vvvnmYBdFsBk6dCi6urqw336mAKpmBm0RZkEQmoe+vj4ceOCBeM973gPLiisMJsyM3bt3o6+vD0ceeWTs8yS0giAIkbz55psYM2aMCPuUQEQYM2ZMxT0uEfiCIMRChH26qOZ+iMAXBEFoE0TgC01NPg90dlrfQuuye/duTJkyBVOmTMGhhx6Kww47zP3/9ttvlz13w4YNuO6668oeAwCnn356ImVdvXo1Ro4ciRNOOAFHH300zjrrLKxcuTLWeb/6lXHxtsSQQVuhqenpAUol67tQGOzSCPVizJgxePppy+v7lltuwYgRI/C5z33O3V8sFtHZaRZnU6dOxdSpUyPzSFLYvu9973OF/NNPP42LLroIBxxwAGbOnBl6zurVqzFixIjEGh4TouELTU02C2Qy1rfQXlx55ZX47Gc/i7PPPhs33HAD1q1bh9NPPx0nnHACTj/9dDz77LMALEH6wQ9+EIDVWHzqU5/CjBkzcNRRR2HBggVueiNGjHCPnzFjBubMmYNjjjkGl112GZyFoh566CEcc8wxOPPMM3Hddde56ZZjypQp+OIXv4hFixYBAH7605/ilFNOwQknnIBZs2bhxRdfxI4dO7B06VL827/9G6ZMmYLHHnvMeFytiIYvNDWFgmj27cxzzz2HVatWIZPJ4NVXX8XatWvR2dmJVatW4Qtf+AJ+/OMfB8555pln8F//9V947bXXcPTRR+Pqq68O+LL/5je/wdatWzFu3DicccYZ+OUvf4mpU6cim81i7dq1OPLII3HppZfGLueJJ56Ib3zjGwCAM888E08++SSICN/5zndw22234Zvf/Cbmz5/v67n85S9/MR5XCyLwBUGoD+vzwPYeYHwWmFafVnnu3LnIZDIAgP7+flxxxRXo7e0FEWHfvn3Gcy644AIMGTIEQ4YMwSGHHIIXX3wRXV1dvmNOPvlkd9uUKVOwY8cOjBgxAkcddZTr937ppZdi2bJlscqpLiXb19eHj33sY9i1axfefvvtUD/6uMdVgph0BEGoD9t7AC5Z33Vi+PDh7u9//Md/xNlnn40tW7bgpz/9aaiP+pAhQ9zfmUwGxWIx1jG1rP/9m9/8BhMnTgQAXHvttbjmmmuwefNm9PT0hJYz7nGVIAJfEIT6MD4LUMb6bgD9/f047DBr7aU777wz8fSPOeYY/P73v8eOHTsAAPfcc0+s8zZt2oSvfOUryNuuZGo5v/e977nHHXjggXjttdfc/2HH1YIIfEEQ6sO0AnBpsW7mHJ3Pf/7zuOmmm3DGGWegVColnv4BBxyAxYsX47zzzsOZZ56Jd77znRg5cqTx2Mcee8x1y8zn81iwYIHroXPLLbdg7ty5eN/73oeDDz7YPedDH/oQ7rvvPnfQNuy4WqBauin1RhZAEYR0sG3bNtck0c68/vrrGDFiBJgZ+XweEyZMwPXXXz9o5THdFyJ6ipmNfqii4QuCIMTk9ttvx5QpUzBp0iT09/cj22T+wOKlIwiCEJPrr79+UDX6WhENXxAEoU0QgS8IgtAmiMAXBEFoExIR+ER0BxG9RERbQvbPIKJ+Inra/nwxiXwFQRCE+CSl4d8J4LyIYx5j5in258sJ5SsIQhtQS3hkIBh6eOnSpfj+97+fSNlmzJiBo48+GpMnT8YxxxyDa665Bnv27Ik872tf+1oi+VdCIgKfmdcCeCWJtARBEHSc8MhPP/005s+fj+uvv979v//++0eerwv8+fPn45Of/GRi5Vu+fDk2bdqETZs2YciQIbjwwgsjz2lagR+T04hoIxH9jIgmNTBfQRBakKeeegrTp0/HSSedhPe///3YtWsXAGDBggU49thjMXnyZFxyySXG0MO33HIL/uVf/gWApaHfcMMNOPnkk/He974Xjz32GABg7969+OhHP4rJkyfjYx/7GE455RRETQTdf//9cdttt+F//ud/sHHjRgDARRddhJNOOgmTJk1yg63deOONeOONNzBlyhRcdtllocclTaP88H8N4Ahmfp2IzgfwHwAmmA4konkA5gHA4Ycf3qDiCYLQTDAzrr32Wtx///0YO3Ys7rnnHtx888244447cOutt+IPf/gDhgwZgj179mDUqFGB0MOPPPKIL71isYh169bhoYcewpe+9CWsWrUKixcvxkEHHYRNmzZhy5YtmDJlSqyyZTIZHH/88XjmmWdw/PHH44477sDo0aPxxhtvYNq0afjIRz6CW2+9FYsWLXIXdQFgPG7MmDHJVRoapOEz86vM/Lr9+yEA+xGRMTgEMy9j5qnMPHXs2LGNKJ4gCHWgnstPvvXWW9iyZQtmz56NKVOm4J/+6Z/Q19cHAJg8eTIuu+wy3HXXXaGrYOlcfPHFAICTTjrJDY72+OOP45JLLgEAdHd3Y/LkybHLp4asWbBgAY4//niceuqpeOGFF9Db22s8J+5xtdAQDZ+IDgXwIjMzEZ0Mq6HZ3Yi8BUEYHOq5/CQzY9KkSXjiiScC+x588EGsXbsWDzzwAL7yla9g69atkek54ZDVcMnVxhkrlUrYvHkzJk6ciNWrV2PVqlV44oknMGzYMMyYMcMY5jjucbWSlFvm3QCeAHA0EfUR0aeJaD4RzbcPmQNgCxFtBLAAwCWc5qhtgiDUTD2XnxwyZAhefvllV+Dv27cPW7duxcDAAF544QWcffbZuO2227Bnzx68/vrrgdDDcTjzzDNx7733AgB++9vfYvPmzZHn7Nu3DzfddBPe/e53Y/Lkyejv78dBBx2EYcOG4ZlnnsGTTz7pHrvffvu5i7SUOy5JEtHwmbnsWl/MvAjAoiTyEgShOajn8pMdHR340Y9+hOuuuw79/f0oFov4zGc+g/e+9734xCc+gf7+fjAzrr/+eowaNQof+tCHMGfOHNx///1YuHBhrDxyuRyuuOIKTJ48GSeccAImT54cGg75sssuw5AhQ/DWW29h1qxZuP/++wEA5513HpYuXYrJkyfj6KOPxqmnnuqeM2/ePEyePBknnngi7rjjjtDjkkTCIwuCEEk7hkculUrYt28fhg4dit/97neYOXMmnnvuuVhuoI2i0vDIEi1TEATBwN69e3H22Wdj3759YGYsWbIkVcK+GkTgC4IgGDjwwAMj/e6bDQmeJghhrM8Dd3da30JNi3gLyVPN/RCBLwhhbO8BuGR9tzlDhw7F7t27ReinBGbG7t27MXTo0IrOE5OOIIQxPmsJ+/HNtYxdPejq6kJfXx9efvnlwS6KYDN06FB0dXVVdI546QiCILQQsoi5IAiCIAJfEAShXRCBLwiC0CaIwBeEVkBcSIUYiMAXhFZAXEiFGIjAF4RWYHwWoIy4kAplET98QWgFphWsjyCUQTR8QRCENkEEviAIQpsgAl8QBKFNEIEvCK2IuGkKBkTgC62HCDuzm6bUS9uT1CLmdxDRS0S0JWQ/EdECItpORJuI6MQk8hUEI+KTbnbTlHppe5LS8O8EcF6Z/R8AMMH+zAOwJKF8BSGI+KRbLpqXFv2umlIvbU9i4ZGJ6D0AVjJzt2FfD4DVzHy3/f9ZADOYeVe5NCU8stAUrM97cfPFF14YZNIQHvkwAC8o//vsbQGIaB4RbSCiDbLYgpAk+TzQ2Wl9J4qYSoQmoVECnwzbjF0LZl7GzFOZeerYsWPrXKw2ZzAH8QYh754eoFSyvhMtk5hKhCahUQK/D8C7lf9dAHY2KG8hjMHUTAch72wWyGSs70TLZLKXC0IKaZTAfwDAJ21vnVMB9EfZ74UGMJia6SDkXSgAxaL1nZYyCUIjScot824ATwA4moj6iOjTRDSfiObbhzwE4PcAtgO4HUAuiXyFKnFMF0B5zbSeZpc0asWmMhnqoG5jAYJQZ2QR83bk7k7LdEEZS8DVelwrY6iDzk5rLCCTsXoMtZLPW+MK2WyZ3ocgxCQNXjpCmohrumhlE0fc3ouhDiLHAiokcjBZEBJCNHyhPam291IHn3vR8IUkEQ1fEHSq7b3UwbsocjB5EJBxitZENHxBqIQ2mVWb9DiF0DhEwxeEpEijd1EdSHqcQkgHIvAFAZDQwRppNDMJtSMCXxCApo2HI7Z2oRJE4KcFVcMUbbPxNKkLahIundJotA8i8KNolPDtXYL8Hd9C56nfRv4LE9OpbbZyQ9SktvkkbO0yD6B9EIEfRQO6+vm5a9B5+dtYvCqH0kAneh6dn05ts0nNHpE0cUOWhK1dBmjbBxH4Bnxd3AZ09Xt+cgZKA50gAJmOIiaO+y06P/Em8rd9tG55VkWKzB6JmiFatSGLiQzQtg/ih2+gM1NCaSCDTEcJxVKm7vnl565Bz0/OQHbWnShc8ffovHwfSgOdyHQUUSx11j3/ZiRRP/E28a0X2gPxw6+Q7MweZDqKyM6sUeOLaSoo/HA6iqVOFK60gotmz7Hzv/iXteXfwiRqhmhS+70gVIoIfJ31eYAHrN/7H1RbWpWaCmxTSeGqa1F88h9Q+OH02vJvYcQMIQiVIwJfp3cxeh6dbw2e/mxubWlVavOeVrCOB7etPTkWaRhkTUMZBKFCROBr5L+7CAMDHQAGkD2np7YXuhpTQYoGRlNLGgZZB7MM0tgIVSIC38F+iXoezYLRAQLQ82gW+ZsnNTR/AGJPjiINjeJgliENDZ7QlIjAd7BfouzMZchkAAYss84j8V/omlwFG/0SN7OWmOAga9X3bDAHetPQ4AlNSVJr2p5HRM8S0XYiutGwfwYR9RPR0/bni0nkmyjOgOmV16D4RB7d3VbVTDw2vltmTTMW477ESQnqNtMS83PXoDNTRH7uGt/2ppxlKl5FQpXULPCJKAOgAOADAI4FcCkRHWs49DFmnmJ/vlxrvtUSqtFNKyB/ZwGdl7+N/M2TsG2btdn59hEidGtyFYz7EiclqNtMS3Qmt/X85Azf9rTNMq2ll2g8V39Wm7lnJ9QOM9f0AXAagIeV/zcBuEk7ZgaAlZWmfdJJJ3HSZDLMgPUd2NdRtPZ1FDmXs47J5QyJrMgwL4f1rbMuZ21fZzqxetzyzFnNvBycm7WQMx37zOVrdaqo49yc1VZ9zVldx4LVTrnns6pz9We13LMrtAQANnCITE3CpHMYgBeU/332Np3TiGgjEf2MiEJHQoloHhFtIKINL7/8cu2lW59HfvYiqzs/exGyH14TqtFl51uza7Mze1C4Mo/i/cehcAYBDx7nP7CMdpy/eZIVFiHhwV7X9HCf5Zvvuo7GUPTzeWv2cP7cxbVpdmnRDqvo5biT21I+t0HtcVSq7WezsJ7fc5T7rD+rhmdXomW2EWEtQdwPgLkAvqP8vxzAQu2YdwAYYf8+H0BvnLQT0fCXgzMd+2zNfV+0ZrMc5o9DhHap9hKSRO1x5C5YwYQSA6VwDV8pp6v5xbn+cqRFO6xTLypt5ahK26/iHtXSq0iMtNzTFgB11vD7ALxb+d8FYKfWqLzKzK/bvx8CsB8RHZxA3rHInrPUClVwztIYNmsyb17RYWlNvYst7bJ3MbAiqP1n52csDW1+sjF41JmlPf95KRgdyGQ6wmeaOlpw72Jkz1lsh4pYVpvNfjDt/mrvIi2DlnpPI+EeUFXjC1Xco1SMY7SZE8FgUXPwNCLqBPAcgJkA/ghgPYCPM/NW5ZhDAbzIzExEJwP4EYAjOCLzRIKnPXgc0L8FoCEAvwWM7AYu2BweMMvZziXDxWYAHkD+uwvQ8+h8ZM9ZisJV11r7JuQqE0BOufYbDez7CwCOnUY+b5l4stkyoQXc6xiw0qaMJSSblbs7rXtS6XXUMzCak/Y7JgKvbqutrts9gFu7X3+C1DV4GjMXAVwD4GEA2wDcy8xbiWg+Ec23D5sDYAsRbQSwAMAlUcI+EdbnrRdxQs4S9oAlZFWh3rvE08oePA7oXYwxf/8n0GUDGDPvz1YDAQAg62GccDWW2HHrl6zKeXmFaSaO1vfgcX7tr3+L9b3vFQCM/HcXWoufRCiH+TzQs9Sy0xauNBysT+CacHXlWnm1mmo9bfzV9i7qqTk6PY1Xt9kKAlffA4oqZ1rGT+pFBb02GXOogTBbTxo+NdvwFXtm7tzbLS+NWQs9W6GzX/nkZi1kYIABZmDAsykqNkagZO8veeeG2R4DeZC1fWW3b7s7zmDb6a0yDHD3UX2+5CLt8UnY2atNwzDmUdbbqRE0wDbsegBdsKL6vKLKmZbxkwYQ9cykYswhxaCMDX/QhXq5T80CXx24VAdul5P9khY5N2uR6+I4evjLPmE/evjLRnc21yVy1kK/gDO9tPY23zlsDbx6DdAQ7u7aaOU5mu382Wt0FHI52210dsEsHJIQcNWmsZwCDaDXQBUbOyjXwHrwNcL1EsptNKgZJdAHXYlIOe0r8BVcLcwW0qpgJ1djH/ALWlVzV1+4ld2uAO/u2hgU/q7g8xoWJw/He0dtgPRehfc9wN1dG630TC+600tY2V15hdRDgKzLeXVgCz335ZxdaKyGWoFGrAuQQJnL9eBYmyPRJkI5KUzCO1SgV/PMtlFD6SACf13OEr6zFtrmmIGAcDcLWvtFNzw0jvulc57Tc3AEjaOxe+mWvIlS63I+jd8R/t7xJd/5Qzr3BgR7bs5qBkpMKFmNTaUPtCYQY2tNUS9Q2H59e71fRCf9ld3mb7vh1s1pzFqvRGvAhGSpxDyTm12w3pnZhfgZtJEpzKHtBb7zoPiFvP7xhKsjiD2hvChg63dNMMNf9jR8RyD7ehAcbEBUu/6KjC28vcYh07FPaQT85zumIG8cIYZ/fRlTU8D0EvVeJPUCVZpOtQ2EYZzGzVcZtzFq+LnwfBM1K9RTc025hhtpolQgst4PooGyx/lI+fXXg/YW+Cu7FeEYJvB1DV8XugOeJq0Psjp2W0d451gbDxjwH6cOGCsPoZq/09jo5eJ7R7v5OhOviErRL0sM4WoUYCat3DFXxXmBymn7laQTcg2xhG6Ypq9o+LFMYtq1EHnPT81Cv5pGNO45zaDhxiyjz1lCCKWcwG/p8MhjRvwZ9MFN8CZTmSZVsb2d3N9EA8ies9SaqGVvY3Sg59H57lnZD/zQnsa+1EtqfNYKgTDQif43Dwavuwa52UvsSV897jEuL621Jm+tIHR3bQbA6O7ajMJV16Jw1bXg5drtKfbb+RZx9azF4JXHY2CgA4Wf2+6hYW57MVwaA0sG2i6q7iQzwHYZZIAyVqC5KNc43dXwweOs6+1d7NYrtsdcZMZwDbEiXTrufhds9r7HZ618DznLctl9dVt0GbRrYfZ2RYa3iHKprMblNO45aQuSZ6qLmGXMzbYmUOZmLy17nFCGsJYgDZ+aNPx7Rxs0+qDdvrtro6ItM+tau9ONBAbMgbdCBnPLan22RqNq8a7JRw2MNmuhb0DZ7WGYtOJaNTldGzeFlgjzeoprzw8zqcwuxNfUlbyqNquodRW33rT8czm2zQvlTT+B/NqdWuqiDc0z1YC2M+ms7FYGPcubbVQzi2XrL1r+1HZXv7vbOr87jiOMKfaOAcdjSLXDO15BqseOY0YKlNeUvuP+OWd1fCGovECBATF1noDB5OFzM3VeXvWFvHe0de69o73tzjYnPXu713iUiT8UR1Co9zBu4+HUm+MmqzfqcYVMufJVO9Bd6bGN8mKpRfA2evC+DWk7ge93c+SAoDdqzCEvbEV+5DFtwk6apHgMdXdt9NnoXVulKoxV18+QF8cN3hZHgVKu2Rf0Lc5LqDZujiAP+0QI61jeF3GEudp4KFmZegK5nGeHtxp1pVENqaNyZat4TKKCPNyBTfX+mxrZOo0FBOovyR6L9H4Sp+0EPvk0Z127Nwh75lAN2X3YY/iRxzUxGF9gxZzjNQRaNExtdq6vPI6ZKI55xEHV8BUBGJhQZiy/58nkRu70eTYZGqeV3WbBGEdgKmYkIr9nh1vvc1YbGwWTB5KzTS+dMCcAACAASURBVH9OrHkVRc9Mo/dy3G3k9RBqdd2MuP7AxC71OFVg1klbD9Rfklq5aPiJ03YCXzeVuIKJBlzBFDahJtQ9sZIXo5xdW09TnZ2qfAJeQPoLbhJENXb1PS1/n1+oaT0JtWxqj0T975nLhnjn69eqlidM01M0V/+cBc8dNbQXZgvj3KxFnhC3G83cubczkdVQdR/V506iczX9jFUmYwOmCnj1ftgNgN7o+BQBpRfoNvzqBC9DoxFQENQeZJx7W6NQjavIlEUEe8NoO4EfmJRkeplCBEzg4a7gQVU1XzdmThSqwFAHMgOChrRtwTAGPhQbuu88XbNWByJV05FuJrAnleVmLfKZoXKzFvk0fP+Es6A7a+D69HpW3SZ99UO+3ohRw9d7YaaeUIjQ1mc7Oxq+0f1WbUTsFch4OUVP5Mr481cbWCu9iBW5qjR/RJnMEhHoUUQ16NIQJEbbCfyAFmwSjHEfNCVMQizU/Az4Xi5TV96g8fvNPMqsXlNDZtSIFV9+3czi5HHBCp+gdrVTLSSFScNWw0yY5zponkjKWEUmw9x9VJ+1/4hnA9dU0dKEmolKLbcbPO/c24ONzuwlrM7VUAWfO2jvlM3Wrn1jHtrz5szoJrLSMmr4jvnNbri8SUXxrq8SQRlYlEdrXCPHfZIQymFpiA0/cdpP4JvMB7r9O+7DGyHAjXmXeTl82p72sOvC1REKwQHokqblk0EjVoWzP2yEGq7BaxT84x5ezB+/mSc3Z7VrCnGEpzkf1gam/Q2OK2zdWcbm/U65Mhl/3QYaAq3x1O3eahkdLyxVe3fGfUid1OPT8IveGE9H0R9DyTC2UtbzyPCMVDypqAJBGVQyNIUiatynnkJZNPzEaT+Bz2zW8E1d/CgSfiADL5+isQUDqpU4KOwVLV/V0nWvjeXQZvsG5ySogskfQG7A7f77zEEru/1CVwsgZ2n4Sk/EFtLdXZv8Gr5Puy54Gn7XFne/Wh518XbnWj0BXgo2krMWeo2So+Hr7q2K665lmtLMXlovSe/h+OdJeI1wIKieYkZx7r0zZpCbtcjuWfnTqGbmbywMwj5K+dHNZxUhwnxQaFOBH67hWy9lhK92o/GZRjaHCvpASAXN5u02KMYInH6BP3r4yz5Nm5ltQe63y4c1mCb7tmryCdSvz+QR0nDZH5/GqwuqdblAcDpzGQbcRi8g1MsKby+InX795qB37JbVV54VGZ/Lqh5wT2+ISV1fIURQVmpv9x1vMnVGKD41xZ4Xc82g0J4Cv4x2EfchTmwwy1QWfZutMesTxAhBd0ddu/W0ySUBTT3cps6uIHQGuB2XRNWtVc3TJ/z0wWBdIJrqTBvUdHsShgalbPjpld2a6+1AQLsONnYDxjyca9dNWr5xipBeoq7hB2ZFa3VkDXgH74F+HeXqMezZVZ9VVSv32eerGAOo6R1opIYvvQmX9hT4ZXAf4nLxy1UTS60KiknTMfjNBzVGK2Cabl5whGAwjn+YgGdtv2lSmvrbE4Kq8HQaH58A1uYB+HpU2uCgUYib5hYYbeF+watfMykC1zOJBccuVLOSbtKK0vDVXoWp56OaiPSejNsoOWadI541Cn1n4ltY6ApdAOdyWgOVUecYDHB316b2WCxEehMudRf4AM4D8CyA7QBuNOwnWGvZbgewCcCJcdKtl8B3KfeQqD7YddTwg3Z7VTht8o5f2R0QfqOH/zmGENcFfngjoIZ6Ng/mqpqwp9Xm5qwOmVNAoUI6cozFYEIxm3wGfOXzeeYEZlw7gndRaPrqPfCFvl7uD3lt0vx9PRdfT0wzXxkaA+e348kTuO4Q/BPI7OfGHhNx80yYhrhxVor2jqWyjA2irgIfQAbA7wAcBWB/ABsBHKsdcz6An9mC/1QA/x0n7cHW8OvVRVQ9TIxhExxhpM761TRka1CynGDXYwdZAiyoxZqFmF9YeVq0KU+fFmoSVnajqpbHGbSsRvCrg7KqSco009c71l8f3Uc8GzLoHGw4yW5ITD0Gp+HzgvAFzWWqac5Uv2pPzTRvITBwzv4BYNN99J1T7nmOY27UaIY1ZZuhjPWinMAna3/1ENFpAG5h5vfb/2+yo3D+s3JMD4DVzHy3/f9ZADOYeVe5tKdOncobNmyoqlwzZsxAby+wcycwbhwwYYK3b80a7/f06VUlXzW9m3Zh51/eZf9jTD/2VwAXvQOo0/2/ZttZcEI6jztoFyYc+hx6d43Hzj2HVZk7Y/rEtf7yKOkN2/+vmPY3G2LkwRg2jLB3r/Vv3Kg/YsK7trt7vXIr+WWGYf1zx2Lv28N9KennWnmPw7hROzHhXdvd/15oa4Ya5nr6xDW+9Ix5HzIdeGlNjXVXDc675ZXHuZ5h++/F3reH2d/DA2eOG/VHANCu3b7eQ6Yrz7Cah3euWqfO9fv+O+jbX+sF3thpPtYm7L2q9rh6MJh518Lq1atrToOInmLmqaZ9ScTDPwzAC8r/PntbpccAAIhoHhFtIKINL7/8ck0F27nT+WbrQbYZN87/XTOv9VovjpOH/t/etv6JvyrCHhi2/16/sD9gnO//uFHei7fzL4da33vKF5owELpv2P57A9smjNsBR2jsfXtYhFBkjDtoJ8Yd3I+9e4FhQ9+yy3QYeneNN+RD3vbSXkw7bTimd693hZlzPb0vTsSabWf5hPvOPYcBB4wLCLzAmgbUid5d47Fm23Ss2Tbdzpu9ussMQ+/GP9oNgdWo6dcU3FY940b90b4+qwxWObzyONez9+1hmD5xLfa+PcyYzs49h9n3wX+9vbvGAy+twbjRL2l5eNfjE/YZO/0DxqH3TxOselYeSxwwzv+tCvsDzM/ahAmWohQlSL33z7DT9I4kSNwyth1hqn/cD4C5AL6j/L8cwELtmAcBnKn8fwTASVFp12rScQZC3VABJkK6rxXZAPWxgJBBWn2QzvEHD4Yx8D66r3jQJKPb5/0ePr74MB1KjBzVZHDBCs/dUzEvWKYjxbZstD179nOT3Txg614xRJmJWlJCRWumiBxrs3+DYxCOG2Ng9q82hhA2TqLPC/DXrZ5f0JwzpHOv4ZhwV1Z1boVqggo3s5kG45XJabOXKG68dmz+MmbKWGaOBG3hZc9V66UR9vY28uJBnW34pwF4WPl/E4CbtGN6AFyq/H8WwLui0k7Ehh91o0MGbiuyARpcLE120cA6uHqRNI8VXVgHZ7QGhZGzJq87Q9UeK1CDdHlCxhNOoROZ1HrRhGuYIHQbHDK7XQZmr7r25kW+PP156YKwpNneldhJhlAHQWHuNWpBd1ivLk11HbTXBxuHgHulYRA3OLjrz8d5TnQ3U14OLZT2QPBZNTyD7tjRBSvirRsQ9R7UIkSVWeINsbenxYunAQ1PvQV+J4DfAzgS3qDtJO2YC+AftF0XJ+26e+kwJ6PhV8KKIa6mq6MP4OqCIVy7NrgQHtXHgBULxjdIHaIR+zyStIlOag9AH4j0ZvP6hZVbFsPsTnWWrbvwiObjz8y+fD2hHdTsXa1+RSbQe3E+ut++uSExC27E0vyDAts712pIvboqekI61IXUHBZC75Wok718i/SYYkAZwm7UNBelFiGqvHfuAHR3su+cr+xxlLJG0ICGp64C30of5wN4Dpa3zs32tvkA5tu/CUDB3r8ZwNQ46TZE4Mel3g+I7nu9POjXrWv9QU3bcsljVjQzpWdA5E3U8mv45F+hanl4WAbdRBP05lEbHlvYlPG+0c93r3VdLtDj8Xvg6NFD4btPTkPi9ALCPWxMvSW/Nq0LVrPpxezdE2aW0a9Z3abfnzDXVEsp8E8Yc+tAPU57hp1wDk5wtzAilZ6E34mkNf2y6ZUTvPV815tdw6/nJzUC3/cCxYyaWSkr/LHXddu9arIwhSD29QZy/vEL3ac+sKqVQQsPs1/rs2r1cviEkvNQGwW2PtM1aKMOO89qlAyavPISqZOP1F5QuKZvFtzBuQgDSiNiSkM9zyzgzbb/YFlNDaxujgvMOLZdePU6UYV3IHqm+pwrwij0uKRxGiLbDTkpTb9sz6Gc4E2L+adKRODXij6YWglxW3RlVqrexVdNMH7hWFIaiC3udkej0c0lAbONMwvWoHn7TTVWGYJaf1DYWQKKfF3nYIPjN1X47dQDAQ2eQoSf81KqpjDXt960qImWj9kUYxL++vEl33iM2USkjWdoAdL0Rju81+Dv+ejjGnrAOkdAuz03R3grPT7VpGZ8zp3orbMLXuNSJ4XUFyHWGbuJ0vQr1JIr7jk0+QCvCPxacTVgqvwhqEJb0G225pgvQVuvb6LWumD0TXeyl+q9ZBD2jgBVQyCEzVr1afi2143vZVFmExPZkS/twVnfYO26HKv2br9w02bQ2t4pzkQk9ToDdn2tJxEMR6H/LifsPVON2fPH32g4xwXNcHpPI6xOg9v9k+f8eWQ69tmTzLRxjXX6ushkFmgGO7fawJSdqFglvvsV1zOowncqkF6TC/QoRODXSi0PSBXn5uas9jQrVQtblwto/z67t+ZRY/YQ8dau1YWCF+5BjYFPmvAN2rh9PR/1ZbQbSt8Sg8yBxd6dRUZUQemdFzRx6Q2ByVunu2uLoVdildlsbvELVr/ZxX++Xh6/CcwT2EEPqHK2ffM4gMnso95bX6/Jdnk1NeY+rb6SZzGnlqGUuKmjogVuHGoV2E1usolCBH4tqCaPOj8gZjtrcH1cXVi5gls9zmAH123EuVkLXY+YQDl8QoOMZhNfjHrT2rphL5Zmd9cFnc/Dx65/texhoZHVOjO5QKoC09RTMmnzetm8BsevSXsNRHA8Qw/hYPI4Mo2JqOYgp+HyNPySZs7xGqpyg+PlNOkwzdpREIgGmFdklMBv/kFfnzdYAxWkavPw9YhbCBH4tRAyKFgPVFujT+gqAtPSuLzuvWuTVzCtnKULfUsjtNM1uMj54txUe91hrnDqAPiKjN9+H5KVt0iKp+E75gxXYCnX7WnA5t6QHptH70moQt7RyFWTkGeeMsXHUbXyYLwfXh6cUBfsiVnnqj2UoM++uVHyx/YxePqE2MrDFoPXGwLfeIHSluurjBmfnSiB3kDtu1Xj7YjArwXN/FBP4tgaAy+lMlPXEXiefdi8GpS7TbGzOy9Z2Evvsi7HgXV446IIe2vpRts1UBtgdHo4PvOD21go7pi6ecJNn7TrLbrjGgGTh8FDSfeE8feOSl7vZl1OG7wNC2gXNqjLvt/lfPKd/7oN33ycJpTVMRylrvXnzV2/t2uTf/A252j5lokxloYf0isOXVBddSKoRsOvxnQaNVaQQB5VUWM+IvBbiMBDqgprzbZd1rtFfajcQb1itEuc7rFUyUOp5KmG9dU1rICmqOcbJhi0azK9ND5TmSOMlFWpyplDfKYwe5/ZBFTOw8cklAd8jZBZ6IebpPyNkp53yb8Qijpuo+Fr7BUnBd+9CukZlrvX6jafaUlFv796Qx/VUwg7P0lMvY96NAI19nLKCfwkgqcJALA+D9zdaX0DyOeBzk7rO+rY0G2GcwpX5lEsAoWCvX18FqAMMD6L7MW/RKajiNysxSj+YD9cfcE9yGSA7PxO6xiHCTlgew/AJet7WgE9j+ZQGshg2zb409cZn4UvoNf2npgVBGBaAbi0CEwrIJu1NhHB/Y31eWBFB7JnL0Kmo4jsOUv9+VIGGNlt/e/f4pXfkL7vt0J2fgaZjhKyM5dZaa7PA/teKVvsieN+C7hRKTvQ8+h8AED+uwuVo7w6yXSUlP8EJ1qmlwYAMIZ0vgmA0d21GcUf7IfCVdcCAApXXYvurs3uPi8967+Vr/cfABavyhvzy81ehsJXtyI7s8e67ot/adXjOyZaz9uDx7nPXfbDa6x6v/hx5O8soPPyt5G/eRKyWes+AQNWvTnn9i4J3gPAqtPtPVb9Tit4z3bvYmTPWWrlMXOZ75T8Tx5B5+X7kP/uIivN3sXuOdb/JVZZV5D1rT6/6/MAO0EDyVymWlmft9IF2e+AjVqOpFDe6cQJawnS8GkqDV9rlSue5RfVqlfS6sfRRLT/jeje+vIwnW+aTKWb0lSzTRKald5jWU7WXAgn1ozPbl7yjW+Y7OmOnT7KzKKOQZiWcQx6RZniHnlafDmTkZuubzBdC6CneETxiozr3klUCj43gV6Qbo7Txp4Cprage3PAlBgSIsPYQ9U9w6Kei7jPrmrO1d+puCaoRpmBFCAmnQZQiQA1HavbrCPOKXuM+hDqZo4y9veKhX4UWpl9jaCpUdIFfZyufK3lU4S8KsCME5Vy/vNU/35daJuFsMn0420Lzh3w2+F5eYc2xqC7eZbzODJE8VQaO5+p5d7RSvk9F1l94NmXhq7oqN5lMe5Z6PiV+hyEjadV+kyEKU/q+6FPSNTfWX3horAxvkFwARWBn3ICvYEoW3TYA648XLkcuxqaq21F2N+NvZJaBKz2sEdq+GFam0Jko1RJeQPavffxDUCWq2vl43nebDJMrIp2+TR7VdlCdnbB1cJVF01fD2HOasNMYjWPUlBI2QLOFPZC/e+/HseVlCpSdBJXKKKIa/93toX1JjRhnjv3dl9j6x5XSRnqiAj8lJPLeb7OuRz7hZ0qWPQBKl1rUDSgwECbruGHCFO3HI6g046t6KWt5WGPHHQtmstTiUZlv+SBIHVxNEiDgCg3VyDoVWN9qy6fgThEmtAxzS3wm3icGcD+3oW+1gHpgt8g4HUTl5qmK+QqNJvU3Q1SzzPC1KO6+hqFvHZ8bs5qw9KiyuTDlCACv1Ya0Er7XoaAGUYT0Iby6LZTR8MHtLC59vlh8dBDY66YzDJq3g3S3HS3vrK9I9N/neUUEKCBxiKsEdEESjA+jqfZ67GJzDb5ATdchC/95fqkLCu8sjPJyj/py8tTb0Ry595unDQWMOloWr/XY9FnBSvpl+ltuveuiuck1jluj5DC3xNDeQL3XW349Jm/6/xhJgLnNlCDj0IEfq00wA5Xic3fhMl2Wk6jCtunmjJcIaAc4/pqd0enFZtKhHQ5E4LpvKgBvXU57u7aZGl6R/WFmwCUsQ+rcS16k9PcbeaQDY5g1Se+OSab0EFWxY5cTtiE5ekKrwtWeGndOzo4F0MT7ta+Ray6fjpp6pPLQt08K52/Etaji/Ns6T3RGM8NM7vzCdTZyz5XZuVc/7iJNyGuu2tjqoQ9swj82vCZQSKCp1UgqKouS0gapgajVnuq6RhTyNyaNXy9QY3ZwMYy50RoedWU0de4aoOVJju9yXSiz+jVo6A6z5t6vB6DRw/noGr3wVm73setL4NZytP0i75Ac+qsZCiCL1TDNy3AErN+y95jExW8W7707Dz9jVjJ3xgyG3pAhutNESLwa8E0sBd1rEnghNjNKyLqJaqn6clOOzS0bgJpV+LVwRzDnBOVT9i+MJu9vc3V8BVTlyNIwiZT8XLyhavWNXa1AfCCxy30bdNdOMMndJVCPHfsxsV5fALPNnkDwu94LTDj2OkhGM2JulCO877EvTcJ4lNYnGfatc1rYSic+6uaeupYvKRMoyLwa0EX2OUe4HImBcVvvGrNO6oM9TQ9Ga6jGip9qAPH64I3qbED00B5FfXoCvULVgTGX/TxEdXNMWDHXx4eoTQY7kH9BMMxmLY7JiifgHMXjWfXXKQPCLsN/brgOgeB3kMtArxODYAxtIN7n0gLt130v/v1boxqNY3aiMBPgnI2yQpNOdXY1nU7spF14YOxNZPQC1jp4haB4+vVqEVp+GXKWBbluVGFrN5r9C07qLlG6ssY+m3pYSEYvJ5DcGzBysfvxcM+U1N310ZX+w2E6WC2GjAliJ1r50/qtsS5zxE9sdjn+BQ68mvzDep5MDeBhg9gNIBfAOi1vw8KOW4HrLVsny5XGP2TKoFfjgqFUFUafsw8UhcBUGuEIh9q7TrLafgNx+3tUfz7rd83Jw119qbBfq56/AQ9fEyfoEbvj/4ZNfFLW1dBE6KBgV5lmz+ipzeQXdG9qsasZ3onqnkX3RXCUH7gt0mop8C/DcCN9u8bAXw95LgdAA6uNP2mEfiNEEIx80jUzJEEiiYYqxEaTIEehcEbJLS+dcEepXFqi7KHm2U4sN1bCS3oH17uXH1xGNclUy+bI7z1cSi74TO5NwZMY1H3tZqeWzUavnZ+wHxT7rw0P5sK9RT4zwJ4l/37XQCeDTku3QK/SW5kJPW4jgRssbHMTM1wDyoxz1UqwBSBGozFM6CYWzwPGX2lL5PWbu4JlJnpazJ16L0TVQtfTp4Z6Kg+v9mxXCyaGHVbd1QnhDjZ1nOMLEHqKfD3aP//EnLcHwD8GsBTAOZFpDkPwAYAGw4//PD61oxDk9zISKp1Z0wgTZdqX9wmvQeRGn4l9WALfH01ru6uTcwrhliNgT15yp2gtU6fEBTnE/TccbVz5bosW3/JGoCO45mjU4mGX22d1UKl+TWDUsI1CnwAqwBsMXwurEDgj7O/DwGwEcBZUfmyaPgWcQaEHQ0q5uIRsez8cU0SOtUK7jTfg3ph1Ji9uDVEpUB9qP7+udkFV0sNN92EbfNr+q79fp2+brJ5clWswfc4c1dU0tgLSGMZIhh0k452zi0APhcn/aaw4Vf7AMQ9L+wlUG2qFfr4V6ydVUITvBB1R7d9m+ojbK3kcit6sbrEpRfZ0u/RY7bzl28EBtzeg276IRqwNHzNQ63SwfeydRRVb/Zv38BxpemFUenz2gQ90XICn6z91UFE3wCwm5lvJaIbAYxm5s9rxwwH0MHMr9m/fwHgy8z8n1HpT506lTds2FB1+RrC3Z0Al6wFCy4tVn4eYC1Ioi3U4S4i8Y6JwKvbvMUkTOeP7DYfEwd9sYqo7UI06jMBmJ+PFcoiMur9V7cDyN9pLU6TzXqL0uTzQM9Sa4EYZ9EUgICPDyA/dw0W/+h98BZCMcEYPXw3XvnrGADA6OG70f/GKJQGOgB3TSR29+2+/VDvWQOs5+2CzeXrIOr5UZ9fZ7EP0/Ot1GHn5ftQGuhEpqOI4pP/EH68U89x3s1K398meC+I6ClmnmraV+uKV7cCmE1EvQBm2/9BROOI6CH7mHcCeJyINgJYB+DBOMI+jRhXsap2dRp91RwdZyWdV7cZV25y852Qs14+0zFxCFuxJ2TFKMGAvlqZ+kyYng91VbOR3f46npDzVvaiDHoeyaJUsgQ8VnQA6/MoFGAJPOqwV4laCEdAr/31eACE0cN3gzBgb/d/urs2o/+NUQAImY6SLew77ebBOc5qMF756xjvGhz6t/guX30v3N93FqzznBWpdNw0Q1aoMtRh9gM/9FZCK3d8uW1h5Yj7/sZ9L6JWsBsswlT/NHzSZtJJ3Mc9jn2+3qYRMcFUhqm+YnTzfSYQw2Bmbs5qd796rDPxSQ3R4GAKmGcK7eCYQtTJU555ZJEv5IPuZjl6+MvetYbM9FZXqzLOUi1n/gh7/irdXgcqcm7QGUTTD2SmbTLU9AAIrYHpRY4hhMIWCHfSU+cqBBZxN8VyWtltdCk0T7TSvX42+tJyzgksqKJORjJcp/M+uAvfzy4Exx+qFc4psJXXpOANoiIlAl8QkqLKF9lVFmYX/Nq9M53fpOEbVsByY7WHxVUK+PJ7gdd84RGU+DC6h48bPiEiWJ8xeF1U+I+46IO2aroNEqbNquCJwG9VxBzTPJjcXKO0WNuTR4+pE9D8Def4GgglNo8aFdIR5rqG7y6JaXsAhcWP8tZ1tcMp2HMF+N7RldVJ2POrCnrTJ8WeMoNJOYFf66CtUE+iBn7CBlwHGePgdrvTu9i6V/1bgEuLOO5TBdDH9+G4GzYh/5NH0JkpIX/uYuteO/f9kLOsgdtH51uDqgRr0PLiX3qDuxNy/vp+dZubZeGqa1H8wX4ofKbHHXRlJgAd6Hl0vn0UY/PXjwev2A+7l421jr/qWqus+14BAOS/lQ3ez+09KFyZt4+/xk7qLet73yvAg8cBd3ciP3dN+LPQu8TKp3eJuc6298AZjDYyPlv54GhaB1MbRE1umfWmKdwy60mUy1hKXcQ6O4FSCchkgGIFnqotzYoOuN4vHx8AkeMJwyAwGB2Wu+FdQ63jnfs+Pov8zZPQ80gW2fkZ1zVTxa3vjhKKP9jPywcMUAb5x4voWVrCABOYrXLkZhVsl07yjh85SfHAcbbDc4dU7+f6vNWIqdAQT+gDyH93IRavygMg87OguqB+nL10HXfk/q0IFfiOa6gpDRX1HQG8MlfqRt1E1NMtU6gnUS5jKXWdzGYtYZ+t0FO1pZlwtfd7fR7dXZvhCFoGee6GuivntAIKP8+hWDIIe1tbzX54jVXfM/0acf67C9H5ibeweDFQGsiAuQOZjhJys5d4Wv+Eq23tn63egeN+SR1WLwJA9pweZDpK/vs5rQDsN1q5vhxw6ZvuOQDsXoQlkH3nOlr2yG57A7k9Al9PyG6w8HH29WjwcbaEva6lm7R2tRes9oQrdaNuFcJsPWn4iA1faClUm/1yUrxnSr4QBL7BwnVK8Lk5q/0277DgZrbd241XT+VdQn3jCrpdvdw4g7NPH6R1F0FfVD7UtzMgbLDPhy4mzuzzUPJ5FIXORqdkB3tTPnYGGbQVkqJZPRdSgeZ5EhZF1Of9skIJL63HtIkI2+AGWlOFpirk9cFPPT1VYJpiKoWFh4gQiMG5BdqA74qMtxShaVx2ub4amPWdu2CF/7h6uXamwGW0HOUEvph0Wp2EB6l6eix7cU+6xolr58HjLHvwg8fVLw/VBFfGVOMziY3PIjtzmWVSufiX8WaF2gO3hSv+3hpUvXimuyt/ZwGdlxeR/7ZiYnLS050AnG/qsNLUHQSUAWJfmSJMjT33TUdpoNNn8nFt/8V+4NIisvMz4WbBkd3InrMUmY6izzTW87O5/oHinzxipz2QzPPvvEvvmFjd7Po0ENYSpOEjGn4CJBwyuWU1/DA3xzRTLrBeSBRVbxHvfdHBxqKCwFVo2ghMKGHAjAAADSJJREFU1LJNVj5//zizzu2eh7MusLNMo74WsNNDqmainJGUa/YOEJNOwqTchucjjq9zVBe6HSi3ZnEKMDa0uo06DEVQ5WYt8tu8q3iGq230Q2euRjW2uqDVZid75i4KhKnwzRdQZv9WtPCJQ5O89yLwk6ZJWvpY2NeSm11oTc29RYhcWUsdiNVRBVUCk5eqDTkQ2lBEzOiN0vBd7T5EEPtCVdg9noqW3WwyROAnTQ0tfepMImWuJXVlbRcM9yT0Xrga66J4MWxMnjkxMZpkkqCa98nUeIWQy9kLlVeq4TeJRq9TTuDLxKsG00yTkoxlTelkr5ZCn3AXo847MyWUBjLW5Ku7hpSPNV8lqXx2q3keQ86x1hkoITuzB4WvbvUGsaMmaaXsnZCJVymimSYlGcvqvAS9i+vv1dKu6BPu1DoP8TZxvVrmZ6JjzQN+762YnlzZrDWbN3tOeDmM1DOcgeYRFCusR4gXUU+PNUGt55F5ngCP442T0hAnJkTDFyrD0WbUFZBMU9qF5FDDGMQICZDPW8Ir++E1lkumSfMMW5XLWbQkaqWqSkITVLsqXBX4ejqlTPmDNc3ct5LYZ3qiV/UKSWewEQ1fSA5HO3KmxbvT49uIRgfgmlbwQgvE8P1250rcNz2oyTrzDTpHmlflitBW8z95xFply/FxjyCfBzo/8Za3AlY9UO5HdmaPFaZiplf+UK1fu9ZCASjeNdSKMaTMMcjn4Q9up5PSECdGwoz7afikdtBWSCeNGmSrt5dWjddRdrA9apAzIu+4HjpOGYiq8+ipCFO4CKX8oWWOObcgMHch5aBeXjoA5gLYCmAAwNQyx50H4FkA2wHcGDf9tAh88VZpEhrlLlvvhqWe11HjfIO474IjZB1BW9d3JyqUQ0SZI/e7cf/DXT/TRD0F/kQARwNYHSbwAWQA/A7AUQD2B7ARwLFx0k+LwE98LVuhLrgxWkwBt5qJJnUHVGkmJSny/W6y+1E3ge8mUl7gnwbgYeX/TQBuipNuWgR+Mz28TUlCL1S9G2Z5DlqTVruv5QR+Il46RLQawOeYOeBSQ0RzAJzHzH9n/78cwCnMfE1IWvMAzAOAww8//KTnn3++5vIJKSchLw7XOyUL40IhtZJKP3RB0KjJS4eIVhHRFsPnwrj5G7aFtjLMvIyZpzLz1LFjx8bMQmhq4vo7R1AoWIK4HsIeaK45FInQ5ssBxqWZlvRshIZ/GoBbmPn99v+bAICZ/zkqXfHDF4RBpIH+881M2np+g+2Hvx7ABCI6koj2B3AJgAcakK8gpBOT5pxGbTqhnldTUcV9aKaeX00Cn4g+TER9sAZmHySih+3t44joIQBg5iKAawA8DGAbgHuZeWttxW4gaXwRq6CZup0tifocmSY3hU14Gsznr5kmFCVFFWES6m1KTJKaBD4z38fMXcw8hJnf6ZhtmHknM5+vHPcQM7+Xmf+Gmb9aa6EbShPFyShHy65U1QTk80Dnqd9G/o5vhcdoCdOmW+T5axpavFcjoRWiaJEHoJm6na1EPg8sXszekn5OvBVdczZtW5+3YxZR0z9/TUOL92pE4EcR9gAk0NVupJmlmbqdrYTVoyIAjOzMZZUJEnVN2UYKoBYxYwpBRODHwfQCJNDVFjNLi6IsiO6EFM7NXmLFWK+EwepdihmpZRGBHwfTC5DAyyhmlpRTrabbv8X9LhSAYimDws9zlWvpg2VeaBEzZuK0QM9H4uHHIWXxroUGUa0f+gplrqGsFdA6NMm8hMH2w29+WnwgRwhBNF1BpQWeBxH4ghBGtQ39hBzciCLr8zIHwkQzmkdaQPETgS8INRIQ6NMKlmcNAGzvQc/SkjU4v7QUmkY7EZiXUA+asUFpACLwBaFGjN5WSvfftOyejzYTTtZi4cq8hHognkZGROALQo0Yva2c7j9gLfwEACMnmRNoM+Hk1tf8zvqZR1rA3l4PxEtHEOrJ3Z3o/MSbKA10hkdTFC+wdNAi90G8dITytJlJoaGMzyI7cxkyHSVfD8Bn92+BwcCmodyz3gY9LdHwhabxL24l0hZDvW0o96yLhi+0BWLvbDgNm2UtvTc/zjPOA8E6aYOelmj4gpBCElufV3pvQVq8TkTDF4QmI7HAetJ7C9LGdSICXxBSSGImnzYwU1RMG9eJmHQEQRBaiLqZdIhoLhFtJaIBIjJmYB+3g4g2E9HTRCQSXBAEYRCo1aSzBcDFANbGOPZsZp4S1vK0FeI5IQjCIFDrIubbmPnZpArTNrTBBA9BENJHowZtGcDPiegpIprXoDzTSxt7CQhCU9CivfDIQVsiWgXgUMOum5n5fvuY1QA+x8xG+zwRjWPmnUR0CIBfALiWmY1mILtBmAcAhx9++EnPP/983GsRBEFIhib21a9p0JaZZzFzt+Fzf9wCMPNO+/slAPcBOLnMscuYeSozTx07dmzcLIQ4tKjW0lTIPWgOWrQXXneTDhENJ6IDnd8AzoU12Cs0Ghk7GHxi3gNZJWuQaVFf/VrdMj9MRH0ATgPwIBE9bG8fR0QP2Ye9E8DjRLQRwDoADzLzf9aSr1AlLaq1NBUx70FiM20FQUEmXglCCkkslo7QdkgsHUFoMgoFK2xyVcJexgmEEETgC0KrIWM1Qggi8AWh1ZCxGiEEEfhC+hETRWW0qIeJUDsi8IX0IyYKQUgEEfhC+hETRcMQ///WRtwyBaFdiLFItyyu3vyIW6YgCLFMYw1bXF0YFETgtzMyGNpexDCN1eT/L6QeEfjtjAyGtiZhDbl471RGCypEIvDbGRkMNdL0A5fSkCdDC9ajCPx2RjQ+I00fuEwa8mRowXoUgS+0Bgl2v5t+4FIa8mRowXoUt0yhNWjiFYoEIUnELVNofVqw+y0ISdM52AUQhESYVmiprrcg1APR8AVBENoEEfiCkBRp8NtOQxmE1CICX2gcrS6M0uC3nYYyCKml1kXMv0FEzxDRJiK6j4hGhRx3HhE9S0TbiejGWvIUmphWF0ZpGDhOQxmE1FKTWyYRnQvgUWYuEtHXAYCZb9COyQB4DsBsAH0A1gO4lJl/G5W+uGW2GDGiNQqCUBvl3DJr8tJh5p8rf58EMMdw2MkAtjPz7+3C/DuACwFECnyhxRBPGkEYVJJ0y/wUgHsM2w8D8ILyvw/AKWGJENE8APPsv68T0bM1lutgAH+uMY3BoFnLDTRv2aXcjUXKXR+OCNsRKfCJaBWAQw27bmbm++1jbgZQBLDclIRhW6gdiZmXAVgWVa64ENGGsO5NmmnWcgPNW3Ypd2ORcjeeSIHPzLPK7SeiKwB8EMBMNg8I9AF4t/K/C8DOSgopCIIg1E6tXjrnAbgBwN8y896Qw9YDmEBERxLR/gAuAfBALfkKgiAIlVOrH/4iAAcC+AURPU1ESwGAiMYR0UMAwMxFANcAeBjANgD3MvPWGvOthMTMQw2mWcsNNG/ZpdyNRcrdYFIdLVMQBEFIDplpKwiC0CaIwBcEQWgTWk7gE9FcItpKRANEFOo6RUQ7iGizPfYw6NN5Kyh3qsJUENFoIvoFEfXa3weFHJeK+o6qP7JYYO/fREQnDkY5dWKUewYR9dv1+zQRfXEwyqlDRHcQ0UtEtCVkf1rrO6rcqazvSJi5pT4AJgI4GsBqAFPLHLcDwMGDXd5Kyg0gA+B3AI4CsD+AjQCOHeRy3wbgRvv3jQC+ntb6jlN/AM4H8DNY80dOBfDfKXg24pR7BoCVg11WQ9nPAnAigC0h+1NX3zHLncr6jvq0nIbPzNuYudbZuQ0nZrndMBXM/DYAJ0zFYHIhgO/Zv78H4KJBLEsUcervQgDfZ4snAYwionc1uqAaabzvsWDmtQBeKXNIGus7TrmbkpYT+BXAAH5ORE/Z4RyaAVOYisMGqSwO72TmXQBgfx8Sclwa6jtO/aWxjuOW6TQi2khEPyOiSY0pWs2ksb7j0nT13ZRLHMYJ9xCDM5h5JxEdAmsewTN2q143Eih3RWEqkqJcuStIpuH1bSBO/Q1KHUcQp0y/BnAEM79OROcD+A8AE+pestpJY33HoSnruykFPkeEe4iZxk77+yUiug9Wt7muAiiBcg9KmIpy5SaiF4noXcy8y+6KvxSSRsPr20Cc+ktjKJDIMjHzq8rvh4hoMREdzMxpDvIFpLO+I2nW+m5Lkw4RDSeiA53fAM4FYByNTxlpDFPxAIAr7N9XAAj0VFJU33Hq7wEAn7S9R04F0O+YrAaRyHIT0aFERPbvk2G927sbXtLKSWN9R9K09T3Yo8ZJfwB8GJbW8BaAFwE8bG8fB+Ah+/dRsDwdNgLYCsukkvpy2//Ph7WgzO9SUu4xAB4B0Gt/j05zfZvqD8B8APPt3wSgYO/fjDKeXikr9zV23W6EtTbF6YNdZrtcdwPYBWCf/Xx/uknqO6rcqazvqI+EVhAEQWgT2tKkIwiC0I6IwBcEQWgTROALgiC0CSLwBUEQ2gQR+IIgCG2CCHxBEIQ2QQS+IAhCm/D/AXe6ZLHK9osvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Residuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Neural Network Residual Plot')\n",
    "plt.scatter(predictions1, predictions1 - y_train_scaled, c= \"orange\",label=\"Training Data\", s=4)\n",
    "plt.scatter(predictions, predictions - y_test_scaled, c= \"blue\",label=\"Testing Data\",s=4)\n",
    "plt.ylim(-2,2)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('neuralnetworkresidual.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the prediction with mse and r2\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_train = mean_squared_error(y_train_scaled, predictions1)\n",
    "r2_train = r2_score(y_train_scaled, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = mean_squared_error(y_test_scaled, predictions)\n",
    "r2_test = r2_score(y_test_scaled, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) Train Data: 0.19237321368001045\n",
      "R-squared (R2) Train Data: 0.8076267863199896\n",
      "-----------------------------------\n",
      "Mean Squared Error (MSE) Test Data: 0.18279156117870676\n",
      "R-squared (R2) Test Data: 0.8141481540685934\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Squared Error (MSE) Train Data: {mse_train}\")\n",
    "print(f\"R-squared (R2) Train Data: {r2_train}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Mean Squared Error (MSE) Test Data: {mse_test}\")\n",
    "print(f\"R-squared (R2) Test Data: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Volve",
   "language": "python",
   "name": "volve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
