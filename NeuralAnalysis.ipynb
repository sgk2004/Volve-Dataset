{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WELL_BORE_CODE</th>\n",
       "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
       "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
       "      <th>AVG_CHOKE_SIZE_P</th>\n",
       "      <th>AVG_WHP_P</th>\n",
       "      <th>AVG_WHT_P</th>\n",
       "      <th>DP_CHOKE_SIZE</th>\n",
       "      <th>BORE_OIL_VOL</th>\n",
       "      <th>BORE_GAS_VOL</th>\n",
       "      <th>BORE_WAT_VOL</th>\n",
       "      <th>FLOW_KIND</th>\n",
       "      <th>WELL_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>289.42</td>\n",
       "      <td>106.35</td>\n",
       "      <td>43.34</td>\n",
       "      <td>107.36</td>\n",
       "      <td>37.94</td>\n",
       "      <td>78.94</td>\n",
       "      <td>631.47</td>\n",
       "      <td>90439.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>270.24</td>\n",
       "      <td>107.64</td>\n",
       "      <td>47.17</td>\n",
       "      <td>99.19</td>\n",
       "      <td>60.76</td>\n",
       "      <td>70.63</td>\n",
       "      <td>1166.46</td>\n",
       "      <td>165720.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>262.84</td>\n",
       "      <td>107.87</td>\n",
       "      <td>47.73</td>\n",
       "      <td>94.60</td>\n",
       "      <td>63.05</td>\n",
       "      <td>66.05</td>\n",
       "      <td>1549.81</td>\n",
       "      <td>221707.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>255.53</td>\n",
       "      <td>107.97</td>\n",
       "      <td>48.53</td>\n",
       "      <td>89.99</td>\n",
       "      <td>64.55</td>\n",
       "      <td>61.41</td>\n",
       "      <td>1248.70</td>\n",
       "      <td>178063.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>247.20</td>\n",
       "      <td>108.05</td>\n",
       "      <td>49.84</td>\n",
       "      <td>84.78</td>\n",
       "      <td>65.72</td>\n",
       "      <td>56.15</td>\n",
       "      <td>1345.78</td>\n",
       "      <td>192602.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>8923</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.58</td>\n",
       "      <td>15.81</td>\n",
       "      <td>49.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>144.01</td>\n",
       "      <td>23201.35</td>\n",
       "      <td>203.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>8924</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.54</td>\n",
       "      <td>15.77</td>\n",
       "      <td>48.99</td>\n",
       "      <td>1.20</td>\n",
       "      <td>145.22</td>\n",
       "      <td>23068.07</td>\n",
       "      <td>202.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>8925</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.32</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.70</td>\n",
       "      <td>50.10</td>\n",
       "      <td>1.28</td>\n",
       "      <td>142.74</td>\n",
       "      <td>23059.68</td>\n",
       "      <td>203.84</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>8926</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.21</td>\n",
       "      <td>106.51</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.61</td>\n",
       "      <td>49.84</td>\n",
       "      <td>1.20</td>\n",
       "      <td>144.46</td>\n",
       "      <td>23090.47</td>\n",
       "      <td>202.76</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>8927</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.31</td>\n",
       "      <td>106.51</td>\n",
       "      <td>24.92</td>\n",
       "      <td>15.76</td>\n",
       "      <td>48.73</td>\n",
       "      <td>1.30</td>\n",
       "      <td>106.30</td>\n",
       "      <td>17537.08</td>\n",
       "      <td>155.70</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5943 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  WELL_BORE_CODE  AVG_DOWNHOLE_PRESSURE  \\\n",
       "0             15   NO 15/9-F-1 C                 289.42   \n",
       "1             16   NO 15/9-F-1 C                 270.24   \n",
       "2             17   NO 15/9-F-1 C                 262.84   \n",
       "3             18   NO 15/9-F-1 C                 255.53   \n",
       "4             19   NO 15/9-F-1 C                 247.20   \n",
       "...          ...             ...                    ...   \n",
       "5938        8923  NO 15/9-F-15 D                 194.98   \n",
       "5939        8924  NO 15/9-F-15 D                 194.98   \n",
       "5940        8925  NO 15/9-F-15 D                 194.32   \n",
       "5941        8926  NO 15/9-F-15 D                 195.21   \n",
       "5942        8927  NO 15/9-F-15 D                 195.31   \n",
       "\n",
       "      AVG_DOWNHOLE_TEMPERATURE  AVG_CHOKE_SIZE_P  AVG_WHP_P  AVG_WHT_P  \\\n",
       "0                       106.35             43.34     107.36      37.94   \n",
       "1                       107.64             47.17      99.19      60.76   \n",
       "2                       107.87             47.73      94.60      63.05   \n",
       "3                       107.97             48.53      89.99      64.55   \n",
       "4                       108.05             49.84      84.78      65.72   \n",
       "...                        ...               ...        ...        ...   \n",
       "5938                    106.52             31.58      15.81      49.02   \n",
       "5939                    106.52             31.54      15.77      48.99   \n",
       "5940                    106.52             31.52      15.70      50.10   \n",
       "5941                    106.51             31.52      15.61      49.84   \n",
       "5942                    106.51             24.92      15.76      48.73   \n",
       "\n",
       "      DP_CHOKE_SIZE  BORE_OIL_VOL  BORE_GAS_VOL  BORE_WAT_VOL   FLOW_KIND  \\\n",
       "0             78.94        631.47      90439.09          0.00  production   \n",
       "1             70.63       1166.46     165720.39          0.00  production   \n",
       "2             66.05       1549.81     221707.31          0.00  production   \n",
       "3             61.41       1248.70     178063.52          0.00  production   \n",
       "4             56.15       1345.78     192602.19          0.00  production   \n",
       "...             ...           ...           ...           ...         ...   \n",
       "5938           1.26        144.01      23201.35        203.93  production   \n",
       "5939           1.20        145.22      23068.07        202.93  production   \n",
       "5940           1.28        142.74      23059.68        203.84  production   \n",
       "5941           1.20        144.46      23090.47        202.76  production   \n",
       "5942           1.30        106.30      17537.08        155.70  production   \n",
       "\n",
       "     WELL_TYPE  \n",
       "0           OP  \n",
       "1           OP  \n",
       "2           OP  \n",
       "3           OP  \n",
       "4           OP  \n",
       "...        ...  \n",
       "5938        OP  \n",
       "5939        OP  \n",
       "5940        OP  \n",
       "5941        OP  \n",
       "5942        OP  \n",
       "\n",
       "[5943 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data csv\n",
    "all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "all_wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUTS: AVG_CHOKE_SIZE_P, AVG_WHP_P, AVG_WHT_P, BORE_OIL_VOL, BORE_GAS_VOL, BORE_WAT_VOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5943, 6)\n"
     ]
    }
   ],
   "source": [
    "#read in data for analysis \n",
    "X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = X_train.shape[1]\n",
    "number_hidden_nodes = 100\n",
    "\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(number_hidden_nodes, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "from keras import losses\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",\n",
    "              optimizer=\"adam\", metrics=[r_square, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,901\n",
      "Trainable params: 10,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "1263/1263 - 1s - loss: 0.6295 - r_square: 0.2888 - rmse: 0.6295 - val_loss: 0.5027 - val_r_square: 0.4800 - val_rmse: 0.5027\n",
      "Epoch 2/100\n",
      "1263/1263 - 0s - loss: 0.4379 - r_square: 0.5815 - rmse: 0.4379 - val_loss: 0.3834 - val_r_square: 0.6321 - val_rmse: 0.3834\n",
      "Epoch 3/100\n",
      "1263/1263 - 0s - loss: 0.3392 - r_square: 0.7095 - rmse: 0.3392 - val_loss: 0.3203 - val_r_square: 0.6846 - val_rmse: 0.3203\n",
      "Epoch 4/100\n",
      "1263/1263 - 0s - loss: 0.2806 - r_square: 0.7715 - rmse: 0.2806 - val_loss: 0.2980 - val_r_square: 0.6926 - val_rmse: 0.2980\n",
      "Epoch 5/100\n",
      "1263/1263 - 0s - loss: 0.2442 - r_square: 0.8188 - rmse: 0.2442 - val_loss: 0.2839 - val_r_square: 0.6923 - val_rmse: 0.2839\n",
      "Epoch 6/100\n",
      "1263/1263 - 0s - loss: 0.2244 - r_square: 0.8215 - rmse: 0.2244 - val_loss: 0.2767 - val_r_square: 0.6800 - val_rmse: 0.2767\n",
      "Epoch 7/100\n",
      "1263/1263 - 0s - loss: 0.2203 - r_square: 0.8315 - rmse: 0.2203 - val_loss: 0.2647 - val_r_square: 0.6862 - val_rmse: 0.2647\n",
      "Epoch 8/100\n",
      "1263/1263 - 0s - loss: 0.2138 - r_square: 0.8322 - rmse: 0.2138 - val_loss: 0.2555 - val_r_square: 0.6732 - val_rmse: 0.2555\n",
      "Epoch 9/100\n",
      "1263/1263 - 0s - loss: 0.1979 - r_square: 0.8511 - rmse: 0.1979 - val_loss: 0.2399 - val_r_square: 0.6812 - val_rmse: 0.2399\n",
      "Epoch 10/100\n",
      "1263/1263 - 0s - loss: 0.1942 - r_square: 0.8578 - rmse: 0.1942 - val_loss: 0.2391 - val_r_square: 0.6741 - val_rmse: 0.2391\n",
      "Epoch 11/100\n",
      "1263/1263 - 0s - loss: 0.1879 - r_square: 0.8559 - rmse: 0.1879 - val_loss: 0.2352 - val_r_square: 0.6673 - val_rmse: 0.2352\n",
      "Epoch 12/100\n",
      "1263/1263 - 0s - loss: 0.1891 - r_square: 0.8631 - rmse: 0.1891 - val_loss: 0.2317 - val_r_square: 0.6539 - val_rmse: 0.2317\n",
      "Epoch 13/100\n",
      "1263/1263 - 0s - loss: 0.1801 - r_square: 0.8680 - rmse: 0.1801 - val_loss: 0.2258 - val_r_square: 0.6587 - val_rmse: 0.2258\n",
      "Epoch 14/100\n",
      "1263/1263 - 0s - loss: 0.1703 - r_square: 0.8664 - rmse: 0.1703 - val_loss: 0.2160 - val_r_square: 0.6486 - val_rmse: 0.2160\n",
      "Epoch 15/100\n",
      "1263/1263 - 0s - loss: 0.1645 - r_square: 0.8683 - rmse: 0.1645 - val_loss: 0.2178 - val_r_square: 0.6351 - val_rmse: 0.2178\n",
      "Epoch 16/100\n",
      "1263/1263 - 0s - loss: 0.1643 - r_square: 0.8748 - rmse: 0.1643 - val_loss: 0.2248 - val_r_square: 0.6518 - val_rmse: 0.2248\n",
      "Epoch 17/100\n",
      "1263/1263 - 0s - loss: 0.1622 - r_square: 0.8754 - rmse: 0.1622 - val_loss: 0.2124 - val_r_square: 0.6399 - val_rmse: 0.2124\n",
      "Epoch 18/100\n",
      "1263/1263 - 0s - loss: 0.1642 - r_square: 0.8893 - rmse: 0.1642 - val_loss: 0.2053 - val_r_square: 0.6475 - val_rmse: 0.2053\n",
      "Epoch 19/100\n",
      "1263/1263 - 0s - loss: 0.1578 - r_square: 0.8770 - rmse: 0.1578 - val_loss: 0.2192 - val_r_square: 0.6391 - val_rmse: 0.2192\n",
      "Epoch 20/100\n",
      "1263/1263 - 0s - loss: 0.1651 - r_square: 0.8799 - rmse: 0.1651 - val_loss: 0.2041 - val_r_square: 0.6636 - val_rmse: 0.2041\n",
      "Epoch 21/100\n",
      "1263/1263 - 0s - loss: 0.1612 - r_square: 0.8787 - rmse: 0.1612 - val_loss: 0.2150 - val_r_square: 0.6512 - val_rmse: 0.2150\n",
      "Epoch 22/100\n",
      "1263/1263 - 0s - loss: 0.1529 - r_square: 0.8905 - rmse: 0.1529 - val_loss: 0.2109 - val_r_square: 0.6505 - val_rmse: 0.2109\n",
      "Epoch 23/100\n",
      "1263/1263 - 0s - loss: 0.1510 - r_square: 0.8736 - rmse: 0.1510 - val_loss: 0.2009 - val_r_square: 0.6438 - val_rmse: 0.2009\n",
      "Epoch 24/100\n",
      "1263/1263 - 0s - loss: 0.1496 - r_square: 0.8868 - rmse: 0.1496 - val_loss: 0.2005 - val_r_square: 0.6544 - val_rmse: 0.2005\n",
      "Epoch 25/100\n",
      "1263/1263 - 0s - loss: 0.1553 - r_square: 0.8930 - rmse: 0.1553 - val_loss: 0.2049 - val_r_square: 0.6291 - val_rmse: 0.2049\n",
      "Epoch 26/100\n",
      "1263/1263 - 0s - loss: 0.1502 - r_square: 0.8853 - rmse: 0.1502 - val_loss: 0.2009 - val_r_square: 0.6650 - val_rmse: 0.2009\n",
      "Epoch 27/100\n",
      "1263/1263 - 0s - loss: 0.1493 - r_square: 0.8780 - rmse: 0.1493 - val_loss: 0.1989 - val_r_square: 0.6470 - val_rmse: 0.1989\n",
      "Epoch 28/100\n",
      "1263/1263 - 0s - loss: 0.1508 - r_square: 0.8762 - rmse: 0.1508 - val_loss: 0.2059 - val_r_square: 0.6577 - val_rmse: 0.2059\n",
      "Epoch 29/100\n",
      "1263/1263 - 0s - loss: 0.1521 - r_square: 0.8912 - rmse: 0.1521 - val_loss: 0.1976 - val_r_square: 0.6596 - val_rmse: 0.1976\n",
      "Epoch 30/100\n",
      "1263/1263 - 0s - loss: 0.1463 - r_square: 0.8920 - rmse: 0.1463 - val_loss: 0.1974 - val_r_square: 0.6496 - val_rmse: 0.1974\n",
      "Epoch 31/100\n",
      "1263/1263 - 0s - loss: 0.1431 - r_square: 0.8893 - rmse: 0.1431 - val_loss: 0.1959 - val_r_square: 0.6504 - val_rmse: 0.1959\n",
      "Epoch 32/100\n",
      "1263/1263 - 0s - loss: 0.1425 - r_square: 0.8861 - rmse: 0.1425 - val_loss: 0.1938 - val_r_square: 0.6510 - val_rmse: 0.1938\n",
      "Epoch 33/100\n",
      "1263/1263 - 0s - loss: 0.1472 - r_square: 0.8845 - rmse: 0.1472 - val_loss: 0.2015 - val_r_square: 0.6484 - val_rmse: 0.2015\n",
      "Epoch 34/100\n",
      "1263/1263 - 0s - loss: 0.1440 - r_square: 0.8866 - rmse: 0.1440 - val_loss: 0.2026 - val_r_square: 0.6496 - val_rmse: 0.2026\n",
      "Epoch 35/100\n",
      "1263/1263 - 0s - loss: 0.1402 - r_square: 0.8868 - rmse: 0.1402 - val_loss: 0.2034 - val_r_square: 0.6651 - val_rmse: 0.2034\n",
      "Epoch 36/100\n",
      "1263/1263 - 0s - loss: 0.1372 - r_square: 0.8951 - rmse: 0.1372 - val_loss: 0.2038 - val_r_square: 0.6597 - val_rmse: 0.2038\n",
      "Epoch 37/100\n",
      "1263/1263 - 0s - loss: 0.1470 - r_square: 0.9015 - rmse: 0.1470 - val_loss: 0.1990 - val_r_square: 0.6638 - val_rmse: 0.1990\n",
      "Epoch 38/100\n",
      "1263/1263 - 0s - loss: 0.1393 - r_square: 0.8905 - rmse: 0.1393 - val_loss: 0.1972 - val_r_square: 0.6634 - val_rmse: 0.1972\n",
      "Epoch 39/100\n",
      "1263/1263 - 0s - loss: 0.1440 - r_square: 0.8968 - rmse: 0.1440 - val_loss: 0.2216 - val_r_square: 0.6732 - val_rmse: 0.2216\n",
      "Epoch 40/100\n",
      "1263/1263 - 0s - loss: 0.1405 - r_square: 0.8959 - rmse: 0.1405 - val_loss: 0.2015 - val_r_square: 0.6790 - val_rmse: 0.2015\n",
      "Epoch 41/100\n",
      "1263/1263 - 0s - loss: 0.1351 - r_square: 0.8987 - rmse: 0.1351 - val_loss: 0.1940 - val_r_square: 0.6713 - val_rmse: 0.1940\n",
      "Epoch 42/100\n",
      "1263/1263 - 0s - loss: 0.1388 - r_square: 0.8997 - rmse: 0.1388 - val_loss: 0.2023 - val_r_square: 0.6782 - val_rmse: 0.2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8b00f33c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping tuning #1\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10,verbose=0, mode='min')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486/1486 [==============================] - 0s 21us/sample - loss: 0.1491 - r_square: 0.8638 - rmse: 0.1491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1491281768334666, 0.86377335, 0.14912818]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "1263/1263 - 0s - loss: 0.1374 - r_square: 0.9003 - rmse: 0.1374 - val_loss: 0.1968 - val_r_square: 0.6748 - val_rmse: 0.1968\n",
      "Epoch 2/100\n",
      "1263/1263 - 0s - loss: 0.1350 - r_square: 0.8948 - rmse: 0.1350 - val_loss: 0.1882 - val_r_square: 0.6859 - val_rmse: 0.1882\n",
      "Epoch 3/100\n",
      "1263/1263 - 0s - loss: 0.1351 - r_square: 0.9055 - rmse: 0.1351 - val_loss: 0.1986 - val_r_square: 0.6768 - val_rmse: 0.1986\n",
      "Epoch 4/100\n",
      "1263/1263 - 0s - loss: 0.1376 - r_square: 0.9022 - rmse: 0.1376 - val_loss: 0.1898 - val_r_square: 0.6879 - val_rmse: 0.1898\n",
      "Epoch 5/100\n",
      "1263/1263 - 0s - loss: 0.1375 - r_square: 0.9036 - rmse: 0.1375 - val_loss: 0.2024 - val_r_square: 0.6869 - val_rmse: 0.2024\n",
      "Epoch 6/100\n",
      "1263/1263 - 0s - loss: 0.1358 - r_square: 0.9087 - rmse: 0.1358 - val_loss: 0.1878 - val_r_square: 0.6912 - val_rmse: 0.1878\n",
      "Epoch 7/100\n",
      "1263/1263 - 0s - loss: 0.1298 - r_square: 0.9048 - rmse: 0.1298 - val_loss: 0.2033 - val_r_square: 0.6876 - val_rmse: 0.2033\n",
      "Epoch 8/100\n",
      "1263/1263 - 0s - loss: 0.1371 - r_square: 0.9056 - rmse: 0.1371 - val_loss: 0.1907 - val_r_square: 0.6878 - val_rmse: 0.1907\n",
      "Epoch 9/100\n",
      "1263/1263 - 0s - loss: 0.1333 - r_square: 0.9130 - rmse: 0.1333 - val_loss: 0.2011 - val_r_square: 0.6907 - val_rmse: 0.2011\n",
      "Epoch 10/100\n",
      "1263/1263 - 0s - loss: 0.1290 - r_square: 0.9059 - rmse: 0.1290 - val_loss: 0.1902 - val_r_square: 0.6933 - val_rmse: 0.1902\n",
      "Epoch 11/100\n",
      "1263/1263 - 0s - loss: 0.1282 - r_square: 0.9046 - rmse: 0.1282 - val_loss: 0.1894 - val_r_square: 0.7045 - val_rmse: 0.1894\n",
      "Epoch 12/100\n",
      "1263/1263 - 0s - loss: 0.1287 - r_square: 0.9067 - rmse: 0.1287 - val_loss: 0.1923 - val_r_square: 0.6955 - val_rmse: 0.1923\n",
      "Epoch 13/100\n",
      "1263/1263 - 0s - loss: 0.1371 - r_square: 0.9053 - rmse: 0.1371 - val_loss: 0.1941 - val_r_square: 0.7065 - val_rmse: 0.1941\n",
      "Epoch 14/100\n",
      "1263/1263 - 0s - loss: 0.1337 - r_square: 0.9102 - rmse: 0.1337 - val_loss: 0.1894 - val_r_square: 0.7031 - val_rmse: 0.1894\n",
      "Epoch 15/100\n",
      "1263/1263 - 0s - loss: 0.1255 - r_square: 0.9021 - rmse: 0.1255 - val_loss: 0.1892 - val_r_square: 0.7127 - val_rmse: 0.1892\n",
      "Epoch 16/100\n",
      "1263/1263 - 0s - loss: 0.1289 - r_square: 0.9121 - rmse: 0.1289 - val_loss: 0.1830 - val_r_square: 0.7108 - val_rmse: 0.1830\n",
      "Epoch 17/100\n",
      "1263/1263 - 0s - loss: 0.1291 - r_square: 0.9029 - rmse: 0.1291 - val_loss: 0.1833 - val_r_square: 0.7110 - val_rmse: 0.1833\n",
      "Epoch 18/100\n",
      "1263/1263 - 0s - loss: 0.1249 - r_square: 0.9074 - rmse: 0.1249 - val_loss: 0.1824 - val_r_square: 0.7082 - val_rmse: 0.1824\n",
      "Epoch 19/100\n",
      "1263/1263 - 0s - loss: 0.1268 - r_square: 0.8985 - rmse: 0.1268 - val_loss: 0.1816 - val_r_square: 0.7138 - val_rmse: 0.1816\n",
      "Epoch 20/100\n",
      "1263/1263 - 0s - loss: 0.1277 - r_square: 0.9038 - rmse: 0.1277 - val_loss: 0.1834 - val_r_square: 0.7117 - val_rmse: 0.1834\n",
      "Epoch 21/100\n",
      "1263/1263 - 0s - loss: 0.1288 - r_square: 0.8973 - rmse: 0.1288 - val_loss: 0.1861 - val_r_square: 0.7217 - val_rmse: 0.1861\n",
      "Epoch 22/100\n",
      "1263/1263 - 0s - loss: 0.1290 - r_square: 0.9121 - rmse: 0.1290 - val_loss: 0.1899 - val_r_square: 0.7276 - val_rmse: 0.1899\n",
      "Epoch 23/100\n",
      "1263/1263 - 0s - loss: 0.1240 - r_square: 0.9109 - rmse: 0.1240 - val_loss: 0.1915 - val_r_square: 0.7151 - val_rmse: 0.1915\n",
      "Epoch 24/100\n",
      "1263/1263 - 0s - loss: 0.1220 - r_square: 0.9143 - rmse: 0.1220 - val_loss: 0.1820 - val_r_square: 0.7234 - val_rmse: 0.1820\n",
      "Epoch 25/100\n",
      "1263/1263 - 0s - loss: 0.1243 - r_square: 0.9156 - rmse: 0.1243 - val_loss: 0.1898 - val_r_square: 0.7181 - val_rmse: 0.1898\n",
      "Epoch 26/100\n",
      "1263/1263 - 0s - loss: 0.1351 - r_square: 0.9065 - rmse: 0.1351 - val_loss: 0.1958 - val_r_square: 0.7361 - val_rmse: 0.1958\n",
      "Epoch 27/100\n",
      "1263/1263 - 0s - loss: 0.1316 - r_square: 0.9059 - rmse: 0.1316 - val_loss: 0.2159 - val_r_square: 0.7222 - val_rmse: 0.2159\n",
      "Epoch 28/100\n",
      "1263/1263 - 0s - loss: 0.1287 - r_square: 0.9074 - rmse: 0.1287 - val_loss: 0.2055 - val_r_square: 0.7222 - val_rmse: 0.2055\n",
      "Epoch 29/100\n",
      "1263/1263 - 0s - loss: 0.1279 - r_square: 0.9111 - rmse: 0.1279 - val_loss: 0.1866 - val_r_square: 0.7332 - val_rmse: 0.1866\n",
      "Epoch 30/100\n",
      "1263/1263 - 0s - loss: 0.1234 - r_square: 0.9120 - rmse: 0.1234 - val_loss: 0.1883 - val_r_square: 0.7334 - val_rmse: 0.1883\n",
      "Epoch 31/100\n",
      "1263/1263 - 0s - loss: 0.1203 - r_square: 0.9050 - rmse: 0.1203 - val_loss: 0.1786 - val_r_square: 0.7396 - val_rmse: 0.1786\n",
      "Epoch 32/100\n",
      "1263/1263 - 0s - loss: 0.1263 - r_square: 0.9170 - rmse: 0.1263 - val_loss: 0.1769 - val_r_square: 0.7432 - val_rmse: 0.1769\n",
      "Epoch 33/100\n",
      "1263/1263 - 0s - loss: 0.1228 - r_square: 0.9166 - rmse: 0.1228 - val_loss: 0.1864 - val_r_square: 0.7346 - val_rmse: 0.1864\n",
      "Epoch 34/100\n",
      "1263/1263 - 0s - loss: 0.1228 - r_square: 0.9121 - rmse: 0.1228 - val_loss: 0.1763 - val_r_square: 0.7481 - val_rmse: 0.1763\n",
      "Epoch 35/100\n",
      "1263/1263 - 0s - loss: 0.1218 - r_square: 0.9174 - rmse: 0.1218 - val_loss: 0.1922 - val_r_square: 0.7433 - val_rmse: 0.1922\n",
      "Epoch 36/100\n",
      "1263/1263 - 0s - loss: 0.1357 - r_square: 0.9115 - rmse: 0.1357 - val_loss: 0.1814 - val_r_square: 0.7405 - val_rmse: 0.1814\n",
      "Epoch 37/100\n",
      "1263/1263 - 0s - loss: 0.1224 - r_square: 0.9125 - rmse: 0.1224 - val_loss: 0.1817 - val_r_square: 0.7521 - val_rmse: 0.1817\n",
      "Epoch 38/100\n",
      "1263/1263 - 0s - loss: 0.1349 - r_square: 0.9066 - rmse: 0.1349 - val_loss: 0.1896 - val_r_square: 0.7484 - val_rmse: 0.1896\n",
      "Epoch 39/100\n",
      "1263/1263 - 0s - loss: 0.1275 - r_square: 0.9128 - rmse: 0.1275 - val_loss: 0.2038 - val_r_square: 0.7389 - val_rmse: 0.2038\n",
      "Epoch 40/100\n",
      "1263/1263 - 0s - loss: 0.1243 - r_square: 0.9138 - rmse: 0.1243 - val_loss: 0.1745 - val_r_square: 0.7500 - val_rmse: 0.1745\n",
      "Epoch 41/100\n",
      "1263/1263 - 0s - loss: 0.1205 - r_square: 0.9173 - rmse: 0.1205 - val_loss: 0.1859 - val_r_square: 0.7518 - val_rmse: 0.1859\n",
      "Epoch 42/100\n",
      "1263/1263 - 0s - loss: 0.1312 - r_square: 0.9079 - rmse: 0.1312 - val_loss: 0.1798 - val_r_square: 0.7611 - val_rmse: 0.1798\n",
      "Epoch 43/100\n",
      "1263/1263 - 0s - loss: 0.1241 - r_square: 0.9133 - rmse: 0.1241 - val_loss: 0.1793 - val_r_square: 0.7570 - val_rmse: 0.1793\n",
      "Epoch 44/100\n",
      "1263/1263 - 0s - loss: 0.1235 - r_square: 0.9106 - rmse: 0.1235 - val_loss: 0.1912 - val_r_square: 0.7615 - val_rmse: 0.1912\n",
      "Epoch 45/100\n",
      "1263/1263 - 0s - loss: 0.1246 - r_square: 0.9133 - rmse: 0.1246 - val_loss: 0.1866 - val_r_square: 0.7612 - val_rmse: 0.1866\n",
      "Epoch 46/100\n",
      "1263/1263 - 0s - loss: 0.1201 - r_square: 0.9173 - rmse: 0.1201 - val_loss: 0.1755 - val_r_square: 0.7673 - val_rmse: 0.1755\n",
      "Epoch 47/100\n",
      "1263/1263 - 0s - loss: 0.1175 - r_square: 0.9171 - rmse: 0.1175 - val_loss: 0.1858 - val_r_square: 0.7559 - val_rmse: 0.1858\n",
      "Epoch 48/100\n",
      "1263/1263 - 0s - loss: 0.1216 - r_square: 0.9180 - rmse: 0.1216 - val_loss: 0.2000 - val_r_square: 0.7662 - val_rmse: 0.2000\n",
      "Epoch 49/100\n",
      "1263/1263 - 0s - loss: 0.1235 - r_square: 0.9157 - rmse: 0.1235 - val_loss: 0.1786 - val_r_square: 0.7754 - val_rmse: 0.1786\n",
      "Epoch 50/100\n",
      "1263/1263 - 0s - loss: 0.1219 - r_square: 0.9189 - rmse: 0.1219 - val_loss: 0.1821 - val_r_square: 0.7772 - val_rmse: 0.1821\n",
      "Epoch 51/100\n",
      "1263/1263 - 0s - loss: 0.1196 - r_square: 0.9193 - rmse: 0.1196 - val_loss: 0.2023 - val_r_square: 0.7697 - val_rmse: 0.2023\n",
      "Epoch 52/100\n",
      "1263/1263 - 0s - loss: 0.1200 - r_square: 0.9202 - rmse: 0.1200 - val_loss: 0.1836 - val_r_square: 0.7786 - val_rmse: 0.1836\n",
      "Epoch 53/100\n",
      "1263/1263 - 0s - loss: 0.1182 - r_square: 0.9212 - rmse: 0.1182 - val_loss: 0.1870 - val_r_square: 0.7718 - val_rmse: 0.1870\n",
      "Epoch 54/100\n",
      "1263/1263 - 0s - loss: 0.1176 - r_square: 0.9259 - rmse: 0.1176 - val_loss: 0.1812 - val_r_square: 0.7809 - val_rmse: 0.1812\n",
      "Epoch 55/100\n",
      "1263/1263 - 0s - loss: 0.1212 - r_square: 0.9180 - rmse: 0.1212 - val_loss: 0.1905 - val_r_square: 0.7732 - val_rmse: 0.1905\n",
      "Epoch 56/100\n",
      "1263/1263 - 0s - loss: 0.1184 - r_square: 0.9197 - rmse: 0.1184 - val_loss: 0.1755 - val_r_square: 0.7853 - val_rmse: 0.1755\n",
      "Epoch 57/100\n",
      "1263/1263 - 0s - loss: 0.1161 - r_square: 0.9219 - rmse: 0.1161 - val_loss: 0.1760 - val_r_square: 0.7860 - val_rmse: 0.1760\n",
      "Epoch 58/100\n",
      "1263/1263 - 0s - loss: 0.1222 - r_square: 0.9201 - rmse: 0.1222 - val_loss: 0.1984 - val_r_square: 0.7675 - val_rmse: 0.1984\n",
      "Epoch 59/100\n",
      "1263/1263 - 0s - loss: 0.1236 - r_square: 0.9196 - rmse: 0.1236 - val_loss: 0.1854 - val_r_square: 0.7886 - val_rmse: 0.1854\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1263/1263 - 0s - loss: 0.1186 - r_square: 0.9251 - rmse: 0.1186 - val_loss: 0.1772 - val_r_square: 0.7918 - val_rmse: 0.1772\n",
      "Epoch 61/100\n",
      "1263/1263 - 0s - loss: 0.1158 - r_square: 0.9237 - rmse: 0.1158 - val_loss: 0.1717 - val_r_square: 0.7905 - val_rmse: 0.1717\n",
      "Epoch 62/100\n",
      "1263/1263 - 0s - loss: 0.1156 - r_square: 0.9227 - rmse: 0.1156 - val_loss: 0.1730 - val_r_square: 0.7928 - val_rmse: 0.1730\n",
      "Epoch 63/100\n",
      "1263/1263 - 0s - loss: 0.1170 - r_square: 0.9204 - rmse: 0.1170 - val_loss: 0.1848 - val_r_square: 0.7883 - val_rmse: 0.1848\n",
      "Epoch 64/100\n",
      "1263/1263 - 0s - loss: 0.1164 - r_square: 0.9165 - rmse: 0.1164 - val_loss: 0.1755 - val_r_square: 0.7901 - val_rmse: 0.1755\n",
      "Epoch 65/100\n",
      "1263/1263 - 0s - loss: 0.1138 - r_square: 0.9223 - rmse: 0.1138 - val_loss: 0.1713 - val_r_square: 0.7948 - val_rmse: 0.1713\n",
      "Epoch 66/100\n",
      "1263/1263 - 0s - loss: 0.1157 - r_square: 0.9289 - rmse: 0.1157 - val_loss: 0.1777 - val_r_square: 0.7879 - val_rmse: 0.1777\n",
      "Epoch 67/100\n",
      "1263/1263 - 0s - loss: 0.1191 - r_square: 0.9276 - rmse: 0.1191 - val_loss: 0.1778 - val_r_square: 0.7897 - val_rmse: 0.1778\n",
      "Epoch 68/100\n",
      "1263/1263 - 0s - loss: 0.1129 - r_square: 0.9300 - rmse: 0.1129 - val_loss: 0.1774 - val_r_square: 0.7881 - val_rmse: 0.1774\n",
      "Epoch 69/100\n",
      "1263/1263 - 0s - loss: 0.1162 - r_square: 0.9221 - rmse: 0.1162 - val_loss: 0.1776 - val_r_square: 0.7975 - val_rmse: 0.1776\n",
      "Epoch 70/100\n",
      "1263/1263 - 0s - loss: 0.1167 - r_square: 0.9254 - rmse: 0.1167 - val_loss: 0.1724 - val_r_square: 0.8008 - val_rmse: 0.1724\n",
      "Epoch 71/100\n",
      "1263/1263 - 0s - loss: 0.1154 - r_square: 0.9228 - rmse: 0.1154 - val_loss: 0.1743 - val_r_square: 0.7955 - val_rmse: 0.1743\n",
      "Epoch 72/100\n",
      "1263/1263 - 0s - loss: 0.1132 - r_square: 0.9246 - rmse: 0.1132 - val_loss: 0.1789 - val_r_square: 0.7950 - val_rmse: 0.1789\n",
      "Epoch 73/100\n",
      "1263/1263 - 0s - loss: 0.1170 - r_square: 0.9235 - rmse: 0.1170 - val_loss: 0.1812 - val_r_square: 0.7996 - val_rmse: 0.1812\n",
      "Epoch 74/100\n",
      "1263/1263 - 0s - loss: 0.1149 - r_square: 0.9237 - rmse: 0.1149 - val_loss: 0.1824 - val_r_square: 0.7896 - val_rmse: 0.1824\n",
      "Epoch 75/100\n",
      "1263/1263 - 0s - loss: 0.1166 - r_square: 0.9261 - rmse: 0.1166 - val_loss: 0.1656 - val_r_square: 0.8053 - val_rmse: 0.1656\n",
      "Epoch 76/100\n",
      "1263/1263 - 0s - loss: 0.1172 - r_square: 0.9274 - rmse: 0.1172 - val_loss: 0.1801 - val_r_square: 0.8025 - val_rmse: 0.1801\n",
      "Epoch 77/100\n",
      "1263/1263 - 0s - loss: 0.1122 - r_square: 0.9293 - rmse: 0.1122 - val_loss: 0.1697 - val_r_square: 0.8046 - val_rmse: 0.1697\n",
      "Epoch 78/100\n",
      "1263/1263 - 0s - loss: 0.1095 - r_square: 0.9279 - rmse: 0.1095 - val_loss: 0.1735 - val_r_square: 0.8031 - val_rmse: 0.1735\n",
      "Epoch 79/100\n",
      "1263/1263 - 0s - loss: 0.1123 - r_square: 0.9272 - rmse: 0.1123 - val_loss: 0.1685 - val_r_square: 0.8147 - val_rmse: 0.1685\n",
      "Epoch 80/100\n",
      "1263/1263 - 0s - loss: 0.1168 - r_square: 0.9270 - rmse: 0.1168 - val_loss: 0.1789 - val_r_square: 0.8025 - val_rmse: 0.1789\n",
      "Epoch 81/100\n",
      "1263/1263 - 0s - loss: 0.1142 - r_square: 0.9275 - rmse: 0.1142 - val_loss: 0.1699 - val_r_square: 0.8119 - val_rmse: 0.1699\n",
      "Epoch 82/100\n",
      "1263/1263 - 0s - loss: 0.1101 - r_square: 0.9266 - rmse: 0.1101 - val_loss: 0.1770 - val_r_square: 0.8057 - val_rmse: 0.1770\n",
      "Epoch 83/100\n",
      "1263/1263 - 0s - loss: 0.1141 - r_square: 0.9266 - rmse: 0.1141 - val_loss: 0.1677 - val_r_square: 0.8076 - val_rmse: 0.1677\n",
      "Epoch 84/100\n",
      "1263/1263 - 0s - loss: 0.1122 - r_square: 0.9292 - rmse: 0.1122 - val_loss: 0.1673 - val_r_square: 0.8128 - val_rmse: 0.1673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8b16dacc8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping tuning #2\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_r_square', min_delta=0.000001, patience=5,verbose=0, mode='max')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486/1486 [==============================] - 0s 33us/sample - loss: 0.1162 - r_square: 0.9078 - rmse: 0.1162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11616962148355443, 0.90783346, 0.11616962]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperas Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scale data for create model function\n",
    "def data():\n",
    "    #read in data for analysis \n",
    "    all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "    X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "    y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "    #split into test and train data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # # Create a StandardScater model and fit it to the training data\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    y_scaler = StandardScaler().fit(y_train)\n",
    "    # # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    y_train_scaled = y_scaler.transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    \n",
    "    x_train = X_train_scaled.reshape(-1,6)\n",
    "    x_test = X_test_scaled.reshape(-1,6)\n",
    "    y_train = y_train_scaled.reshape(-1,1)\n",
    "    y_test = y_test_scaled.reshape(-1,1)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import losses\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import print_summary\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error, r2_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [50,200,500]),\n",
      "        'Dropout': hp.uniform('Dropout', 0,1),\n",
      "        'Dense_1': hp.choice('Dense_1', [50,200,500]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0,1),\n",
      "        'batch_size': hp.choice('batch_size', [64,128]),\n",
      "        'epochs': hp.choice('epochs', [50,100,150]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: #read in data for analysis \n",
      "   3: all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
      "   4: X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
      "   5: y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
      "   6: #split into test and train data\n",
      "   7: from sklearn.model_selection import train_test_split\n",
      "   8: X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
      "   9: from sklearn.preprocessing import StandardScaler\n",
      "  10: # # Create a StandardScater model and fit it to the training data\n",
      "  11: X_scaler = StandardScaler().fit(X_train)\n",
      "  12: y_scaler = StandardScaler().fit(y_train)\n",
      "  13: # # Transform the training and testing data using the X_scaler and y_scaler models\n",
      "  14: X_train_scaled = X_scaler.transform(X_train)\n",
      "  15: X_test_scaled = X_scaler.transform(X_test)\n",
      "  16: y_train_scaled = y_scaler.transform(y_train)\n",
      "  17: y_test_scaled = y_scaler.transform(y_test)\n",
      "  18: \n",
      "  19: x_train = X_train_scaled.reshape(-1,6)\n",
      "  20: x_test = X_test_scaled.reshape(-1,6)\n",
      "  21: y_train = y_train_scaled.reshape(-1,1)\n",
      "  22: y_test = y_test_scaled.reshape(-1,1)\n",
      "  23: \n",
      "  24: \n",
      "  25: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print(x_train.shape)\n",
      "   4:     model= Sequential() \n",
      "   5:     model.add(Dense(space['Dense'], input_dim=x_train.shape[1], activation= 'relu'))\n",
      "   6:     model.add(Dropout(space['Dropout']))\n",
      "   7:     model.add(Dense(space['Dense_1'],activation= 'relu'))\n",
      "   8:     #model.add(Activation('relu'))\n",
      "   9:     model.add(Dropout(space['Dropout_1']))\n",
      "  10:     model.add(Dense(1, activation= 'linear'))\n",
      "  11: \n",
      "  12:     \n",
      "  13: ################################################\n",
      "  14: # CREDIT: https://github.com/keras-team/keras/issues/7947\n",
      "  15:     def rmse(y_true, y_pred):\n",
      "  16:         return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
      "  17: # mean squared error (mse) for regression  (only for Keras tensors)\n",
      "  18:     def mse(y_true, y_pred):\n",
      "  19:         return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
      "  20:     def r_square(y_true, y_pred):\n",
      "  21:         SS_res =  K.sum(K.square(y_true - y_pred)) \n",
      "  22:         SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
      "  23:         return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
      "  24: #############################################\n",
      "  25: \n",
      "  26:     model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
      "  27:     print_summary(model, line_length=None, positions=None, print_fn=None)\n",
      "  28:     result= model.fit(x_train, y_train,\n",
      "  29:                       batch_size=space['batch_size'],\n",
      "  30:                       epochs=space['epochs'],\n",
      "  31:                       verbose=2,\n",
      "  32:                       validation_split =0.15)\n",
      "  33:     validation_acc= np.min(result.history['val_loss'])\n",
      "  34:     print('Lowest Validation Loss:', validation_acc)\n",
      "  35:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
      "  36: \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_11\"                                                                                                 \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_31 (Dense)             (None, 200)               1400                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_21 (Dropout)         (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_32 (Dense)             (None, 200)               40200                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_22 (Dropout)         (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_33 (Dense)             (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 41,801                                                                                                   \n",
      "Trainable params: 41,801                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/150                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.6980 - r_square: 0.1314 - rmse: 0.6980 - val_loss: 0.4937 - val_r_square: 0.5740 - val_rmse: 0.4937    \n",
      "\n",
      "Epoch 2/150                                                                                                            \n",
      " - 0s - loss: 0.5748 - r_square: 0.3907 - rmse: 0.5748 - val_loss: 0.4355 - val_r_square: 0.6562 - val_rmse: 0.4355    \n",
      "\n",
      "Epoch 3/150                                                                                                            \n",
      " - 0s - loss: 0.5232 - r_square: 0.4821 - rmse: 0.5232 - val_loss: 0.4121 - val_r_square: 0.6932 - val_rmse: 0.4121    \n",
      "\n",
      "Epoch 4/150                                                                                                            \n",
      " - 0s - loss: 0.4875 - r_square: 0.5501 - rmse: 0.4875 - val_loss: 0.3876 - val_r_square: 0.7204 - val_rmse: 0.3876    \n",
      "\n",
      "Epoch 5/150                                                                                                            \n",
      " - 0s - loss: 0.4575 - r_square: 0.5687 - rmse: 0.4575 - val_loss: 0.3687 - val_r_square: 0.7363 - val_rmse: 0.3687    \n",
      "\n",
      "Epoch 6/150                                                                                                            \n",
      " - 0s - loss: 0.4338 - r_square: 0.6089 - rmse: 0.4338 - val_loss: 0.3495 - val_r_square: 0.7553 - val_rmse: 0.3495    \n",
      "\n",
      "Epoch 7/150                                                                                                            \n",
      " - 0s - loss: 0.4170 - r_square: 0.6380 - rmse: 0.4170 - val_loss: 0.3769 - val_r_square: 0.7377 - val_rmse: 0.3769    \n",
      "\n",
      "Epoch 8/150                                                                                                            \n",
      " - 0s - loss: 0.4118 - r_square: 0.6311 - rmse: 0.4118 - val_loss: 0.3541 - val_r_square: 0.7535 - val_rmse: 0.3541    \n",
      "\n",
      "Epoch 9/150                                                                                                            \n",
      " - 0s - loss: 0.3983 - r_square: 0.6533 - rmse: 0.3983 - val_loss: 0.3380 - val_r_square: 0.7661 - val_rmse: 0.3380    \n",
      "\n",
      "Epoch 10/150                                                                                                           \n",
      " - 0s - loss: 0.3940 - r_square: 0.6513 - rmse: 0.3940 - val_loss: 0.3256 - val_r_square: 0.7764 - val_rmse: 0.3256    \n",
      "\n",
      "Epoch 11/150                                                                                                           \n",
      " - 0s - loss: 0.3847 - r_square: 0.6703 - rmse: 0.3847 - val_loss: 0.3402 - val_r_square: 0.7693 - val_rmse: 0.3402    \n",
      "\n",
      "Epoch 12/150                                                                                                           \n",
      " - 0s - loss: 0.3790 - r_square: 0.6633 - rmse: 0.3790 - val_loss: 0.3365 - val_r_square: 0.7763 - val_rmse: 0.3365    \n",
      "\n",
      "Epoch 13/150                                                                                                           \n",
      " - 0s - loss: 0.3777 - r_square: 0.6771 - rmse: 0.3777 - val_loss: 0.3355 - val_r_square: 0.7744 - val_rmse: 0.3355    \n",
      "\n",
      "Epoch 14/150                                                                                                           \n",
      " - 0s - loss: 0.3679 - r_square: 0.6874 - rmse: 0.3679 - val_loss: 0.3137 - val_r_square: 0.7909 - val_rmse: 0.3137    \n",
      "\n",
      "Epoch 15/150                                                                                                           \n",
      " - 0s - loss: 0.3626 - r_square: 0.6909 - rmse: 0.3626 - val_loss: 0.3051 - val_r_square: 0.7938 - val_rmse: 0.3051    \n",
      "\n",
      "Epoch 16/150                                                                                                           \n",
      " - 0s - loss: 0.3562 - r_square: 0.6974 - rmse: 0.3562 - val_loss: 0.3034 - val_r_square: 0.7914 - val_rmse: 0.3034    \n",
      "\n",
      "Epoch 17/150                                                                                                           \n",
      " - 0s - loss: 0.3508 - r_square: 0.7089 - rmse: 0.3508 - val_loss: 0.2943 - val_r_square: 0.8014 - val_rmse: 0.2943    \n",
      "\n",
      "Epoch 18/150                                                                                                           \n",
      " - 0s - loss: 0.3418 - r_square: 0.7081 - rmse: 0.3418 - val_loss: 0.2906 - val_r_square: 0.8062 - val_rmse: 0.2906    \n",
      "\n",
      "Epoch 19/150                                                                                                           \n",
      " - 0s - loss: 0.3404 - r_square: 0.7174 - rmse: 0.3404 - val_loss: 0.3088 - val_r_square: 0.7940 - val_rmse: 0.3088    \n",
      "\n",
      "Epoch 20/150                                                                                                           \n",
      " - 0s - loss: 0.3314 - r_square: 0.7325 - rmse: 0.3314 - val_loss: 0.2815 - val_r_square: 0.8143 - val_rmse: 0.2815    \n",
      "\n",
      "Epoch 21/150                                                                                                           \n",
      " - 0s - loss: 0.3272 - r_square: 0.7319 - rmse: 0.3272 - val_loss: 0.2921 - val_r_square: 0.8061 - val_rmse: 0.2921    \n",
      "\n",
      "Epoch 22/150                                                                                                           \n",
      " - 0s - loss: 0.3227 - r_square: 0.7399 - rmse: 0.3227 - val_loss: 0.2681 - val_r_square: 0.8235 - val_rmse: 0.2681    \n",
      "\n",
      "Epoch 23/150                                                                                                           \n",
      " - 0s - loss: 0.3248 - r_square: 0.7383 - rmse: 0.3248 - val_loss: 0.2819 - val_r_square: 0.8161 - val_rmse: 0.2819    \n",
      "\n",
      "Epoch 24/150                                                                                                           \n",
      " - 0s - loss: 0.3236 - r_square: 0.7305 - rmse: 0.3236 - val_loss: 0.2779 - val_r_square: 0.8179 - val_rmse: 0.2779    \n",
      "\n",
      "Epoch 25/150                                                                                                           \n",
      " - 0s - loss: 0.3154 - r_square: 0.7402 - rmse: 0.3154 - val_loss: 0.2844 - val_r_square: 0.8144 - val_rmse: 0.2844    \n",
      "\n",
      "Epoch 26/150                                                                                                           \n",
      " - 0s - loss: 0.3146 - r_square: 0.7392 - rmse: 0.3146 - val_loss: 0.2803 - val_r_square: 0.8174 - val_rmse: 0.2803    \n",
      "\n",
      "Epoch 27/150                                                                                                           \n",
      " - 0s - loss: 0.3174 - r_square: 0.7388 - rmse: 0.3174 - val_loss: 0.2685 - val_r_square: 0.8265 - val_rmse: 0.2685    \n",
      "\n",
      "Epoch 28/150                                                                                                           \n",
      " - 0s - loss: 0.3107 - r_square: 0.7521 - rmse: 0.3107 - val_loss: 0.2835 - val_r_square: 0.8192 - val_rmse: 0.2835    \n",
      "\n",
      "Epoch 29/150                                                                                                           \n",
      " - 0s - loss: 0.3091 - r_square: 0.7590 - rmse: 0.3091 - val_loss: 0.2648 - val_r_square: 0.8279 - val_rmse: 0.2648    \n",
      "\n",
      "Epoch 30/150                                                                                                           \n",
      " - 0s - loss: 0.3087 - r_square: 0.7472 - rmse: 0.3087 - val_loss: 0.2751 - val_r_square: 0.8209 - val_rmse: 0.2751    \n",
      "\n",
      "Epoch 31/150                                                                                                           \n",
      " - 0s - loss: 0.3048 - r_square: 0.7586 - rmse: 0.3048 - val_loss: 0.2755 - val_r_square: 0.8204 - val_rmse: 0.2755    \n",
      "\n",
      "Epoch 32/150                                                                                                           \n",
      " - 0s - loss: 0.2966 - r_square: 0.7702 - rmse: 0.2966 - val_loss: 0.2817 - val_r_square: 0.8203 - val_rmse: 0.2817    \n",
      "\n",
      "Epoch 33/150                                                                                                           \n",
      " - 0s - loss: 0.3042 - r_square: 0.7522 - rmse: 0.3042 - val_loss: 0.2502 - val_r_square: 0.8429 - val_rmse: 0.2502    \n",
      "\n",
      "Epoch 34/150                                                                                                           \n",
      " - 0s - loss: 0.3060 - r_square: 0.7540 - rmse: 0.3060 - val_loss: 0.2573 - val_r_square: 0.8354 - val_rmse: 0.2573    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150                                                                                                           \n",
      " - 0s - loss: 0.3029 - r_square: 0.7585 - rmse: 0.3029 - val_loss: 0.2630 - val_r_square: 0.8305 - val_rmse: 0.2630    \n",
      "\n",
      "Epoch 36/150                                                                                                           \n",
      " - 0s - loss: 0.3005 - r_square: 0.7624 - rmse: 0.3005 - val_loss: 0.2693 - val_r_square: 0.8287 - val_rmse: 0.2693    \n",
      "\n",
      "Epoch 37/150                                                                                                           \n",
      " - 0s - loss: 0.2936 - r_square: 0.7623 - rmse: 0.2936 - val_loss: 0.2657 - val_r_square: 0.8318 - val_rmse: 0.2657    \n",
      "\n",
      "Epoch 38/150                                                                                                           \n",
      " - 0s - loss: 0.2962 - r_square: 0.7662 - rmse: 0.2962 - val_loss: 0.2520 - val_r_square: 0.8379 - val_rmse: 0.2520    \n",
      "\n",
      "Epoch 39/150                                                                                                           \n",
      " - 0s - loss: 0.2906 - r_square: 0.7713 - rmse: 0.2906 - val_loss: 0.2449 - val_r_square: 0.8426 - val_rmse: 0.2449    \n",
      "\n",
      "Epoch 40/150                                                                                                           \n",
      " - 0s - loss: 0.2976 - r_square: 0.7603 - rmse: 0.2976 - val_loss: 0.2559 - val_r_square: 0.8364 - val_rmse: 0.2559    \n",
      "\n",
      "Epoch 41/150                                                                                                           \n",
      " - 0s - loss: 0.2939 - r_square: 0.7655 - rmse: 0.2939 - val_loss: 0.2524 - val_r_square: 0.8384 - val_rmse: 0.2524    \n",
      "\n",
      "Epoch 42/150                                                                                                           \n",
      " - 0s - loss: 0.2925 - r_square: 0.7733 - rmse: 0.2925 - val_loss: 0.2568 - val_r_square: 0.8378 - val_rmse: 0.2568    \n",
      "\n",
      "Epoch 43/150                                                                                                           \n",
      " - 0s - loss: 0.2893 - r_square: 0.7767 - rmse: 0.2893 - val_loss: 0.2477 - val_r_square: 0.8444 - val_rmse: 0.2477    \n",
      "\n",
      "Epoch 44/150                                                                                                           \n",
      " - 0s - loss: 0.2848 - r_square: 0.7845 - rmse: 0.2848 - val_loss: 0.2581 - val_r_square: 0.8386 - val_rmse: 0.2581    \n",
      "\n",
      "Epoch 45/150                                                                                                           \n",
      " - 0s - loss: 0.2886 - r_square: 0.7731 - rmse: 0.2886 - val_loss: 0.2427 - val_r_square: 0.8451 - val_rmse: 0.2427    \n",
      "\n",
      "Epoch 46/150                                                                                                           \n",
      " - 0s - loss: 0.2889 - r_square: 0.7814 - rmse: 0.2889 - val_loss: 0.2471 - val_r_square: 0.8433 - val_rmse: 0.2471    \n",
      "\n",
      "Epoch 47/150                                                                                                           \n",
      " - 0s - loss: 0.2857 - r_square: 0.7868 - rmse: 0.2857 - val_loss: 0.2504 - val_r_square: 0.8396 - val_rmse: 0.2504    \n",
      "\n",
      "Epoch 48/150                                                                                                           \n",
      " - 0s - loss: 0.2815 - r_square: 0.7851 - rmse: 0.2815 - val_loss: 0.2316 - val_r_square: 0.8494 - val_rmse: 0.2316    \n",
      "\n",
      "Epoch 49/150                                                                                                           \n",
      " - 0s - loss: 0.2839 - r_square: 0.7785 - rmse: 0.2839 - val_loss: 0.2433 - val_r_square: 0.8430 - val_rmse: 0.2433    \n",
      "\n",
      "Epoch 50/150                                                                                                           \n",
      " - 0s - loss: 0.2791 - r_square: 0.7848 - rmse: 0.2791 - val_loss: 0.2480 - val_r_square: 0.8442 - val_rmse: 0.2480    \n",
      "\n",
      "Epoch 51/150                                                                                                           \n",
      " - 0s - loss: 0.2839 - r_square: 0.7816 - rmse: 0.2839 - val_loss: 0.2483 - val_r_square: 0.8434 - val_rmse: 0.2483    \n",
      "\n",
      "Epoch 52/150                                                                                                           \n",
      " - 0s - loss: 0.2863 - r_square: 0.7797 - rmse: 0.2863 - val_loss: 0.2431 - val_r_square: 0.8486 - val_rmse: 0.2431    \n",
      "\n",
      "Epoch 53/150                                                                                                           \n",
      " - 0s - loss: 0.2785 - r_square: 0.7869 - rmse: 0.2785 - val_loss: 0.2590 - val_r_square: 0.8362 - val_rmse: 0.2590    \n",
      "\n",
      "Epoch 54/150                                                                                                           \n",
      " - 0s - loss: 0.2806 - r_square: 0.7879 - rmse: 0.2806 - val_loss: 0.2488 - val_r_square: 0.8443 - val_rmse: 0.2488    \n",
      "\n",
      "Epoch 55/150                                                                                                           \n",
      " - 0s - loss: 0.2787 - r_square: 0.7869 - rmse: 0.2787 - val_loss: 0.2471 - val_r_square: 0.8459 - val_rmse: 0.2471    \n",
      "\n",
      "Epoch 56/150                                                                                                           \n",
      " - 0s - loss: 0.2843 - r_square: 0.7810 - rmse: 0.2843 - val_loss: 0.2463 - val_r_square: 0.8457 - val_rmse: 0.2463    \n",
      "\n",
      "Epoch 57/150                                                                                                           \n",
      " - 0s - loss: 0.2791 - r_square: 0.7888 - rmse: 0.2791 - val_loss: 0.2422 - val_r_square: 0.8480 - val_rmse: 0.2422    \n",
      "\n",
      "Epoch 58/150                                                                                                           \n",
      " - 0s - loss: 0.2761 - r_square: 0.7896 - rmse: 0.2761 - val_loss: 0.2485 - val_r_square: 0.8460 - val_rmse: 0.2485    \n",
      "\n",
      "Epoch 59/150                                                                                                           \n",
      " - 0s - loss: 0.2791 - r_square: 0.7835 - rmse: 0.2791 - val_loss: 0.2462 - val_r_square: 0.8458 - val_rmse: 0.2462    \n",
      "\n",
      "Epoch 60/150                                                                                                           \n",
      " - 0s - loss: 0.2744 - r_square: 0.7913 - rmse: 0.2744 - val_loss: 0.2392 - val_r_square: 0.8490 - val_rmse: 0.2392    \n",
      "\n",
      "Epoch 61/150                                                                                                           \n",
      " - 0s - loss: 0.2759 - r_square: 0.7794 - rmse: 0.2759 - val_loss: 0.2403 - val_r_square: 0.8473 - val_rmse: 0.2403    \n",
      "\n",
      "Epoch 62/150                                                                                                           \n",
      " - 0s - loss: 0.2749 - r_square: 0.7892 - rmse: 0.2749 - val_loss: 0.2371 - val_r_square: 0.8506 - val_rmse: 0.2371    \n",
      "\n",
      "Epoch 63/150                                                                                                           \n",
      " - 0s - loss: 0.2745 - r_square: 0.7872 - rmse: 0.2745 - val_loss: 0.2374 - val_r_square: 0.8510 - val_rmse: 0.2374    \n",
      "\n",
      "Epoch 64/150                                                                                                           \n",
      " - 0s - loss: 0.2738 - r_square: 0.7909 - rmse: 0.2738 - val_loss: 0.2337 - val_r_square: 0.8490 - val_rmse: 0.2337    \n",
      "\n",
      "Epoch 65/150                                                                                                           \n",
      " - 0s - loss: 0.2755 - r_square: 0.7960 - rmse: 0.2755 - val_loss: 0.2476 - val_r_square: 0.8452 - val_rmse: 0.2476    \n",
      "\n",
      "Epoch 66/150                                                                                                           \n",
      " - 0s - loss: 0.2792 - r_square: 0.7890 - rmse: 0.2792 - val_loss: 0.2405 - val_r_square: 0.8509 - val_rmse: 0.2405    \n",
      "\n",
      "Epoch 67/150                                                                                                           \n",
      " - 0s - loss: 0.2731 - r_square: 0.7887 - rmse: 0.2731 - val_loss: 0.2421 - val_r_square: 0.8480 - val_rmse: 0.2421    \n",
      "\n",
      "Epoch 68/150                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2697 - r_square: 0.7904 - rmse: 0.2697 - val_loss: 0.2372 - val_r_square: 0.8535 - val_rmse: 0.2372    \n",
      "\n",
      "Epoch 69/150                                                                                                           \n",
      " - 0s - loss: 0.2766 - r_square: 0.7848 - rmse: 0.2766 - val_loss: 0.2443 - val_r_square: 0.8494 - val_rmse: 0.2443    \n",
      "\n",
      "Epoch 70/150                                                                                                           \n",
      " - 0s - loss: 0.2775 - r_square: 0.7885 - rmse: 0.2775 - val_loss: 0.2394 - val_r_square: 0.8517 - val_rmse: 0.2394    \n",
      "\n",
      "Epoch 71/150                                                                                                           \n",
      " - 0s - loss: 0.2781 - r_square: 0.7862 - rmse: 0.2781 - val_loss: 0.2439 - val_r_square: 0.8484 - val_rmse: 0.2439    \n",
      "\n",
      "Epoch 72/150                                                                                                           \n",
      " - 0s - loss: 0.2722 - r_square: 0.7892 - rmse: 0.2722 - val_loss: 0.2240 - val_r_square: 0.8563 - val_rmse: 0.2240    \n",
      "\n",
      "Epoch 73/150                                                                                                           \n",
      " - 0s - loss: 0.2737 - r_square: 0.7885 - rmse: 0.2737 - val_loss: 0.2448 - val_r_square: 0.8469 - val_rmse: 0.2448    \n",
      "\n",
      "Epoch 74/150                                                                                                           \n",
      " - 0s - loss: 0.2680 - r_square: 0.7934 - rmse: 0.2680 - val_loss: 0.2358 - val_r_square: 0.8525 - val_rmse: 0.2358    \n",
      "\n",
      "Epoch 75/150                                                                                                           \n",
      " - 0s - loss: 0.2704 - r_square: 0.7931 - rmse: 0.2704 - val_loss: 0.2417 - val_r_square: 0.8459 - val_rmse: 0.2417    \n",
      "\n",
      "Epoch 76/150                                                                                                           \n",
      " - 0s - loss: 0.2718 - r_square: 0.7919 - rmse: 0.2718 - val_loss: 0.2413 - val_r_square: 0.8492 - val_rmse: 0.2413    \n",
      "\n",
      "Epoch 77/150                                                                                                           \n",
      " - 0s - loss: 0.2739 - r_square: 0.8050 - rmse: 0.2739 - val_loss: 0.2553 - val_r_square: 0.8440 - val_rmse: 0.2553    \n",
      "\n",
      "Epoch 78/150                                                                                                           \n",
      " - 0s - loss: 0.2702 - r_square: 0.7946 - rmse: 0.2702 - val_loss: 0.2446 - val_r_square: 0.8493 - val_rmse: 0.2446    \n",
      "\n",
      "Epoch 79/150                                                                                                           \n",
      " - 0s - loss: 0.2730 - r_square: 0.7880 - rmse: 0.2730 - val_loss: 0.2483 - val_r_square: 0.8466 - val_rmse: 0.2483    \n",
      "\n",
      "Epoch 80/150                                                                                                           \n",
      " - 0s - loss: 0.2708 - r_square: 0.8021 - rmse: 0.2708 - val_loss: 0.2361 - val_r_square: 0.8556 - val_rmse: 0.2361    \n",
      "\n",
      "Epoch 81/150                                                                                                           \n",
      " - 0s - loss: 0.2658 - r_square: 0.7946 - rmse: 0.2658 - val_loss: 0.2359 - val_r_square: 0.8532 - val_rmse: 0.2359    \n",
      "\n",
      "Epoch 82/150                                                                                                           \n",
      " - 0s - loss: 0.2723 - r_square: 0.7961 - rmse: 0.2723 - val_loss: 0.2329 - val_r_square: 0.8546 - val_rmse: 0.2329    \n",
      "\n",
      "Epoch 83/150                                                                                                           \n",
      " - 0s - loss: 0.2673 - r_square: 0.7974 - rmse: 0.2673 - val_loss: 0.2300 - val_r_square: 0.8568 - val_rmse: 0.2300    \n",
      "\n",
      "Epoch 84/150                                                                                                           \n",
      " - 0s - loss: 0.2642 - r_square: 0.7996 - rmse: 0.2642 - val_loss: 0.2371 - val_r_square: 0.8516 - val_rmse: 0.2371    \n",
      "\n",
      "Epoch 85/150                                                                                                           \n",
      " - 0s - loss: 0.2682 - r_square: 0.7863 - rmse: 0.2682 - val_loss: 0.2309 - val_r_square: 0.8574 - val_rmse: 0.2309    \n",
      "\n",
      "Epoch 86/150                                                                                                           \n",
      " - 0s - loss: 0.2674 - r_square: 0.7981 - rmse: 0.2674 - val_loss: 0.2406 - val_r_square: 0.8540 - val_rmse: 0.2406    \n",
      "\n",
      "Epoch 87/150                                                                                                           \n",
      " - 0s - loss: 0.2679 - r_square: 0.7950 - rmse: 0.2679 - val_loss: 0.2373 - val_r_square: 0.8475 - val_rmse: 0.2373    \n",
      "\n",
      "Epoch 88/150                                                                                                           \n",
      " - 0s - loss: 0.2679 - r_square: 0.8016 - rmse: 0.2679 - val_loss: 0.2367 - val_r_square: 0.8519 - val_rmse: 0.2367    \n",
      "\n",
      "Epoch 89/150                                                                                                           \n",
      " - 0s - loss: 0.2669 - r_square: 0.8002 - rmse: 0.2669 - val_loss: 0.2294 - val_r_square: 0.8557 - val_rmse: 0.2294    \n",
      "\n",
      "Epoch 90/150                                                                                                           \n",
      " - 0s - loss: 0.2683 - r_square: 0.7972 - rmse: 0.2683 - val_loss: 0.2397 - val_r_square: 0.8528 - val_rmse: 0.2397    \n",
      "\n",
      "Epoch 91/150                                                                                                           \n",
      " - 0s - loss: 0.2658 - r_square: 0.8027 - rmse: 0.2658 - val_loss: 0.2370 - val_r_square: 0.8531 - val_rmse: 0.2370    \n",
      "\n",
      "Epoch 92/150                                                                                                           \n",
      " - 0s - loss: 0.2635 - r_square: 0.7955 - rmse: 0.2635 - val_loss: 0.2334 - val_r_square: 0.8570 - val_rmse: 0.2334    \n",
      "\n",
      "Epoch 93/150                                                                                                           \n",
      " - 0s - loss: 0.2625 - r_square: 0.8045 - rmse: 0.2625 - val_loss: 0.2420 - val_r_square: 0.8513 - val_rmse: 0.2420    \n",
      "\n",
      "Epoch 94/150                                                                                                           \n",
      " - 0s - loss: 0.2675 - r_square: 0.7982 - rmse: 0.2675 - val_loss: 0.2279 - val_r_square: 0.8603 - val_rmse: 0.2279    \n",
      "\n",
      "Epoch 95/150                                                                                                           \n",
      " - 0s - loss: 0.2675 - r_square: 0.7987 - rmse: 0.2675 - val_loss: 0.2349 - val_r_square: 0.8546 - val_rmse: 0.2349    \n",
      "\n",
      "Epoch 96/150                                                                                                           \n",
      " - 0s - loss: 0.2647 - r_square: 0.8017 - rmse: 0.2647 - val_loss: 0.2359 - val_r_square: 0.8545 - val_rmse: 0.2359    \n",
      "\n",
      "Epoch 97/150                                                                                                           \n",
      " - 0s - loss: 0.2684 - r_square: 0.7972 - rmse: 0.2684 - val_loss: 0.2336 - val_r_square: 0.8537 - val_rmse: 0.2336    \n",
      "\n",
      "Epoch 98/150                                                                                                           \n",
      " - 0s - loss: 0.2635 - r_square: 0.7962 - rmse: 0.2635 - val_loss: 0.2279 - val_r_square: 0.8613 - val_rmse: 0.2279    \n",
      "\n",
      "Epoch 99/150                                                                                                           \n",
      " - 0s - loss: 0.2660 - r_square: 0.8011 - rmse: 0.2660 - val_loss: 0.2321 - val_r_square: 0.8558 - val_rmse: 0.2321    \n",
      "\n",
      "Epoch 100/150                                                                                                          \n",
      " - 0s - loss: 0.2640 - r_square: 0.8009 - rmse: 0.2640 - val_loss: 0.2373 - val_r_square: 0.8540 - val_rmse: 0.2373    \n",
      "\n",
      "Epoch 101/150                                                                                                          \n",
      " - 0s - loss: 0.2636 - r_square: 0.8052 - rmse: 0.2636 - val_loss: 0.2341 - val_r_square: 0.8549 - val_rmse: 0.2341    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150                                                                                                          \n",
      " - 0s - loss: 0.2568 - r_square: 0.8125 - rmse: 0.2568 - val_loss: 0.2436 - val_r_square: 0.8482 - val_rmse: 0.2436    \n",
      "\n",
      "Epoch 103/150                                                                                                          \n",
      " - 0s - loss: 0.2632 - r_square: 0.7984 - rmse: 0.2632 - val_loss: 0.2282 - val_r_square: 0.8603 - val_rmse: 0.2282    \n",
      "\n",
      "Epoch 104/150                                                                                                          \n",
      " - 0s - loss: 0.2648 - r_square: 0.7963 - rmse: 0.2648 - val_loss: 0.2318 - val_r_square: 0.8578 - val_rmse: 0.2318    \n",
      "\n",
      "Epoch 105/150                                                                                                          \n",
      " - 0s - loss: 0.2675 - r_square: 0.8006 - rmse: 0.2675 - val_loss: 0.2308 - val_r_square: 0.8544 - val_rmse: 0.2308    \n",
      "\n",
      "Epoch 106/150                                                                                                          \n",
      " - 0s - loss: 0.2613 - r_square: 0.8015 - rmse: 0.2613 - val_loss: 0.2338 - val_r_square: 0.8532 - val_rmse: 0.2338    \n",
      "\n",
      "Epoch 107/150                                                                                                          \n",
      " - 0s - loss: 0.2621 - r_square: 0.8080 - rmse: 0.2621 - val_loss: 0.2360 - val_r_square: 0.8530 - val_rmse: 0.2360    \n",
      "\n",
      "Epoch 108/150                                                                                                          \n",
      " - 0s - loss: 0.2616 - r_square: 0.8047 - rmse: 0.2616 - val_loss: 0.2369 - val_r_square: 0.8581 - val_rmse: 0.2369    \n",
      "\n",
      "Epoch 109/150                                                                                                          \n",
      " - 0s - loss: 0.2598 - r_square: 0.8092 - rmse: 0.2598 - val_loss: 0.2311 - val_r_square: 0.8581 - val_rmse: 0.2311    \n",
      "\n",
      "Epoch 110/150                                                                                                          \n",
      " - 0s - loss: 0.2630 - r_square: 0.7982 - rmse: 0.2630 - val_loss: 0.2362 - val_r_square: 0.8551 - val_rmse: 0.2362    \n",
      "\n",
      "Epoch 111/150                                                                                                          \n",
      " - 0s - loss: 0.2644 - r_square: 0.8006 - rmse: 0.2644 - val_loss: 0.2446 - val_r_square: 0.8472 - val_rmse: 0.2446    \n",
      "\n",
      "Epoch 112/150                                                                                                          \n",
      " - 0s - loss: 0.2622 - r_square: 0.8041 - rmse: 0.2622 - val_loss: 0.2231 - val_r_square: 0.8631 - val_rmse: 0.2231    \n",
      "\n",
      "Epoch 113/150                                                                                                          \n",
      " - 0s - loss: 0.2594 - r_square: 0.8101 - rmse: 0.2594 - val_loss: 0.2415 - val_r_square: 0.8505 - val_rmse: 0.2415    \n",
      "\n",
      "Epoch 114/150                                                                                                          \n",
      " - 0s - loss: 0.2579 - r_square: 0.8105 - rmse: 0.2579 - val_loss: 0.2367 - val_r_square: 0.8567 - val_rmse: 0.2367    \n",
      "\n",
      "Epoch 115/150                                                                                                          \n",
      " - 0s - loss: 0.2623 - r_square: 0.8127 - rmse: 0.2623 - val_loss: 0.2313 - val_r_square: 0.8569 - val_rmse: 0.2313    \n",
      "\n",
      "Epoch 116/150                                                                                                          \n",
      " - 0s - loss: 0.2621 - r_square: 0.8025 - rmse: 0.2621 - val_loss: 0.2400 - val_r_square: 0.8495 - val_rmse: 0.2400    \n",
      "\n",
      "Epoch 117/150                                                                                                          \n",
      " - 0s - loss: 0.2653 - r_square: 0.8056 - rmse: 0.2653 - val_loss: 0.2326 - val_r_square: 0.8556 - val_rmse: 0.2326    \n",
      "\n",
      "Epoch 118/150                                                                                                          \n",
      " - 0s - loss: 0.2572 - r_square: 0.8094 - rmse: 0.2572 - val_loss: 0.2299 - val_r_square: 0.8582 - val_rmse: 0.2299    \n",
      "\n",
      "Epoch 119/150                                                                                                          \n",
      " - 0s - loss: 0.2615 - r_square: 0.8060 - rmse: 0.2615 - val_loss: 0.2240 - val_r_square: 0.8631 - val_rmse: 0.2240    \n",
      "\n",
      "Epoch 120/150                                                                                                          \n",
      " - 0s - loss: 0.2606 - r_square: 0.8058 - rmse: 0.2606 - val_loss: 0.2407 - val_r_square: 0.8536 - val_rmse: 0.2407    \n",
      "\n",
      "Epoch 121/150                                                                                                          \n",
      " - 0s - loss: 0.2594 - r_square: 0.8062 - rmse: 0.2594 - val_loss: 0.2296 - val_r_square: 0.8604 - val_rmse: 0.2296    \n",
      "\n",
      "Epoch 122/150                                                                                                          \n",
      " - 0s - loss: 0.2607 - r_square: 0.8029 - rmse: 0.2607 - val_loss: 0.2328 - val_r_square: 0.8568 - val_rmse: 0.2328    \n",
      "\n",
      "Epoch 123/150                                                                                                          \n",
      " - 0s - loss: 0.2598 - r_square: 0.8069 - rmse: 0.2598 - val_loss: 0.2287 - val_r_square: 0.8609 - val_rmse: 0.2287    \n",
      "\n",
      "Epoch 124/150                                                                                                          \n",
      " - 0s - loss: 0.2615 - r_square: 0.8027 - rmse: 0.2615 - val_loss: 0.2368 - val_r_square: 0.8541 - val_rmse: 0.2368    \n",
      "\n",
      "Epoch 125/150                                                                                                          \n",
      " - 0s - loss: 0.2588 - r_square: 0.8110 - rmse: 0.2588 - val_loss: 0.2340 - val_r_square: 0.8542 - val_rmse: 0.2340    \n",
      "\n",
      "Epoch 126/150                                                                                                          \n",
      " - 0s - loss: 0.2560 - r_square: 0.8005 - rmse: 0.2560 - val_loss: 0.2325 - val_r_square: 0.8580 - val_rmse: 0.2325    \n",
      "\n",
      "Epoch 127/150                                                                                                          \n",
      " - 0s - loss: 0.2612 - r_square: 0.8130 - rmse: 0.2612 - val_loss: 0.2248 - val_r_square: 0.8581 - val_rmse: 0.2248    \n",
      "\n",
      "Epoch 128/150                                                                                                          \n",
      " - 0s - loss: 0.2654 - r_square: 0.7982 - rmse: 0.2654 - val_loss: 0.2336 - val_r_square: 0.8537 - val_rmse: 0.2336    \n",
      "\n",
      "Epoch 129/150                                                                                                          \n",
      " - 0s - loss: 0.2622 - r_square: 0.8058 - rmse: 0.2622 - val_loss: 0.2206 - val_r_square: 0.8629 - val_rmse: 0.2206    \n",
      "\n",
      "Epoch 130/150                                                                                                          \n",
      " - 0s - loss: 0.2599 - r_square: 0.8039 - rmse: 0.2599 - val_loss: 0.2224 - val_r_square: 0.8639 - val_rmse: 0.2224    \n",
      "\n",
      "Epoch 131/150                                                                                                          \n",
      " - 0s - loss: 0.2607 - r_square: 0.7997 - rmse: 0.2607 - val_loss: 0.2267 - val_r_square: 0.8607 - val_rmse: 0.2267    \n",
      "\n",
      "Epoch 132/150                                                                                                          \n",
      " - 0s - loss: 0.2583 - r_square: 0.8123 - rmse: 0.2583 - val_loss: 0.2214 - val_r_square: 0.8629 - val_rmse: 0.2214    \n",
      "\n",
      "Epoch 133/150                                                                                                          \n",
      " - 0s - loss: 0.2596 - r_square: 0.8002 - rmse: 0.2596 - val_loss: 0.2332 - val_r_square: 0.8564 - val_rmse: 0.2332    \n",
      "\n",
      "Epoch 134/150                                                                                                          \n",
      " - 0s - loss: 0.2588 - r_square: 0.8092 - rmse: 0.2588 - val_loss: 0.2387 - val_r_square: 0.8561 - val_rmse: 0.2387    \n",
      "\n",
      "Epoch 135/150                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2545 - r_square: 0.8121 - rmse: 0.2545 - val_loss: 0.2295 - val_r_square: 0.8616 - val_rmse: 0.2295    \n",
      "\n",
      "Epoch 136/150                                                                                                          \n",
      " - 0s - loss: 0.2568 - r_square: 0.8054 - rmse: 0.2568 - val_loss: 0.2221 - val_r_square: 0.8639 - val_rmse: 0.2221    \n",
      "\n",
      "Epoch 137/150                                                                                                          \n",
      " - 0s - loss: 0.2596 - r_square: 0.8104 - rmse: 0.2596 - val_loss: 0.2304 - val_r_square: 0.8564 - val_rmse: 0.2304    \n",
      "\n",
      "Epoch 138/150                                                                                                          \n",
      " - 0s - loss: 0.2583 - r_square: 0.8123 - rmse: 0.2583 - val_loss: 0.2190 - val_r_square: 0.8669 - val_rmse: 0.2190    \n",
      "\n",
      "Epoch 139/150                                                                                                          \n",
      " - 0s - loss: 0.2593 - r_square: 0.8094 - rmse: 0.2593 - val_loss: 0.2235 - val_r_square: 0.8624 - val_rmse: 0.2235    \n",
      "\n",
      "Epoch 140/150                                                                                                          \n",
      " - 0s - loss: 0.2561 - r_square: 0.8133 - rmse: 0.2561 - val_loss: 0.2196 - val_r_square: 0.8631 - val_rmse: 0.2196    \n",
      "\n",
      "Epoch 141/150                                                                                                          \n",
      " - 0s - loss: 0.2543 - r_square: 0.8152 - rmse: 0.2543 - val_loss: 0.2186 - val_r_square: 0.8636 - val_rmse: 0.2186    \n",
      "\n",
      "Epoch 142/150                                                                                                          \n",
      " - 0s - loss: 0.2569 - r_square: 0.8109 - rmse: 0.2569 - val_loss: 0.2311 - val_r_square: 0.8570 - val_rmse: 0.2311    \n",
      "\n",
      "Epoch 143/150                                                                                                          \n",
      " - 0s - loss: 0.2562 - r_square: 0.8171 - rmse: 0.2562 - val_loss: 0.2225 - val_r_square: 0.8611 - val_rmse: 0.2225    \n",
      "\n",
      "Epoch 144/150                                                                                                          \n",
      " - 0s - loss: 0.2585 - r_square: 0.8070 - rmse: 0.2585 - val_loss: 0.2295 - val_r_square: 0.8577 - val_rmse: 0.2295    \n",
      "\n",
      "Epoch 145/150                                                                                                          \n",
      " - 0s - loss: 0.2599 - r_square: 0.7973 - rmse: 0.2599 - val_loss: 0.2244 - val_r_square: 0.8609 - val_rmse: 0.2244    \n",
      "\n",
      "Epoch 146/150                                                                                                          \n",
      " - 0s - loss: 0.2515 - r_square: 0.8218 - rmse: 0.2515 - val_loss: 0.2346 - val_r_square: 0.8563 - val_rmse: 0.2346    \n",
      "\n",
      "Epoch 147/150                                                                                                          \n",
      " - 0s - loss: 0.2600 - r_square: 0.8103 - rmse: 0.2600 - val_loss: 0.2385 - val_r_square: 0.8545 - val_rmse: 0.2385    \n",
      "\n",
      "Epoch 148/150                                                                                                          \n",
      " - 0s - loss: 0.2584 - r_square: 0.8035 - rmse: 0.2584 - val_loss: 0.2237 - val_r_square: 0.8618 - val_rmse: 0.2237    \n",
      "\n",
      "Epoch 149/150                                                                                                          \n",
      " - 0s - loss: 0.2579 - r_square: 0.8043 - rmse: 0.2579 - val_loss: 0.2356 - val_r_square: 0.8577 - val_rmse: 0.2356    \n",
      "\n",
      "Epoch 150/150                                                                                                          \n",
      " - 0s - loss: 0.2520 - r_square: 0.8117 - rmse: 0.2520 - val_loss: 0.2214 - val_r_square: 0.8657 - val_rmse: 0.2214    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.2186421764449332                                                                                                     \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_12\"                                                                                                 \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_34 (Dense)             (None, 500)               3500                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_23 (Dropout)         (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_35 (Dense)             (None, 500)               250500                                                          \n",
      "_________________________________________________________________                                                      \n",
      "dropout_24 (Dropout)         (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_36 (Dense)             (None, 1)                 501                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 254,501                                                                                                  \n",
      "Trainable params: 254,501                                                                                              \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 1s - loss: 0.8355 - r_square: -2.3980e-01 - rmse: 0.8355 - val_loss: 0.5433 - val_r_square: 0.5104 - val_rmse: 0.5433\n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 1s - loss: 0.6238 - r_square: 0.2841 - rmse: 0.6238 - val_loss: 0.4935 - val_r_square: 0.5771 - val_rmse: 0.4935    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 1s - loss: 0.5565 - r_square: 0.4190 - rmse: 0.5565 - val_loss: 0.4531 - val_r_square: 0.6370 - val_rmse: 0.4531    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 1s - loss: 0.5160 - r_square: 0.4857 - rmse: 0.5160 - val_loss: 0.4432 - val_r_square: 0.6499 - val_rmse: 0.4432    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.4834 - r_square: 0.5380 - rmse: 0.4834 - val_loss: 0.4444 - val_r_square: 0.6494 - val_rmse: 0.4444    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.4666 - r_square: 0.5422 - rmse: 0.4666 - val_loss: 0.3906 - val_r_square: 0.7081 - val_rmse: 0.3906    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 1s - loss: 0.4493 - r_square: 0.5818 - rmse: 0.4493 - val_loss: 0.3893 - val_r_square: 0.7111 - val_rmse: 0.3893    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4400 - r_square: 0.6061 - rmse: 0.4400 - val_loss: 0.3868 - val_r_square: 0.7087 - val_rmse: 0.3868    \n",
      "\n",
      "Epoch 9/50                                                                                                             \n",
      " - 1s - loss: 0.4243 - r_square: 0.6223 - rmse: 0.4243 - val_loss: 0.3538 - val_r_square: 0.7445 - val_rmse: 0.3538    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.4166 - r_square: 0.6313 - rmse: 0.4166 - val_loss: 0.3492 - val_r_square: 0.7468 - val_rmse: 0.3492    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 1s - loss: 0.4143 - r_square: 0.6323 - rmse: 0.4143 - val_loss: 0.3421 - val_r_square: 0.7581 - val_rmse: 0.3421    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.4081 - r_square: 0.6367 - rmse: 0.4081 - val_loss: 0.3339 - val_r_square: 0.7596 - val_rmse: 0.3339    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 1s - loss: 0.3992 - r_square: 0.6478 - rmse: 0.3992 - val_loss: 0.3198 - val_r_square: 0.7691 - val_rmse: 0.3198    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.3894 - r_square: 0.6635 - rmse: 0.3894 - val_loss: 0.3161 - val_r_square: 0.7737 - val_rmse: 0.3161    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.3924 - r_square: 0.6572 - rmse: 0.3924 - val_loss: 0.3088 - val_r_square: 0.7848 - val_rmse: 0.3088    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 1s - loss: 0.3879 - r_square: 0.6632 - rmse: 0.3879 - val_loss: 0.3018 - val_r_square: 0.7868 - val_rmse: 0.3018    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.3832 - r_square: 0.6741 - rmse: 0.3832 - val_loss: 0.2979 - val_r_square: 0.7896 - val_rmse: 0.2979    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 1s - loss: 0.3756 - r_square: 0.6875 - rmse: 0.3756 - val_loss: 0.3216 - val_r_square: 0.7743 - val_rmse: 0.3216    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.3689 - r_square: 0.6920 - rmse: 0.3689 - val_loss: 0.3020 - val_r_square: 0.7899 - val_rmse: 0.3020    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.3670 - r_square: 0.7011 - rmse: 0.3670 - val_loss: 0.2859 - val_r_square: 0.7990 - val_rmse: 0.2859    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.3622 - r_square: 0.7128 - rmse: 0.3622 - val_loss: 0.2758 - val_r_square: 0.8086 - val_rmse: 0.2758    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.3649 - r_square: 0.6902 - rmse: 0.3649 - val_loss: 0.2941 - val_r_square: 0.7986 - val_rmse: 0.2941    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 1s - loss: 0.3646 - r_square: 0.6948 - rmse: 0.3646 - val_loss: 0.2669 - val_r_square: 0.8167 - val_rmse: 0.2669    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.3522 - r_square: 0.7142 - rmse: 0.3522 - val_loss: 0.2606 - val_r_square: 0.8215 - val_rmse: 0.2606    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.3551 - r_square: 0.6963 - rmse: 0.3551 - val_loss: 0.2816 - val_r_square: 0.8103 - val_rmse: 0.2816    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.3523 - r_square: 0.7103 - rmse: 0.3523 - val_loss: 0.2706 - val_r_square: 0.8175 - val_rmse: 0.2706    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.3479 - r_square: 0.7105 - rmse: 0.3479 - val_loss: 0.2545 - val_r_square: 0.8224 - val_rmse: 0.2545    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 1s - loss: 0.3492 - r_square: 0.7174 - rmse: 0.3492 - val_loss: 0.2702 - val_r_square: 0.8127 - val_rmse: 0.2702    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n",
      " - 0s - loss: 0.3519 - r_square: 0.7134 - rmse: 0.3519 - val_loss: 0.2626 - val_r_square: 0.8227 - val_rmse: 0.2626    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.3482 - r_square: 0.7109 - rmse: 0.3482 - val_loss: 0.2676 - val_r_square: 0.8188 - val_rmse: 0.2676    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.3477 - r_square: 0.7309 - rmse: 0.3477 - val_loss: 0.2695 - val_r_square: 0.8196 - val_rmse: 0.2695    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.3448 - r_square: 0.7051 - rmse: 0.3448 - val_loss: 0.2612 - val_r_square: 0.8254 - val_rmse: 0.2612    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.3451 - r_square: 0.7138 - rmse: 0.3451 - val_loss: 0.2698 - val_r_square: 0.8208 - val_rmse: 0.2698    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.3479 - r_square: 0.7238 - rmse: 0.3479 - val_loss: 0.2545 - val_r_square: 0.8235 - val_rmse: 0.2545    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 1s - loss: 0.3433 - r_square: 0.7124 - rmse: 0.3433 - val_loss: 0.2408 - val_r_square: 0.8356 - val_rmse: 0.2408    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.3356 - r_square: 0.7248 - rmse: 0.3356 - val_loss: 0.2535 - val_r_square: 0.8309 - val_rmse: 0.2535    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.3429 - r_square: 0.7301 - rmse: 0.3429 - val_loss: 0.2575 - val_r_square: 0.8287 - val_rmse: 0.2575    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.3364 - r_square: 0.7307 - rmse: 0.3364 - val_loss: 0.2580 - val_r_square: 0.8282 - val_rmse: 0.2580    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.3398 - r_square: 0.7421 - rmse: 0.3398 - val_loss: 0.2556 - val_r_square: 0.8298 - val_rmse: 0.2556    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 1s - loss: 0.3425 - r_square: 0.7309 - rmse: 0.3425 - val_loss: 0.2546 - val_r_square: 0.8342 - val_rmse: 0.2546    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.3369 - r_square: 0.7299 - rmse: 0.3369 - val_loss: 0.2641 - val_r_square: 0.8240 - val_rmse: 0.2641    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50                                                                                                            \n",
      " - 1s - loss: 0.3358 - r_square: 0.7385 - rmse: 0.3358 - val_loss: 0.2707 - val_r_square: 0.8210 - val_rmse: 0.2707    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.3338 - r_square: 0.7287 - rmse: 0.3338 - val_loss: 0.2518 - val_r_square: 0.8325 - val_rmse: 0.2518    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 1s - loss: 0.3344 - r_square: 0.7373 - rmse: 0.3344 - val_loss: 0.2483 - val_r_square: 0.8359 - val_rmse: 0.2483    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 1s - loss: 0.3395 - r_square: 0.7316 - rmse: 0.3395 - val_loss: 0.2570 - val_r_square: 0.8320 - val_rmse: 0.2570    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 1s - loss: 0.3299 - r_square: 0.7366 - rmse: 0.3299 - val_loss: 0.2661 - val_r_square: 0.8280 - val_rmse: 0.2661    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 1s - loss: 0.3306 - r_square: 0.7439 - rmse: 0.3306 - val_loss: 0.2495 - val_r_square: 0.8374 - val_rmse: 0.2495    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 1s - loss: 0.3264 - r_square: 0.7445 - rmse: 0.3264 - val_loss: 0.2563 - val_r_square: 0.8316 - val_rmse: 0.2563    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 1s - loss: 0.3305 - r_square: 0.7419 - rmse: 0.3305 - val_loss: 0.2377 - val_r_square: 0.8431 - val_rmse: 0.2377    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.3348 - r_square: 0.7304 - rmse: 0.3348 - val_loss: 0.2398 - val_r_square: 0.8412 - val_rmse: 0.2398    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.23772287751883492                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_13\"                                                                                                 \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_37 (Dense)             (None, 50)                350                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_25 (Dropout)         (None, 50)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_38 (Dense)             (None, 500)               25500                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_26 (Dropout)         (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_39 (Dense)             (None, 1)                 501                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 26,351                                                                                                   \n",
      "Trainable params: 26,351                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 0s - loss: 0.9395 - r_square: -5.7384e-01 - rmse: 0.9395 - val_loss: 0.7686 - val_r_square: 0.0464 - val_rmse: 0.7686\n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.8577 - r_square: -2.8048e-01 - rmse: 0.8577 - val_loss: 0.7656 - val_r_square: 0.0599 - val_rmse: 0.7656\n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.8234 - r_square: -1.3493e-01 - rmse: 0.8234 - val_loss: 0.7552 - val_r_square: 0.0790 - val_rmse: 0.7552\n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.7958 - r_square: -7.0913e-02 - rmse: 0.7958 - val_loss: 0.7775 - val_r_square: 0.0205 - val_rmse: 0.7775\n",
      "\n",
      "Epoch 5/100                                                                                                            \n",
      " - 0s - loss: 0.7789 - r_square: -2.4491e-02 - rmse: 0.7789 - val_loss: 0.7534 - val_r_square: 0.0851 - val_rmse: 0.7534\n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.7721 - r_square: 0.0048 - rmse: 0.7721 - val_loss: 0.7604 - val_r_square: 0.0632 - val_rmse: 0.7604    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.7501 - r_square: 0.0344 - rmse: 0.7501 - val_loss: 0.7584 - val_r_square: 0.0732 - val_rmse: 0.7584    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.7442 - r_square: 0.0679 - rmse: 0.7442 - val_loss: 0.7542 - val_r_square: 0.0846 - val_rmse: 0.7542    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.7457 - r_square: 0.0487 - rmse: 0.7457 - val_loss: 0.7433 - val_r_square: 0.1180 - val_rmse: 0.7433    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.7285 - r_square: 0.1060 - rmse: 0.7285 - val_loss: 0.7443 - val_r_square: 0.1145 - val_rmse: 0.7443    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.7245 - r_square: 0.1115 - rmse: 0.7245 - val_loss: 0.7492 - val_r_square: 0.1049 - val_rmse: 0.7492    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.7251 - r_square: 0.0919 - rmse: 0.7251 - val_loss: 0.7493 - val_r_square: 0.1004 - val_rmse: 0.7493    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.7164 - r_square: 0.1145 - rmse: 0.7164 - val_loss: 0.7450 - val_r_square: 0.1133 - val_rmse: 0.7450    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.7186 - r_square: 0.0973 - rmse: 0.7186 - val_loss: 0.7424 - val_r_square: 0.1214 - val_rmse: 0.7424    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100                                                                                                           \n",
      " - 0s - loss: 0.6999 - r_square: 0.1347 - rmse: 0.6999 - val_loss: 0.7504 - val_r_square: 0.1002 - val_rmse: 0.7504    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.7136 - r_square: 0.0690 - rmse: 0.7136 - val_loss: 0.7498 - val_r_square: 0.1030 - val_rmse: 0.7498    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.6976 - r_square: 0.1386 - rmse: 0.6976 - val_loss: 0.7498 - val_r_square: 0.1001 - val_rmse: 0.7498    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.7031 - r_square: 0.1449 - rmse: 0.7031 - val_loss: 0.7566 - val_r_square: 0.0821 - val_rmse: 0.7566    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.6846 - r_square: 0.1665 - rmse: 0.6846 - val_loss: 0.7516 - val_r_square: 0.0938 - val_rmse: 0.7516    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.6847 - r_square: 0.1758 - rmse: 0.6847 - val_loss: 0.7535 - val_r_square: 0.0894 - val_rmse: 0.7535    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.6903 - r_square: 0.1579 - rmse: 0.6903 - val_loss: 0.7591 - val_r_square: 0.0765 - val_rmse: 0.7591    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.6787 - r_square: 0.1805 - rmse: 0.6787 - val_loss: 0.7550 - val_r_square: 0.0843 - val_rmse: 0.7550    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.6804 - r_square: 0.1713 - rmse: 0.6804 - val_loss: 0.7588 - val_r_square: 0.0766 - val_rmse: 0.7588    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.6888 - r_square: 0.1607 - rmse: 0.6888 - val_loss: 0.7602 - val_r_square: 0.0718 - val_rmse: 0.7602    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.6851 - r_square: 0.1591 - rmse: 0.6851 - val_loss: 0.7622 - val_r_square: 0.0661 - val_rmse: 0.7622    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.6724 - r_square: 0.2013 - rmse: 0.6724 - val_loss: 0.7579 - val_r_square: 0.0773 - val_rmse: 0.7579    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.6623 - r_square: 0.2051 - rmse: 0.6623 - val_loss: 0.7602 - val_r_square: 0.0716 - val_rmse: 0.7602    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.6816 - r_square: 0.1681 - rmse: 0.6816 - val_loss: 0.7614 - val_r_square: 0.0686 - val_rmse: 0.7614    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.6657 - r_square: 0.2018 - rmse: 0.6657 - val_loss: 0.7565 - val_r_square: 0.0838 - val_rmse: 0.7565    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.6788 - r_square: 0.1645 - rmse: 0.6788 - val_loss: 0.7645 - val_r_square: 0.0643 - val_rmse: 0.7645    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.6716 - r_square: 0.1957 - rmse: 0.6716 - val_loss: 0.7637 - val_r_square: 0.0646 - val_rmse: 0.7637    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.6698 - r_square: 0.1849 - rmse: 0.6698 - val_loss: 0.7608 - val_r_square: 0.0700 - val_rmse: 0.7608    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.6616 - r_square: 0.2031 - rmse: 0.6616 - val_loss: 0.7571 - val_r_square: 0.0832 - val_rmse: 0.7571    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.6720 - r_square: 0.1718 - rmse: 0.6720 - val_loss: 0.7656 - val_r_square: 0.0623 - val_rmse: 0.7656    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.6632 - r_square: 0.2006 - rmse: 0.6632 - val_loss: 0.7640 - val_r_square: 0.0652 - val_rmse: 0.7640    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.6680 - r_square: 0.2009 - rmse: 0.6680 - val_loss: 0.7655 - val_r_square: 0.0631 - val_rmse: 0.7655    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.6569 - r_square: 0.2157 - rmse: 0.6569 - val_loss: 0.7676 - val_r_square: 0.0579 - val_rmse: 0.7676    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.6606 - r_square: 0.1955 - rmse: 0.6606 - val_loss: 0.7630 - val_r_square: 0.0707 - val_rmse: 0.7630    \n",
      "\n",
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.6597 - r_square: 0.2156 - rmse: 0.6597 - val_loss: 0.7655 - val_r_square: 0.0631 - val_rmse: 0.7655    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.6508 - r_square: 0.2074 - rmse: 0.6508 - val_loss: 0.7714 - val_r_square: 0.0470 - val_rmse: 0.7714    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.6575 - r_square: 0.2083 - rmse: 0.6575 - val_loss: 0.7677 - val_r_square: 0.0543 - val_rmse: 0.7677    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.6596 - r_square: 0.1992 - rmse: 0.6596 - val_loss: 0.7710 - val_r_square: 0.0486 - val_rmse: 0.7710    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.6629 - r_square: 0.1937 - rmse: 0.6629 - val_loss: 0.7706 - val_r_square: 0.0483 - val_rmse: 0.7706    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.6586 - r_square: 0.1957 - rmse: 0.6586 - val_loss: 0.7722 - val_r_square: 0.0453 - val_rmse: 0.7722    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.6528 - r_square: 0.2050 - rmse: 0.6528 - val_loss: 0.7707 - val_r_square: 0.0486 - val_rmse: 0.7707    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.6507 - r_square: 0.2145 - rmse: 0.6507 - val_loss: 0.7772 - val_r_square: 0.0330 - val_rmse: 0.7772    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.6555 - r_square: 0.2126 - rmse: 0.6555 - val_loss: 0.7754 - val_r_square: 0.0375 - val_rmse: 0.7754    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6482 - r_square: 0.2175 - rmse: 0.6482 - val_loss: 0.7722 - val_r_square: 0.0472 - val_rmse: 0.7722    \n",
      "\n",
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.6511 - r_square: 0.1934 - rmse: 0.6511 - val_loss: 0.7785 - val_r_square: 0.0339 - val_rmse: 0.7785    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.6569 - r_square: 0.1966 - rmse: 0.6569 - val_loss: 0.7772 - val_r_square: 0.0358 - val_rmse: 0.7772    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.6640 - r_square: 0.1923 - rmse: 0.6640 - val_loss: 0.7811 - val_r_square: 0.0274 - val_rmse: 0.7811    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.6604 - r_square: 0.1931 - rmse: 0.6604 - val_loss: 0.7788 - val_r_square: 0.0330 - val_rmse: 0.7788    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.6415 - r_square: 0.2250 - rmse: 0.6415 - val_loss: 0.7776 - val_r_square: 0.0361 - val_rmse: 0.7776    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.6540 - r_square: 0.1924 - rmse: 0.6540 - val_loss: 0.7762 - val_r_square: 0.0380 - val_rmse: 0.7762    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.6488 - r_square: 0.2042 - rmse: 0.6488 - val_loss: 0.7801 - val_r_square: 0.0293 - val_rmse: 0.7801    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.6525 - r_square: 0.2042 - rmse: 0.6525 - val_loss: 0.7824 - val_r_square: 0.0233 - val_rmse: 0.7824    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.6534 - r_square: 0.2122 - rmse: 0.6534 - val_loss: 0.7818 - val_r_square: 0.0246 - val_rmse: 0.7818    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.6523 - r_square: 0.2022 - rmse: 0.6523 - val_loss: 0.7812 - val_r_square: 0.0265 - val_rmse: 0.7812    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.6471 - r_square: 0.2356 - rmse: 0.6471 - val_loss: 0.7810 - val_r_square: 0.0266 - val_rmse: 0.7810    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.6460 - r_square: 0.2252 - rmse: 0.6460 - val_loss: 0.7815 - val_r_square: 0.0263 - val_rmse: 0.7815    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.6451 - r_square: 0.2227 - rmse: 0.6451 - val_loss: 0.7801 - val_r_square: 0.0303 - val_rmse: 0.7801    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.6473 - r_square: 0.2183 - rmse: 0.6473 - val_loss: 0.7833 - val_r_square: 0.0216 - val_rmse: 0.7833    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.6556 - r_square: 0.1968 - rmse: 0.6556 - val_loss: 0.7837 - val_r_square: 0.0216 - val_rmse: 0.7837    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.6479 - r_square: 0.2225 - rmse: 0.6479 - val_loss: 0.7844 - val_r_square: 0.0203 - val_rmse: 0.7844    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.6458 - r_square: 0.2144 - rmse: 0.6458 - val_loss: 0.7863 - val_r_square: 0.0168 - val_rmse: 0.7863    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.6470 - r_square: 0.2178 - rmse: 0.6470 - val_loss: 0.7848 - val_r_square: 0.0194 - val_rmse: 0.7848    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.6369 - r_square: 0.2371 - rmse: 0.6369 - val_loss: 0.7839 - val_r_square: 0.0227 - val_rmse: 0.7839    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.6411 - r_square: 0.2159 - rmse: 0.6411 - val_loss: 0.7819 - val_r_square: 0.0272 - val_rmse: 0.7819    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.6518 - r_square: 0.2140 - rmse: 0.6518 - val_loss: 0.7825 - val_r_square: 0.0266 - val_rmse: 0.7825    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.6415 - r_square: 0.2279 - rmse: 0.6415 - val_loss: 0.7801 - val_r_square: 0.0317 - val_rmse: 0.7801    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.6425 - r_square: 0.2217 - rmse: 0.6425 - val_loss: 0.7818 - val_r_square: 0.0270 - val_rmse: 0.7818    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n",
      " - 0s - loss: 0.6474 - r_square: 0.2075 - rmse: 0.6474 - val_loss: 0.7807 - val_r_square: 0.0301 - val_rmse: 0.7807    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.6443 - r_square: 0.2253 - rmse: 0.6443 - val_loss: 0.7846 - val_r_square: 0.0202 - val_rmse: 0.7846    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.6564 - r_square: 0.1947 - rmse: 0.6564 - val_loss: 0.7817 - val_r_square: 0.0272 - val_rmse: 0.7817    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.6527 - r_square: 0.1967 - rmse: 0.6527 - val_loss: 0.7841 - val_r_square: 0.0223 - val_rmse: 0.7841    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.6417 - r_square: 0.2258 - rmse: 0.6417 - val_loss: 0.7852 - val_r_square: 0.0212 - val_rmse: 0.7852    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.6403 - r_square: 0.2275 - rmse: 0.6403 - val_loss: 0.7840 - val_r_square: 0.0244 - val_rmse: 0.7840    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.6477 - r_square: 0.2198 - rmse: 0.6476 - val_loss: 0.7807 - val_r_square: 0.0301 - val_rmse: 0.7807    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.6426 - r_square: 0.2221 - rmse: 0.6426 - val_loss: 0.7819 - val_r_square: 0.0290 - val_rmse: 0.7819    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.6293 - r_square: 0.2387 - rmse: 0.6293 - val_loss: 0.7817 - val_r_square: 0.0290 - val_rmse: 0.7817    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.6357 - r_square: 0.2398 - rmse: 0.6357 - val_loss: 0.7826 - val_r_square: 0.0269 - val_rmse: 0.7826    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100                                                                                                           \n",
      " - 0s - loss: 0.6366 - r_square: 0.2373 - rmse: 0.6366 - val_loss: 0.7838 - val_r_square: 0.0250 - val_rmse: 0.7838    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.6522 - r_square: 0.1976 - rmse: 0.6522 - val_loss: 0.7839 - val_r_square: 0.0242 - val_rmse: 0.7839    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.6458 - r_square: 0.2189 - rmse: 0.6458 - val_loss: 0.7853 - val_r_square: 0.0199 - val_rmse: 0.7853    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.6440 - r_square: 0.2133 - rmse: 0.6440 - val_loss: 0.7854 - val_r_square: 0.0205 - val_rmse: 0.7854    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.6358 - r_square: 0.2348 - rmse: 0.6358 - val_loss: 0.7855 - val_r_square: 0.0205 - val_rmse: 0.7855    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.6479 - r_square: 0.2258 - rmse: 0.6479 - val_loss: 0.7853 - val_r_square: 0.0208 - val_rmse: 0.7853    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.6464 - r_square: 0.1988 - rmse: 0.6464 - val_loss: 0.7834 - val_r_square: 0.0249 - val_rmse: 0.7834    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.6382 - r_square: 0.2439 - rmse: 0.6382 - val_loss: 0.7850 - val_r_square: 0.0209 - val_rmse: 0.7850    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.6392 - r_square: 0.2329 - rmse: 0.6392 - val_loss: 0.7883 - val_r_square: 0.0132 - val_rmse: 0.7883    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.6397 - r_square: 0.2257 - rmse: 0.6397 - val_loss: 0.7887 - val_r_square: 0.0139 - val_rmse: 0.7887    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.6493 - r_square: 0.2156 - rmse: 0.6493 - val_loss: 0.7888 - val_r_square: 0.0139 - val_rmse: 0.7888    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.6382 - r_square: 0.2095 - rmse: 0.6382 - val_loss: 0.7876 - val_r_square: 0.0175 - val_rmse: 0.7876    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.6448 - r_square: 0.2344 - rmse: 0.6448 - val_loss: 0.7896 - val_r_square: 0.0126 - val_rmse: 0.7896    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.6494 - r_square: 0.2072 - rmse: 0.6494 - val_loss: 0.7879 - val_r_square: 0.0162 - val_rmse: 0.7879    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.6483 - r_square: 0.2118 - rmse: 0.6483 - val_loss: 0.7890 - val_r_square: 0.0143 - val_rmse: 0.7890    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.6454 - r_square: 0.2091 - rmse: 0.6454 - val_loss: 0.7889 - val_r_square: 0.0140 - val_rmse: 0.7889    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.6461 - r_square: 0.2173 - rmse: 0.6461 - val_loss: 0.7899 - val_r_square: 0.0125 - val_rmse: 0.7899    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.6355 - r_square: 0.2341 - rmse: 0.6355 - val_loss: 0.7904 - val_r_square: 0.0118 - val_rmse: 0.7904    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.6452 - r_square: 0.2095 - rmse: 0.6452 - val_loss: 0.7905 - val_r_square: 0.0128 - val_rmse: 0.7905    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.7424035684410232                                                                                                     \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_14\"                                                                                                 \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_40 (Dense)             (None, 500)               3500                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_27 (Dropout)         (None, 500)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_41 (Dense)             (None, 50)                25050                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_28 (Dropout)         (None, 50)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_42 (Dense)             (None, 1)                 51                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 28,601                                                                                                   \n",
      "Trainable params: 28,601                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 0s - loss: 0.6899 - r_square: 0.1715 - rmse: 0.6899 - val_loss: 0.5116 - val_r_square: 0.5408 - val_rmse: 0.5116    \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.5772 - r_square: 0.3910 - rmse: 0.5772 - val_loss: 0.4831 - val_r_square: 0.6104 - val_rmse: 0.4831    \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.5170 - r_square: 0.4834 - rmse: 0.5170 - val_loss: 0.4158 - val_r_square: 0.6862 - val_rmse: 0.4158    \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.4937 - r_square: 0.5264 - rmse: 0.4937 - val_loss: 0.4036 - val_r_square: 0.7072 - val_rmse: 0.4036    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100                                                                                                            \n",
      " - 0s - loss: 0.4762 - r_square: 0.5499 - rmse: 0.4762 - val_loss: 0.3772 - val_r_square: 0.7293 - val_rmse: 0.3772    \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.4485 - r_square: 0.5828 - rmse: 0.4485 - val_loss: 0.3643 - val_r_square: 0.7435 - val_rmse: 0.3643    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.4285 - r_square: 0.6181 - rmse: 0.4285 - val_loss: 0.3467 - val_r_square: 0.7573 - val_rmse: 0.3467    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.4280 - r_square: 0.6181 - rmse: 0.4280 - val_loss: 0.3218 - val_r_square: 0.7761 - val_rmse: 0.3218    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.4138 - r_square: 0.6313 - rmse: 0.4138 - val_loss: 0.3167 - val_r_square: 0.7820 - val_rmse: 0.3167    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.4015 - r_square: 0.6481 - rmse: 0.4015 - val_loss: 0.3046 - val_r_square: 0.7860 - val_rmse: 0.3046    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.3949 - r_square: 0.6455 - rmse: 0.3949 - val_loss: 0.2946 - val_r_square: 0.7977 - val_rmse: 0.2946    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.3869 - r_square: 0.6703 - rmse: 0.3869 - val_loss: 0.2990 - val_r_square: 0.7967 - val_rmse: 0.2990    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.3907 - r_square: 0.6567 - rmse: 0.3907 - val_loss: 0.3049 - val_r_square: 0.7909 - val_rmse: 0.3049    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.3780 - r_square: 0.6727 - rmse: 0.3780 - val_loss: 0.2907 - val_r_square: 0.8021 - val_rmse: 0.2907    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n",
      " - 0s - loss: 0.3705 - r_square: 0.6840 - rmse: 0.3705 - val_loss: 0.2775 - val_r_square: 0.8096 - val_rmse: 0.2775    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.3702 - r_square: 0.6855 - rmse: 0.3702 - val_loss: 0.2553 - val_r_square: 0.8212 - val_rmse: 0.2553    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.3669 - r_square: 0.6775 - rmse: 0.3669 - val_loss: 0.2713 - val_r_square: 0.8164 - val_rmse: 0.2713    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.3585 - r_square: 0.7118 - rmse: 0.3585 - val_loss: 0.2582 - val_r_square: 0.8236 - val_rmse: 0.2582    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.3608 - r_square: 0.6995 - rmse: 0.3608 - val_loss: 0.2527 - val_r_square: 0.8275 - val_rmse: 0.2527    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.3495 - r_square: 0.7040 - rmse: 0.3495 - val_loss: 0.2669 - val_r_square: 0.8233 - val_rmse: 0.2669    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.3494 - r_square: 0.7098 - rmse: 0.3494 - val_loss: 0.2541 - val_r_square: 0.8279 - val_rmse: 0.2541    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.3495 - r_square: 0.7018 - rmse: 0.3495 - val_loss: 0.2474 - val_r_square: 0.8348 - val_rmse: 0.2474    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.3411 - r_square: 0.7232 - rmse: 0.3411 - val_loss: 0.2376 - val_r_square: 0.8394 - val_rmse: 0.2376    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.3410 - r_square: 0.7255 - rmse: 0.3410 - val_loss: 0.2445 - val_r_square: 0.8375 - val_rmse: 0.2445    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.3482 - r_square: 0.7072 - rmse: 0.3482 - val_loss: 0.2394 - val_r_square: 0.8405 - val_rmse: 0.2394    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.3426 - r_square: 0.7110 - rmse: 0.3426 - val_loss: 0.2321 - val_r_square: 0.8415 - val_rmse: 0.2321    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.3383 - r_square: 0.7121 - rmse: 0.3383 - val_loss: 0.2401 - val_r_square: 0.8411 - val_rmse: 0.2401    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.3420 - r_square: 0.7116 - rmse: 0.3420 - val_loss: 0.2436 - val_r_square: 0.8413 - val_rmse: 0.2436    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.3270 - r_square: 0.7284 - rmse: 0.3270 - val_loss: 0.2298 - val_r_square: 0.8476 - val_rmse: 0.2298    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.3366 - r_square: 0.7274 - rmse: 0.3366 - val_loss: 0.2382 - val_r_square: 0.8428 - val_rmse: 0.2382    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.3329 - r_square: 0.7288 - rmse: 0.3329 - val_loss: 0.2343 - val_r_square: 0.8478 - val_rmse: 0.2343    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.3296 - r_square: 0.7362 - rmse: 0.3296 - val_loss: 0.2391 - val_r_square: 0.8463 - val_rmse: 0.2391    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.3275 - r_square: 0.7321 - rmse: 0.3275 - val_loss: 0.2365 - val_r_square: 0.8477 - val_rmse: 0.2365    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.3229 - r_square: 0.7493 - rmse: 0.3229 - val_loss: 0.2238 - val_r_square: 0.8503 - val_rmse: 0.2238    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.3275 - r_square: 0.7289 - rmse: 0.3275 - val_loss: 0.2288 - val_r_square: 0.8494 - val_rmse: 0.2288    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.3249 - r_square: 0.7401 - rmse: 0.3249 - val_loss: 0.2261 - val_r_square: 0.8487 - val_rmse: 0.2261    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.3204 - r_square: 0.7443 - rmse: 0.3204 - val_loss: 0.2183 - val_r_square: 0.8514 - val_rmse: 0.2183    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.3198 - r_square: 0.7449 - rmse: 0.3198 - val_loss: 0.2340 - val_r_square: 0.8503 - val_rmse: 0.2340    \n",
      "\n",
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.3248 - r_square: 0.7334 - rmse: 0.3248 - val_loss: 0.2326 - val_r_square: 0.8496 - val_rmse: 0.2326    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.3203 - r_square: 0.7434 - rmse: 0.3203 - val_loss: 0.2336 - val_r_square: 0.8515 - val_rmse: 0.2336    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.3110 - r_square: 0.7571 - rmse: 0.3110 - val_loss: 0.2288 - val_r_square: 0.8537 - val_rmse: 0.2288    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.3182 - r_square: 0.7435 - rmse: 0.3182 - val_loss: 0.2267 - val_r_square: 0.8536 - val_rmse: 0.2267    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.3127 - r_square: 0.7471 - rmse: 0.3127 - val_loss: 0.2145 - val_r_square: 0.8565 - val_rmse: 0.2145    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.3182 - r_square: 0.7393 - rmse: 0.3182 - val_loss: 0.2215 - val_r_square: 0.8551 - val_rmse: 0.2215    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.3127 - r_square: 0.7540 - rmse: 0.3127 - val_loss: 0.2166 - val_r_square: 0.8578 - val_rmse: 0.2166    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.3137 - r_square: 0.7499 - rmse: 0.3137 - val_loss: 0.2234 - val_r_square: 0.8549 - val_rmse: 0.2234    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.3116 - r_square: 0.7584 - rmse: 0.3116 - val_loss: 0.2187 - val_r_square: 0.8580 - val_rmse: 0.2187    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.3099 - r_square: 0.7491 - rmse: 0.3099 - val_loss: 0.2144 - val_r_square: 0.8591 - val_rmse: 0.2144    \n",
      "\n",
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.3148 - r_square: 0.7467 - rmse: 0.3148 - val_loss: 0.2206 - val_r_square: 0.8574 - val_rmse: 0.2206    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.3113 - r_square: 0.7576 - rmse: 0.3113 - val_loss: 0.2232 - val_r_square: 0.8558 - val_rmse: 0.2232    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.3102 - r_square: 0.7579 - rmse: 0.3102 - val_loss: 0.2154 - val_r_square: 0.8606 - val_rmse: 0.2154    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.3115 - r_square: 0.7611 - rmse: 0.3115 - val_loss: 0.2148 - val_r_square: 0.8598 - val_rmse: 0.2148    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.3105 - r_square: 0.7578 - rmse: 0.3105 - val_loss: 0.2148 - val_r_square: 0.8588 - val_rmse: 0.2148    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.3081 - r_square: 0.7605 - rmse: 0.3081 - val_loss: 0.2238 - val_r_square: 0.8585 - val_rmse: 0.2238    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.3014 - r_square: 0.7632 - rmse: 0.3014 - val_loss: 0.2180 - val_r_square: 0.8583 - val_rmse: 0.2180    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.3022 - r_square: 0.7723 - rmse: 0.3022 - val_loss: 0.2206 - val_r_square: 0.8602 - val_rmse: 0.2206    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.3026 - r_square: 0.7674 - rmse: 0.3026 - val_loss: 0.2151 - val_r_square: 0.8610 - val_rmse: 0.2151    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.3042 - r_square: 0.7629 - rmse: 0.3042 - val_loss: 0.2261 - val_r_square: 0.8586 - val_rmse: 0.2261    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.3068 - r_square: 0.7626 - rmse: 0.3068 - val_loss: 0.2177 - val_r_square: 0.8614 - val_rmse: 0.2177    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.3034 - r_square: 0.7660 - rmse: 0.3034 - val_loss: 0.2307 - val_r_square: 0.8594 - val_rmse: 0.2307    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.3059 - r_square: 0.7562 - rmse: 0.3059 - val_loss: 0.2273 - val_r_square: 0.8587 - val_rmse: 0.2273    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.3005 - r_square: 0.7767 - rmse: 0.3005 - val_loss: 0.2217 - val_r_square: 0.8590 - val_rmse: 0.2217    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.3047 - r_square: 0.7662 - rmse: 0.3047 - val_loss: 0.2170 - val_r_square: 0.8636 - val_rmse: 0.2170    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.3029 - r_square: 0.7629 - rmse: 0.3029 - val_loss: 0.2078 - val_r_square: 0.8639 - val_rmse: 0.2078    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.3049 - r_square: 0.7745 - rmse: 0.3049 - val_loss: 0.2195 - val_r_square: 0.8604 - val_rmse: 0.2195    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.3058 - r_square: 0.7561 - rmse: 0.3058 - val_loss: 0.2157 - val_r_square: 0.8629 - val_rmse: 0.2157    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.3001 - r_square: 0.7582 - rmse: 0.3001 - val_loss: 0.2135 - val_r_square: 0.8620 - val_rmse: 0.2135    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.3007 - r_square: 0.7612 - rmse: 0.3007 - val_loss: 0.2033 - val_r_square: 0.8651 - val_rmse: 0.2033    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.3003 - r_square: 0.7559 - rmse: 0.3003 - val_loss: 0.2083 - val_r_square: 0.8658 - val_rmse: 0.2083    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.2992 - r_square: 0.7699 - rmse: 0.2992 - val_loss: 0.2071 - val_r_square: 0.8657 - val_rmse: 0.2071    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.3010 - r_square: 0.7696 - rmse: 0.3010 - val_loss: 0.2077 - val_r_square: 0.8677 - val_rmse: 0.2077    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100                                                                                                           \n",
      " - 0s - loss: 0.2957 - r_square: 0.7752 - rmse: 0.2957 - val_loss: 0.2107 - val_r_square: 0.8654 - val_rmse: 0.2107    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.3015 - r_square: 0.7641 - rmse: 0.3015 - val_loss: 0.2140 - val_r_square: 0.8650 - val_rmse: 0.2140    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.3053 - r_square: 0.7648 - rmse: 0.3053 - val_loss: 0.2174 - val_r_square: 0.8646 - val_rmse: 0.2174    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.3015 - r_square: 0.7710 - rmse: 0.3015 - val_loss: 0.2091 - val_r_square: 0.8669 - val_rmse: 0.2091    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.2974 - r_square: 0.7694 - rmse: 0.2974 - val_loss: 0.2107 - val_r_square: 0.8667 - val_rmse: 0.2107    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.2947 - r_square: 0.7804 - rmse: 0.2947 - val_loss: 0.2191 - val_r_square: 0.8638 - val_rmse: 0.2191    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.2962 - r_square: 0.7658 - rmse: 0.2962 - val_loss: 0.2061 - val_r_square: 0.8695 - val_rmse: 0.2061    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.3015 - r_square: 0.7646 - rmse: 0.3015 - val_loss: 0.2083 - val_r_square: 0.8684 - val_rmse: 0.2083    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.2947 - r_square: 0.7700 - rmse: 0.2947 - val_loss: 0.2045 - val_r_square: 0.8678 - val_rmse: 0.2045    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.2959 - r_square: 0.7801 - rmse: 0.2959 - val_loss: 0.2022 - val_r_square: 0.8692 - val_rmse: 0.2022    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n",
      " - 0s - loss: 0.3026 - r_square: 0.7639 - rmse: 0.3026 - val_loss: 0.2047 - val_r_square: 0.8694 - val_rmse: 0.2047    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.3036 - r_square: 0.7636 - rmse: 0.3036 - val_loss: 0.2039 - val_r_square: 0.8679 - val_rmse: 0.2039    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.2918 - r_square: 0.7829 - rmse: 0.2918 - val_loss: 0.2146 - val_r_square: 0.8660 - val_rmse: 0.2146    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.2945 - r_square: 0.7755 - rmse: 0.2945 - val_loss: 0.2129 - val_r_square: 0.8666 - val_rmse: 0.2129    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.2972 - r_square: 0.7756 - rmse: 0.2972 - val_loss: 0.2057 - val_r_square: 0.8684 - val_rmse: 0.2057    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.2970 - r_square: 0.7740 - rmse: 0.2970 - val_loss: 0.2160 - val_r_square: 0.8654 - val_rmse: 0.2160    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.2988 - r_square: 0.7676 - rmse: 0.2988 - val_loss: 0.2167 - val_r_square: 0.8676 - val_rmse: 0.2167    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.2944 - r_square: 0.7726 - rmse: 0.2944 - val_loss: 0.2127 - val_r_square: 0.8664 - val_rmse: 0.2127    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.2961 - r_square: 0.7695 - rmse: 0.2961 - val_loss: 0.1968 - val_r_square: 0.8732 - val_rmse: 0.1968    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.2937 - r_square: 0.7704 - rmse: 0.2937 - val_loss: 0.2043 - val_r_square: 0.8696 - val_rmse: 0.2043    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.2945 - r_square: 0.7673 - rmse: 0.2945 - val_loss: 0.2052 - val_r_square: 0.8712 - val_rmse: 0.2052    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.2905 - r_square: 0.7821 - rmse: 0.2905 - val_loss: 0.1926 - val_r_square: 0.8728 - val_rmse: 0.1926    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.2919 - r_square: 0.7805 - rmse: 0.2919 - val_loss: 0.2100 - val_r_square: 0.8689 - val_rmse: 0.2100    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.2940 - r_square: 0.7761 - rmse: 0.2940 - val_loss: 0.2177 - val_r_square: 0.8674 - val_rmse: 0.2177    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.2996 - r_square: 0.7673 - rmse: 0.2996 - val_loss: 0.2104 - val_r_square: 0.8688 - val_rmse: 0.2104    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.2973 - r_square: 0.7713 - rmse: 0.2973 - val_loss: 0.2089 - val_r_square: 0.8702 - val_rmse: 0.2089    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.2946 - r_square: 0.7718 - rmse: 0.2946 - val_loss: 0.1990 - val_r_square: 0.8703 - val_rmse: 0.1990    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.2924 - r_square: 0.7765 - rmse: 0.2924 - val_loss: 0.2043 - val_r_square: 0.8699 - val_rmse: 0.2043    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.2943 - r_square: 0.7706 - rmse: 0.2943 - val_loss: 0.2112 - val_r_square: 0.8679 - val_rmse: 0.2112    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.19263392083224337                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_15\"                                                                                                 \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_43 (Dense)             (None, 500)               3500                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_29 (Dropout)         (None, 500)               0                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________                                                      \n",
      "dense_44 (Dense)             (None, 200)               100200                                                          \n",
      "_________________________________________________________________                                                      \n",
      "dropout_30 (Dropout)         (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_45 (Dense)             (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 103,901                                                                                                  \n",
      "Trainable params: 103,901                                                                                              \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 0s - loss: 0.4525 - r_square: 0.5610 - rmse: 0.4525 - val_loss: 0.2768 - val_r_square: 0.8017 - val_rmse: 0.2768    \n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.2768 - r_square: 0.7709 - rmse: 0.2768 - val_loss: 0.2317 - val_r_square: 0.8299 - val_rmse: 0.2317    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.2464 - r_square: 0.8013 - rmse: 0.2464 - val_loss: 0.2095 - val_r_square: 0.8467 - val_rmse: 0.2095    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.2293 - r_square: 0.8126 - rmse: 0.2293 - val_loss: 0.2176 - val_r_square: 0.8229 - val_rmse: 0.2176    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.2202 - r_square: 0.8183 - rmse: 0.2202 - val_loss: 0.1961 - val_r_square: 0.8468 - val_rmse: 0.1961    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.2124 - r_square: 0.8232 - rmse: 0.2124 - val_loss: 0.1848 - val_r_square: 0.8715 - val_rmse: 0.1848    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.2050 - r_square: 0.8309 - rmse: 0.2050 - val_loss: 0.1778 - val_r_square: 0.8750 - val_rmse: 0.1778    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.1966 - r_square: 0.8309 - rmse: 0.1966 - val_loss: 0.1801 - val_r_square: 0.8755 - val_rmse: 0.1801    \n",
      "\n",
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.1927 - r_square: 0.8392 - rmse: 0.1927 - val_loss: 0.1626 - val_r_square: 0.8781 - val_rmse: 0.1626    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.1866 - r_square: 0.8444 - rmse: 0.1866 - val_loss: 0.1628 - val_r_square: 0.8858 - val_rmse: 0.1628    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.1853 - r_square: 0.8503 - rmse: 0.1853 - val_loss: 0.1608 - val_r_square: 0.8822 - val_rmse: 0.1608    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.1861 - r_square: 0.8373 - rmse: 0.1861 - val_loss: 0.1730 - val_r_square: 0.8864 - val_rmse: 0.1730    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.1859 - r_square: 0.8421 - rmse: 0.1859 - val_loss: 0.1601 - val_r_square: 0.8837 - val_rmse: 0.1601    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.1813 - r_square: 0.8571 - rmse: 0.1813 - val_loss: 0.1701 - val_r_square: 0.8824 - val_rmse: 0.1701    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.1792 - r_square: 0.8459 - rmse: 0.1792 - val_loss: 0.1594 - val_r_square: 0.8845 - val_rmse: 0.1594    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.1763 - r_square: 0.8477 - rmse: 0.1763 - val_loss: 0.1483 - val_r_square: 0.8890 - val_rmse: 0.1483    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.1738 - r_square: 0.8595 - rmse: 0.1738 - val_loss: 0.1511 - val_r_square: 0.8947 - val_rmse: 0.1511    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.1732 - r_square: 0.8565 - rmse: 0.1732 - val_loss: 0.1548 - val_r_square: 0.8955 - val_rmse: 0.1548    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.1727 - r_square: 0.8552 - rmse: 0.1727 - val_loss: 0.1670 - val_r_square: 0.8802 - val_rmse: 0.1670    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.1767 - r_square: 0.8595 - rmse: 0.1767 - val_loss: 0.1455 - val_r_square: 0.8938 - val_rmse: 0.1455    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.1671 - r_square: 0.8535 - rmse: 0.1671 - val_loss: 0.1371 - val_r_square: 0.8985 - val_rmse: 0.1371    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.1637 - r_square: 0.8612 - rmse: 0.1637 - val_loss: 0.1553 - val_r_square: 0.8913 - val_rmse: 0.1553    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.1676 - r_square: 0.8530 - rmse: 0.1676 - val_loss: 0.1548 - val_r_square: 0.8912 - val_rmse: 0.1548    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.1721 - r_square: 0.8533 - rmse: 0.1721 - val_loss: 0.1512 - val_r_square: 0.8992 - val_rmse: 0.1512    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.1643 - r_square: 0.8627 - rmse: 0.1643 - val_loss: 0.1574 - val_r_square: 0.8991 - val_rmse: 0.1574    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.1636 - r_square: 0.8570 - rmse: 0.1636 - val_loss: 0.1395 - val_r_square: 0.9021 - val_rmse: 0.1395    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.1642 - r_square: 0.8544 - rmse: 0.1642 - val_loss: 0.1359 - val_r_square: 0.9010 - val_rmse: 0.1359    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.1632 - r_square: 0.8647 - rmse: 0.1632 - val_loss: 0.1441 - val_r_square: 0.8952 - val_rmse: 0.1441    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50                                                                                                            \n",
      " - 0s - loss: 0.1600 - r_square: 0.8557 - rmse: 0.1600 - val_loss: 0.1344 - val_r_square: 0.9022 - val_rmse: 0.1344    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.1558 - r_square: 0.8698 - rmse: 0.1558 - val_loss: 0.1328 - val_r_square: 0.9016 - val_rmse: 0.1328    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.1575 - r_square: 0.8689 - rmse: 0.1575 - val_loss: 0.1378 - val_r_square: 0.9025 - val_rmse: 0.1378    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.1599 - r_square: 0.8661 - rmse: 0.1599 - val_loss: 0.1384 - val_r_square: 0.9037 - val_rmse: 0.1384    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.1601 - r_square: 0.8646 - rmse: 0.1601 - val_loss: 0.1568 - val_r_square: 0.8952 - val_rmse: 0.1568    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.1596 - r_square: 0.8629 - rmse: 0.1596 - val_loss: 0.1357 - val_r_square: 0.9028 - val_rmse: 0.1357    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.1551 - r_square: 0.8622 - rmse: 0.1551 - val_loss: 0.1345 - val_r_square: 0.9045 - val_rmse: 0.1345    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.1551 - r_square: 0.8689 - rmse: 0.1551 - val_loss: 0.1305 - val_r_square: 0.9046 - val_rmse: 0.1305    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.1579 - r_square: 0.8631 - rmse: 0.1579 - val_loss: 0.1287 - val_r_square: 0.9068 - val_rmse: 0.1287    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.1564 - r_square: 0.8682 - rmse: 0.1564 - val_loss: 0.1360 - val_r_square: 0.9017 - val_rmse: 0.1360    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.1526 - r_square: 0.8721 - rmse: 0.1526 - val_loss: 0.1299 - val_r_square: 0.9082 - val_rmse: 0.1299    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.1515 - r_square: 0.8726 - rmse: 0.1515 - val_loss: 0.1330 - val_r_square: 0.9112 - val_rmse: 0.1330    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.1560 - r_square: 0.8659 - rmse: 0.1560 - val_loss: 0.1335 - val_r_square: 0.9060 - val_rmse: 0.1335    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n",
      " - 0s - loss: 0.1508 - r_square: 0.8712 - rmse: 0.1508 - val_loss: 0.1254 - val_r_square: 0.9105 - val_rmse: 0.1254    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.1516 - r_square: 0.8828 - rmse: 0.1516 - val_loss: 0.1325 - val_r_square: 0.9073 - val_rmse: 0.1325    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.1544 - r_square: 0.8720 - rmse: 0.1544 - val_loss: 0.1438 - val_r_square: 0.9046 - val_rmse: 0.1438    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.1511 - r_square: 0.8694 - rmse: 0.1511 - val_loss: 0.1321 - val_r_square: 0.9064 - val_rmse: 0.1321    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.1597 - r_square: 0.8776 - rmse: 0.1597 - val_loss: 0.1336 - val_r_square: 0.9036 - val_rmse: 0.1336    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.1535 - r_square: 0.8740 - rmse: 0.1535 - val_loss: 0.1396 - val_r_square: 0.8998 - val_rmse: 0.1396    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.1517 - r_square: 0.8726 - rmse: 0.1517 - val_loss: 0.1339 - val_r_square: 0.9051 - val_rmse: 0.1339    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.1517 - r_square: 0.8644 - rmse: 0.1517 - val_loss: 0.1226 - val_r_square: 0.9119 - val_rmse: 0.1226    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.1505 - r_square: 0.8758 - rmse: 0.1505 - val_loss: 0.1295 - val_r_square: 0.9096 - val_rmse: 0.1295    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.12255392964199875                                                                                                    \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:57<00:00, 23.49s/trial, best loss: -0.7424035684410232]\n",
      "1486/1486 [==============================] - 0s 26us/step\n",
      "Evaluate: 0.8025105733569827\n",
      "Best Performing Model: {'Dense': 50, 'Dense_1': 500, 'Dropout': 0.9758185183456943, 'Dropout_1': 0.288662535902546, 'batch_size': 64, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "#defining the create model function\n",
    "exec('from __future__ import absolute_import, division, print_function')\n",
    "from hyperas.distributions import uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras import backend as K\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    print(x_train.shape)\n",
    "    model= Sequential() \n",
    "    model.add(Dense({{choice([50,200,500])}}, input_dim=x_train.shape[1], activation= 'relu'))\n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Dense({{choice([50,200,500])}},activation= 'relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Dense(1, activation= 'linear'))\n",
    "\n",
    "    \n",
    "################################################\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "    def rmse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "    def mse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "    def r_square(y_true, y_pred):\n",
    "        SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "        SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "        return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "#############################################\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
    "    from keras.utils import print_summary\n",
    "    print_summary(model, line_length=None, positions=None, print_fn=None)\n",
    "    result= model.fit(x_train, y_train,\n",
    "                      batch_size={{choice([64,128])}},\n",
    "                      epochs={{choice([50,100,150])}},\n",
    "                      verbose=2,\n",
    "                      validation_split =0.15)\n",
    "    validation_acc= np.min(result.history['val_loss'])\n",
    "    print('Lowest Validation Loss:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
    "\n",
    "#finding the best model\n",
    "best_run, best_model= optim.minimize(model=create_model,\n",
    "                                     data=data,\n",
    "                                     algo=tpe.suggest,\n",
    "                                     max_evals=5,\n",
    "                                     trials=Trials(),\n",
    "                                     eval_space=True,\n",
    "                                     notebook_name='NeuralAnalysis')\n",
    "score= best_model.evaluate(X_test_scaled,y_test_scaled, batch_size= 64)\n",
    "\n",
    "predictions_test = best_model.predict(X_test_scaled)\n",
    "predictions_train = best_model.predict(X_train_scaled)\n",
    "\n",
    "#print best model results\n",
    "print('Evaluate:', score[0])\n",
    "#print('Predictions:', predictions[:6])\n",
    "print('Best Performing Model:', best_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'r_square', 'rmse']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "[0.8025105784911647, -0.0095308106392622, 0.802510678768158]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test, verbose=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11042935],\n",
       "       [-0.02757291],\n",
       "       [ 0.08504621],\n",
       "       ...,\n",
       "       [-0.08176664],\n",
       "       [-0.07878926],\n",
       "       [-0.07380855]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using model to predict y values\n",
    "# predictions = best_model.predict(X_test_scaled)\n",
    "# predictions1 = best_model.predict(X_train_scaled)\n",
    "# predictions1\n",
    "#predictions= test\n",
    "#predictions1= train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Residuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Neural Network Residual Plot')\n",
    "plt.scatter(predictions1, predictions1 - y_train_scaled, c= \"orange\",label=\"Training Data\", s=4)\n",
    "plt.scatter(predictions, predictions - y_test_scaled, c= \"blue\",label=\"Testing Data\",s=4)\n",
    "plt.ylim(-2,2)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('neuralnetworkresidual.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the prediction with mse and r2\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_train = mean_squared_error(y_train_scaled, predictions1)\n",
    "r2_train = r2_score(y_train_scaled, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = mean_squared_error(y_test_scaled, predictions)\n",
    "r2_test = r2_score(y_test_scaled, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) Train Data: 0.9695344313476822\n",
      "R-squared (R2) Train Data: 0.030465568652317976\n",
      "-----------------------------------\n",
      "Mean Squared Error (MSE) Test Data: 0.9560464283070286\n",
      "R-squared (R2) Test Data: 0.02794750287581882\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Squared Error (MSE) Train Data: {mse_train}\")\n",
    "print(f\"R-squared (R2) Train Data: {r2_train}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Mean Squared Error (MSE) Test Data: {mse_test}\")\n",
    "print(f\"R-squared (R2) Test Data: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Dense': 50, 'Dense_1': 500, 'Dropout': 0.9758185183456943, 'Dropout_1': 0.288662535902546, 'batch_size': 64, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.975819 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "number_inputs = X_train.shape[1]\n",
    "#first dense\n",
    "model.add(Dense(units=50,\n",
    "                activation='relu', input_dim=number_inputs))\n",
    "#first dropout\n",
    "model.add(Dropout(0.9758185183456943))\n",
    "#second dense\n",
    "model.add(Dense(500, kernel_initializer='normal',activation='relu'))\n",
    "#second dropout\n",
    "model.add(Dropout(0.288662535902546))\n",
    "#last dense layer\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "from keras import losses\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",\n",
    "              optimizer=\"adam\", metrics=[r_square, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3788 samples, validate on 669 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.975819 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.975819 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "3788/3788 - 2s - loss: 0.6239 - r_square: 0.2548 - rmse: 0.6239 - val_loss: 0.6230 - val_r_square: 0.3358 - val_rmse: 0.6230\n",
      "Epoch 2/100\n",
      "3788/3788 - 1s - loss: 0.5560 - r_square: 0.3449 - rmse: 0.5560 - val_loss: 0.6734 - val_r_square: 0.2297 - val_rmse: 0.6734\n",
      "Epoch 3/100\n",
      "3788/3788 - 1s - loss: 0.5554 - r_square: 0.3437 - rmse: 0.5554 - val_loss: 0.7021 - val_r_square: 0.1668 - val_rmse: 0.7021\n",
      "Epoch 4/100\n",
      "3788/3788 - 1s - loss: 0.5295 - r_square: 0.3882 - rmse: 0.5295 - val_loss: 0.7251 - val_r_square: 0.1088 - val_rmse: 0.7251\n",
      "Epoch 5/100\n",
      "3788/3788 - 1s - loss: 0.5373 - r_square: 0.3599 - rmse: 0.5373 - val_loss: 0.7303 - val_r_square: 0.1004 - val_rmse: 0.7303\n",
      "Epoch 6/100\n",
      "3788/3788 - 1s - loss: 0.5302 - r_square: 0.3740 - rmse: 0.5302 - val_loss: 0.7262 - val_r_square: 0.0972 - val_rmse: 0.7262\n",
      "Epoch 7/100\n",
      "3788/3788 - 1s - loss: 0.5221 - r_square: 0.3741 - rmse: 0.5221 - val_loss: 0.7377 - val_r_square: 0.0764 - val_rmse: 0.7377\n",
      "Epoch 8/100\n",
      "3788/3788 - 1s - loss: 0.5269 - r_square: 0.3744 - rmse: 0.5269 - val_loss: 0.7452 - val_r_square: 0.0626 - val_rmse: 0.7452\n",
      "Epoch 9/100\n",
      "3788/3788 - 1s - loss: 0.5320 - r_square: 0.3465 - rmse: 0.5320 - val_loss: 0.7462 - val_r_square: 0.0584 - val_rmse: 0.7462\n",
      "Epoch 10/100\n",
      "3788/3788 - 1s - loss: 0.5185 - r_square: 0.3832 - rmse: 0.5185 - val_loss: 0.7514 - val_r_square: 0.0430 - val_rmse: 0.7514\n",
      "Epoch 11/100\n",
      "3788/3788 - 1s - loss: 0.5258 - r_square: 0.3785 - rmse: 0.5258 - val_loss: 0.7484 - val_r_square: 0.0510 - val_rmse: 0.7484\n",
      "Epoch 12/100\n",
      "3788/3788 - 1s - loss: 0.5106 - r_square: 0.3963 - rmse: 0.5106 - val_loss: 0.7531 - val_r_square: 0.0364 - val_rmse: 0.7531\n",
      "Epoch 13/100\n",
      "3788/3788 - 1s - loss: 0.5145 - r_square: 0.3950 - rmse: 0.5145 - val_loss: 0.7513 - val_r_square: 0.0416 - val_rmse: 0.7513\n",
      "Epoch 14/100\n",
      "3788/3788 - 1s - loss: 0.5222 - r_square: 0.3769 - rmse: 0.5222 - val_loss: 0.7510 - val_r_square: 0.0388 - val_rmse: 0.7510\n",
      "Epoch 15/100\n",
      "3788/3788 - 1s - loss: 0.5390 - r_square: 0.3463 - rmse: 0.5390 - val_loss: 0.7524 - val_r_square: 0.0378 - val_rmse: 0.7524\n",
      "Epoch 16/100\n",
      "3788/3788 - 1s - loss: 0.5168 - r_square: 0.3836 - rmse: 0.5168 - val_loss: 0.7533 - val_r_square: 0.0315 - val_rmse: 0.7533\n",
      "Epoch 17/100\n",
      "3788/3788 - 1s - loss: 0.5109 - r_square: 0.4003 - rmse: 0.5109 - val_loss: 0.7562 - val_r_square: 0.0289 - val_rmse: 0.7562\n",
      "Epoch 18/100\n",
      "3788/3788 - 1s - loss: 0.5118 - r_square: 0.3729 - rmse: 0.5118 - val_loss: 0.7510 - val_r_square: 0.0378 - val_rmse: 0.7510\n",
      "Epoch 19/100\n",
      "3788/3788 - 1s - loss: 0.5147 - r_square: 0.3821 - rmse: 0.5147 - val_loss: 0.7612 - val_r_square: 0.0199 - val_rmse: 0.7612\n",
      "Epoch 20/100\n",
      "3788/3788 - 1s - loss: 0.5184 - r_square: 0.3706 - rmse: 0.5184 - val_loss: 0.7637 - val_r_square: 0.0148 - val_rmse: 0.7637\n",
      "Epoch 21/100\n",
      "3788/3788 - 1s - loss: 0.5147 - r_square: 0.3808 - rmse: 0.5147 - val_loss: 0.7639 - val_r_square: 0.0137 - val_rmse: 0.7639\n",
      "Epoch 22/100\n",
      "3788/3788 - 1s - loss: 0.5081 - r_square: 0.3910 - rmse: 0.5081 - val_loss: 0.7624 - val_r_square: 0.0145 - val_rmse: 0.7624\n",
      "Epoch 23/100\n",
      "3788/3788 - 1s - loss: 0.5197 - r_square: 0.3556 - rmse: 0.5197 - val_loss: 0.7621 - val_r_square: 0.0159 - val_rmse: 0.7621\n",
      "Epoch 24/100\n",
      "3788/3788 - 1s - loss: 0.5095 - r_square: 0.3839 - rmse: 0.5095 - val_loss: 0.7573 - val_r_square: 0.0211 - val_rmse: 0.7573\n",
      "Epoch 25/100\n",
      "3788/3788 - 1s - loss: 0.5190 - r_square: 0.3761 - rmse: 0.5190 - val_loss: 0.7588 - val_r_square: 0.0189 - val_rmse: 0.7588\n",
      "Epoch 26/100\n",
      "3788/3788 - 1s - loss: 0.5185 - r_square: 0.3628 - rmse: 0.5185 - val_loss: 0.7648 - val_r_square: 0.0098 - val_rmse: 0.7648\n",
      "Epoch 27/100\n",
      "3788/3788 - 1s - loss: 0.5100 - r_square: 0.3892 - rmse: 0.5100 - val_loss: 0.7659 - val_r_square: 0.0077 - val_rmse: 0.7659\n",
      "Epoch 28/100\n",
      "3788/3788 - 0s - loss: 0.5000 - r_square: 0.4052 - rmse: 0.5000 - val_loss: 0.7627 - val_r_square: 0.0130 - val_rmse: 0.7627\n",
      "Epoch 29/100\n",
      "3788/3788 - 0s - loss: 0.5092 - r_square: 0.3814 - rmse: 0.5092 - val_loss: 0.7609 - val_r_square: 0.0159 - val_rmse: 0.7609\n",
      "Epoch 30/100\n",
      "3788/3788 - 1s - loss: 0.5149 - r_square: 0.3826 - rmse: 0.5149 - val_loss: 0.7635 - val_r_square: 0.0112 - val_rmse: 0.7635\n",
      "Epoch 31/100\n",
      "3788/3788 - 1s - loss: 0.5197 - r_square: 0.3718 - rmse: 0.5197 - val_loss: 0.7715 - val_r_square: -2.5863e-03 - val_rmse: 0.7715\n",
      "Epoch 32/100\n",
      "3788/3788 - 1s - loss: 0.5100 - r_square: 0.3878 - rmse: 0.5100 - val_loss: 0.7703 - val_r_square: -6.7507e-04 - val_rmse: 0.7703\n",
      "Epoch 33/100\n",
      "3788/3788 - 1s - loss: 0.5038 - r_square: 0.3973 - rmse: 0.5038 - val_loss: 0.7707 - val_r_square: -3.4713e-03 - val_rmse: 0.7707\n",
      "Epoch 34/100\n",
      "3788/3788 - 1s - loss: 0.5192 - r_square: 0.3816 - rmse: 0.5192 - val_loss: 0.7708 - val_r_square: -1.7694e-03 - val_rmse: 0.7708\n",
      "Epoch 35/100\n",
      "3788/3788 - 1s - loss: 0.5068 - r_square: 0.3879 - rmse: 0.5068 - val_loss: 0.7717 - val_r_square: -2.1132e-03 - val_rmse: 0.7717\n",
      "Epoch 36/100\n",
      "3788/3788 - 1s - loss: 0.5171 - r_square: 0.3741 - rmse: 0.5171 - val_loss: 0.7709 - val_r_square: -2.8288e-03 - val_rmse: 0.7709\n",
      "Epoch 37/100\n",
      "3788/3788 - 1s - loss: 0.5141 - r_square: 0.3746 - rmse: 0.5141 - val_loss: 0.7709 - val_r_square: -2.8224e-03 - val_rmse: 0.7709\n",
      "Epoch 38/100\n",
      "3788/3788 - 1s - loss: 0.5100 - r_square: 0.3838 - rmse: 0.5100 - val_loss: 0.7708 - val_r_square: -3.2903e-03 - val_rmse: 0.7708\n",
      "Epoch 39/100\n",
      "3788/3788 - 0s - loss: 0.5056 - r_square: 0.3968 - rmse: 0.5056 - val_loss: 0.7693 - val_r_square: -6.2381e-03 - val_rmse: 0.7693\n",
      "Epoch 40/100\n",
      "3788/3788 - 0s - loss: 0.5109 - r_square: 0.3746 - rmse: 0.5109 - val_loss: 0.7715 - val_r_square: -6.4790e-03 - val_rmse: 0.7715\n",
      "Epoch 41/100\n",
      "3788/3788 - 0s - loss: 0.5151 - r_square: 0.3869 - rmse: 0.5151 - val_loss: 0.7723 - val_r_square: -1.1785e-02 - val_rmse: 0.7723\n",
      "Epoch 42/100\n",
      "3788/3788 - 0s - loss: 0.5116 - r_square: 0.3763 - rmse: 0.5116 - val_loss: 0.7758 - val_r_square: -1.3596e-02 - val_rmse: 0.7758\n",
      "Epoch 43/100\n",
      "3788/3788 - 1s - loss: 0.5214 - r_square: 0.3733 - rmse: 0.5214 - val_loss: 0.7767 - val_r_square: -1.8252e-02 - val_rmse: 0.7767\n",
      "Epoch 44/100\n",
      "3788/3788 - 1s - loss: 0.5172 - r_square: 0.3816 - rmse: 0.5172 - val_loss: 0.7778 - val_r_square: -1.9107e-02 - val_rmse: 0.7778\n",
      "Epoch 45/100\n",
      "3788/3788 - 1s - loss: 0.5056 - r_square: 0.3976 - rmse: 0.5056 - val_loss: 0.7795 - val_r_square: -2.0701e-02 - val_rmse: 0.7795\n",
      "Epoch 46/100\n",
      "3788/3788 - 1s - loss: 0.5265 - r_square: 0.3387 - rmse: 0.5265 - val_loss: 0.7746 - val_r_square: -1.3394e-02 - val_rmse: 0.7746\n",
      "Epoch 47/100\n",
      "3788/3788 - 1s - loss: 0.5092 - r_square: 0.3912 - rmse: 0.5092 - val_loss: 0.7773 - val_r_square: -1.8436e-02 - val_rmse: 0.7773\n",
      "Epoch 48/100\n",
      "3788/3788 - 1s - loss: 0.5062 - r_square: 0.3842 - rmse: 0.5062 - val_loss: 0.7789 - val_r_square: -2.0043e-02 - val_rmse: 0.7789\n",
      "Epoch 49/100\n",
      "3788/3788 - 1s - loss: 0.5126 - r_square: 0.3794 - rmse: 0.5126 - val_loss: 0.7766 - val_r_square: -1.7592e-02 - val_rmse: 0.7766\n",
      "Epoch 50/100\n",
      "3788/3788 - 1s - loss: 0.5068 - r_square: 0.3916 - rmse: 0.5068 - val_loss: 0.7767 - val_r_square: -1.7308e-02 - val_rmse: 0.7767\n",
      "Epoch 51/100\n",
      "3788/3788 - 1s - loss: 0.5003 - r_square: 0.3948 - rmse: 0.5003 - val_loss: 0.7761 - val_r_square: -1.9097e-02 - val_rmse: 0.7761\n",
      "Epoch 52/100\n",
      "3788/3788 - 1s - loss: 0.5287 - r_square: 0.3408 - rmse: 0.5287 - val_loss: 0.7798 - val_r_square: -2.1900e-02 - val_rmse: 0.7798\n",
      "Epoch 53/100\n",
      "3788/3788 - 1s - loss: 0.5097 - r_square: 0.3836 - rmse: 0.5097 - val_loss: 0.7748 - val_r_square: -1.5928e-02 - val_rmse: 0.7748\n",
      "Epoch 54/100\n",
      "3788/3788 - 1s - loss: 0.5073 - r_square: 0.3975 - rmse: 0.5073 - val_loss: 0.7761 - val_r_square: -1.9561e-02 - val_rmse: 0.7761\n",
      "Epoch 55/100\n",
      "3788/3788 - 1s - loss: 0.5067 - r_square: 0.3921 - rmse: 0.5067 - val_loss: 0.7777 - val_r_square: -2.3856e-02 - val_rmse: 0.7777\n",
      "Epoch 56/100\n",
      "3788/3788 - 0s - loss: 0.4980 - r_square: 0.4081 - rmse: 0.4980 - val_loss: 0.7767 - val_r_square: -1.9859e-02 - val_rmse: 0.7767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "3788/3788 - 1s - loss: 0.5084 - r_square: 0.3763 - rmse: 0.5084 - val_loss: 0.7790 - val_r_square: -2.3721e-02 - val_rmse: 0.7790\n",
      "Epoch 58/100\n",
      "3788/3788 - 1s - loss: 0.5022 - r_square: 0.3944 - rmse: 0.5022 - val_loss: 0.7766 - val_r_square: -1.9441e-02 - val_rmse: 0.7766\n",
      "Epoch 59/100\n",
      "3788/3788 - 0s - loss: 0.5050 - r_square: 0.3942 - rmse: 0.5050 - val_loss: 0.7761 - val_r_square: -1.9069e-02 - val_rmse: 0.7761\n",
      "Epoch 60/100\n",
      "3788/3788 - 0s - loss: 0.5138 - r_square: 0.3816 - rmse: 0.5138 - val_loss: 0.7753 - val_r_square: -1.7307e-02 - val_rmse: 0.7753\n",
      "Epoch 61/100\n",
      "3788/3788 - 0s - loss: 0.5054 - r_square: 0.3830 - rmse: 0.5054 - val_loss: 0.7706 - val_r_square: -1.1960e-02 - val_rmse: 0.7706\n",
      "Epoch 62/100\n",
      "3788/3788 - 0s - loss: 0.5061 - r_square: 0.3866 - rmse: 0.5061 - val_loss: 0.7746 - val_r_square: -1.8148e-02 - val_rmse: 0.7746\n",
      "Epoch 63/100\n",
      "3788/3788 - 0s - loss: 0.5020 - r_square: 0.4144 - rmse: 0.5020 - val_loss: 0.7736 - val_r_square: -1.6318e-02 - val_rmse: 0.7736\n",
      "Epoch 64/100\n",
      "3788/3788 - 0s - loss: 0.4986 - r_square: 0.3958 - rmse: 0.4986 - val_loss: 0.7744 - val_r_square: -1.8295e-02 - val_rmse: 0.7744\n",
      "Epoch 65/100\n",
      "3788/3788 - 0s - loss: 0.5150 - r_square: 0.3774 - rmse: 0.5150 - val_loss: 0.7695 - val_r_square: -1.3754e-02 - val_rmse: 0.7695\n",
      "Epoch 66/100\n",
      "3788/3788 - 0s - loss: 0.5018 - r_square: 0.3924 - rmse: 0.5018 - val_loss: 0.7787 - val_r_square: -2.2820e-02 - val_rmse: 0.7787\n",
      "Epoch 67/100\n",
      "3788/3788 - 0s - loss: 0.5071 - r_square: 0.3875 - rmse: 0.5071 - val_loss: 0.7779 - val_r_square: -2.3669e-02 - val_rmse: 0.7779\n",
      "Epoch 68/100\n",
      "3788/3788 - 0s - loss: 0.5078 - r_square: 0.3808 - rmse: 0.5078 - val_loss: 0.7750 - val_r_square: -2.0141e-02 - val_rmse: 0.7750\n",
      "Epoch 69/100\n",
      "3788/3788 - 0s - loss: 0.5161 - r_square: 0.3667 - rmse: 0.5161 - val_loss: 0.7761 - val_r_square: -1.8364e-02 - val_rmse: 0.7761\n",
      "Epoch 70/100\n",
      "3788/3788 - 0s - loss: 0.4981 - r_square: 0.4033 - rmse: 0.4981 - val_loss: 0.7737 - val_r_square: -1.8978e-02 - val_rmse: 0.7737\n",
      "Epoch 71/100\n",
      "3788/3788 - 0s - loss: 0.5142 - r_square: 0.3748 - rmse: 0.5142 - val_loss: 0.7759 - val_r_square: -1.7445e-02 - val_rmse: 0.7759\n",
      "Epoch 72/100\n",
      "3788/3788 - 0s - loss: 0.5072 - r_square: 0.3989 - rmse: 0.5072 - val_loss: 0.7712 - val_r_square: -1.4491e-02 - val_rmse: 0.7712\n",
      "Epoch 73/100\n",
      "3788/3788 - 0s - loss: 0.4966 - r_square: 0.3882 - rmse: 0.4966 - val_loss: 0.7728 - val_r_square: -1.5400e-02 - val_rmse: 0.7728\n",
      "Epoch 74/100\n",
      "3788/3788 - 0s - loss: 0.5062 - r_square: 0.3723 - rmse: 0.5062 - val_loss: 0.7711 - val_r_square: -1.3631e-02 - val_rmse: 0.7711\n",
      "Epoch 75/100\n",
      "3788/3788 - 1s - loss: 0.5032 - r_square: 0.3790 - rmse: 0.5032 - val_loss: 0.7715 - val_r_square: -1.1505e-02 - val_rmse: 0.7715\n",
      "Epoch 76/100\n",
      "3788/3788 - 0s - loss: 0.5039 - r_square: 0.3855 - rmse: 0.5039 - val_loss: 0.7728 - val_r_square: -1.7643e-02 - val_rmse: 0.7728\n",
      "Epoch 77/100\n",
      "3788/3788 - 0s - loss: 0.5021 - r_square: 0.3921 - rmse: 0.5021 - val_loss: 0.7716 - val_r_square: -1.4731e-02 - val_rmse: 0.7716\n",
      "Epoch 78/100\n",
      "3788/3788 - 0s - loss: 0.5072 - r_square: 0.3819 - rmse: 0.5072 - val_loss: 0.7756 - val_r_square: -2.0402e-02 - val_rmse: 0.7756\n",
      "Epoch 79/100\n",
      "3788/3788 - 0s - loss: 0.5007 - r_square: 0.4034 - rmse: 0.5007 - val_loss: 0.7744 - val_r_square: -1.9976e-02 - val_rmse: 0.7744\n",
      "Epoch 80/100\n",
      "3788/3788 - 0s - loss: 0.5085 - r_square: 0.3805 - rmse: 0.5085 - val_loss: 0.7749 - val_r_square: -1.9796e-02 - val_rmse: 0.7749\n",
      "Epoch 81/100\n",
      "3788/3788 - 0s - loss: 0.5064 - r_square: 0.3856 - rmse: 0.5064 - val_loss: 0.7704 - val_r_square: -1.2505e-02 - val_rmse: 0.7704\n",
      "Epoch 82/100\n",
      "3788/3788 - 0s - loss: 0.4972 - r_square: 0.4035 - rmse: 0.4972 - val_loss: 0.7732 - val_r_square: -1.8162e-02 - val_rmse: 0.7732\n",
      "Epoch 83/100\n",
      "3788/3788 - 0s - loss: 0.5136 - r_square: 0.3567 - rmse: 0.5136 - val_loss: 0.7715 - val_r_square: -1.3909e-02 - val_rmse: 0.7715\n",
      "Epoch 84/100\n",
      "3788/3788 - 0s - loss: 0.4957 - r_square: 0.4043 - rmse: 0.4957 - val_loss: 0.7732 - val_r_square: -1.7122e-02 - val_rmse: 0.7732\n",
      "Epoch 85/100\n",
      "3788/3788 - 0s - loss: 0.5023 - r_square: 0.3888 - rmse: 0.5023 - val_loss: 0.7735 - val_r_square: -1.7476e-02 - val_rmse: 0.7735\n",
      "Epoch 86/100\n",
      "3788/3788 - 0s - loss: 0.4965 - r_square: 0.4010 - rmse: 0.4965 - val_loss: 0.7729 - val_r_square: -1.5470e-02 - val_rmse: 0.7729\n",
      "Epoch 87/100\n",
      "3788/3788 - 0s - loss: 0.5011 - r_square: 0.3880 - rmse: 0.5011 - val_loss: 0.7732 - val_r_square: -1.8134e-02 - val_rmse: 0.7732\n",
      "Epoch 88/100\n",
      "3788/3788 - 0s - loss: 0.5172 - r_square: 0.3530 - rmse: 0.5172 - val_loss: 0.7741 - val_r_square: -2.0743e-02 - val_rmse: 0.7741\n",
      "Epoch 89/100\n",
      "3788/3788 - 0s - loss: 0.4991 - r_square: 0.3923 - rmse: 0.4991 - val_loss: 0.7758 - val_r_square: -2.2145e-02 - val_rmse: 0.7758\n",
      "Epoch 90/100\n",
      "3788/3788 - 0s - loss: 0.5045 - r_square: 0.3928 - rmse: 0.5045 - val_loss: 0.7751 - val_r_square: -2.0692e-02 - val_rmse: 0.7751\n",
      "Epoch 91/100\n",
      "3788/3788 - 0s - loss: 0.4932 - r_square: 0.4093 - rmse: 0.4932 - val_loss: 0.7723 - val_r_square: -1.9267e-02 - val_rmse: 0.7723\n",
      "Epoch 92/100\n",
      "3788/3788 - 0s - loss: 0.4920 - r_square: 0.4114 - rmse: 0.4920 - val_loss: 0.7740 - val_r_square: -2.1124e-02 - val_rmse: 0.7740\n",
      "Epoch 93/100\n",
      "3788/3788 - 0s - loss: 0.5045 - r_square: 0.3853 - rmse: 0.5045 - val_loss: 0.7704 - val_r_square: -1.4226e-02 - val_rmse: 0.7704\n",
      "Epoch 94/100\n",
      "3788/3788 - 0s - loss: 0.5000 - r_square: 0.3857 - rmse: 0.5000 - val_loss: 0.7743 - val_r_square: -2.1973e-02 - val_rmse: 0.7743\n",
      "Epoch 95/100\n",
      "3788/3788 - 0s - loss: 0.4966 - r_square: 0.4115 - rmse: 0.4966 - val_loss: 0.7729 - val_r_square: -2.0556e-02 - val_rmse: 0.7729\n",
      "Epoch 96/100\n",
      "3788/3788 - 0s - loss: 0.5096 - r_square: 0.3761 - rmse: 0.5096 - val_loss: 0.7724 - val_r_square: -2.1131e-02 - val_rmse: 0.7724\n",
      "Epoch 97/100\n",
      "3788/3788 - 0s - loss: 0.5094 - r_square: 0.3775 - rmse: 0.5094 - val_loss: 0.7744 - val_r_square: -2.1668e-02 - val_rmse: 0.7744\n",
      "Epoch 98/100\n",
      "3788/3788 - 0s - loss: 0.5028 - r_square: 0.3831 - rmse: 0.5028 - val_loss: 0.7741 - val_r_square: -2.5062e-02 - val_rmse: 0.7741\n",
      "Epoch 99/100\n",
      "3788/3788 - 0s - loss: 0.5036 - r_square: 0.3954 - rmse: 0.5036 - val_loss: 0.7763 - val_r_square: -2.8439e-02 - val_rmse: 0.7763\n",
      "Epoch 100/100\n",
      "3788/3788 - 0s - loss: 0.5086 - r_square: 0.3824 - rmse: 0.5086 - val_loss: 0.7762 - val_r_square: -2.9425e-02 - val_rmse: 0.7762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8b1447e48>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = data()\n",
    "model.fit(x_train,y_train,epochs=100, shuffle=True, validation_split=.15, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "[0.7785015925263653, -0.0045601293, 0.77850163]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalutation of best performing model:\")\n",
    "print(model.evaluate(x_test, y_test, verbose=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) Train Data: 0.9695344313476822\n",
      "R-squared (R2) Train Data: 0.030465568652317976\n",
      "-----------------------------------\n",
      "Mean Squared Error (MSE) Test Data: 0.9560464283070286\n",
      "R-squared (R2) Test Data: 0.02794750287581882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_train = mean_squared_error(y_train_scaled, predictions1)\n",
    "r2_train = r2_score(y_train_scaled, predictions1)\n",
    "\n",
    "mse_test = mean_squared_error(y_test_scaled, predictions)\n",
    "r2_test = r2_score(y_test_scaled, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) Train Data: {mse_train}\")\n",
    "print(f\"R-squared (R2) Train Data: {r2_train}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Mean Squared Error (MSE) Test Data: {mse_test}\")\n",
    "print(f\"R-squared (R2) Test Data: {r2_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Volve",
   "language": "python",
   "name": "volve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
