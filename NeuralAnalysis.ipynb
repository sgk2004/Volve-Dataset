{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Deep Learning with Keras Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WELL_BORE_CODE</th>\n",
       "      <th>AVG_DOWNHOLE_PRESSURE</th>\n",
       "      <th>AVG_DOWNHOLE_TEMPERATURE</th>\n",
       "      <th>AVG_CHOKE_SIZE_P</th>\n",
       "      <th>AVG_WHP_P</th>\n",
       "      <th>AVG_WHT_P</th>\n",
       "      <th>DP_CHOKE_SIZE</th>\n",
       "      <th>BORE_OIL_VOL</th>\n",
       "      <th>BORE_GAS_VOL</th>\n",
       "      <th>BORE_WAT_VOL</th>\n",
       "      <th>FLOW_KIND</th>\n",
       "      <th>WELL_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>289.42</td>\n",
       "      <td>106.35</td>\n",
       "      <td>43.34</td>\n",
       "      <td>107.36</td>\n",
       "      <td>37.94</td>\n",
       "      <td>78.94</td>\n",
       "      <td>631.47</td>\n",
       "      <td>90439.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>270.24</td>\n",
       "      <td>107.64</td>\n",
       "      <td>47.17</td>\n",
       "      <td>99.19</td>\n",
       "      <td>60.76</td>\n",
       "      <td>70.63</td>\n",
       "      <td>1166.46</td>\n",
       "      <td>165720.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>262.84</td>\n",
       "      <td>107.87</td>\n",
       "      <td>47.73</td>\n",
       "      <td>94.60</td>\n",
       "      <td>63.05</td>\n",
       "      <td>66.05</td>\n",
       "      <td>1549.81</td>\n",
       "      <td>221707.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>255.53</td>\n",
       "      <td>107.97</td>\n",
       "      <td>48.53</td>\n",
       "      <td>89.99</td>\n",
       "      <td>64.55</td>\n",
       "      <td>61.41</td>\n",
       "      <td>1248.70</td>\n",
       "      <td>178063.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>NO 15/9-F-1 C</td>\n",
       "      <td>247.20</td>\n",
       "      <td>108.05</td>\n",
       "      <td>49.84</td>\n",
       "      <td>84.78</td>\n",
       "      <td>65.72</td>\n",
       "      <td>56.15</td>\n",
       "      <td>1345.78</td>\n",
       "      <td>192602.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>8923</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.58</td>\n",
       "      <td>15.81</td>\n",
       "      <td>49.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>144.01</td>\n",
       "      <td>23201.35</td>\n",
       "      <td>203.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>8924</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.98</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.54</td>\n",
       "      <td>15.77</td>\n",
       "      <td>48.99</td>\n",
       "      <td>1.20</td>\n",
       "      <td>145.22</td>\n",
       "      <td>23068.07</td>\n",
       "      <td>202.93</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>8925</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>194.32</td>\n",
       "      <td>106.52</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.70</td>\n",
       "      <td>50.10</td>\n",
       "      <td>1.28</td>\n",
       "      <td>142.74</td>\n",
       "      <td>23059.68</td>\n",
       "      <td>203.84</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>8926</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.21</td>\n",
       "      <td>106.51</td>\n",
       "      <td>31.52</td>\n",
       "      <td>15.61</td>\n",
       "      <td>49.84</td>\n",
       "      <td>1.20</td>\n",
       "      <td>144.46</td>\n",
       "      <td>23090.47</td>\n",
       "      <td>202.76</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>8927</td>\n",
       "      <td>NO 15/9-F-15 D</td>\n",
       "      <td>195.31</td>\n",
       "      <td>106.51</td>\n",
       "      <td>24.92</td>\n",
       "      <td>15.76</td>\n",
       "      <td>48.73</td>\n",
       "      <td>1.30</td>\n",
       "      <td>106.30</td>\n",
       "      <td>17537.08</td>\n",
       "      <td>155.70</td>\n",
       "      <td>production</td>\n",
       "      <td>OP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5943 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  WELL_BORE_CODE  AVG_DOWNHOLE_PRESSURE  \\\n",
       "0             15   NO 15/9-F-1 C                 289.42   \n",
       "1             16   NO 15/9-F-1 C                 270.24   \n",
       "2             17   NO 15/9-F-1 C                 262.84   \n",
       "3             18   NO 15/9-F-1 C                 255.53   \n",
       "4             19   NO 15/9-F-1 C                 247.20   \n",
       "...          ...             ...                    ...   \n",
       "5938        8923  NO 15/9-F-15 D                 194.98   \n",
       "5939        8924  NO 15/9-F-15 D                 194.98   \n",
       "5940        8925  NO 15/9-F-15 D                 194.32   \n",
       "5941        8926  NO 15/9-F-15 D                 195.21   \n",
       "5942        8927  NO 15/9-F-15 D                 195.31   \n",
       "\n",
       "      AVG_DOWNHOLE_TEMPERATURE  AVG_CHOKE_SIZE_P  AVG_WHP_P  AVG_WHT_P  \\\n",
       "0                       106.35             43.34     107.36      37.94   \n",
       "1                       107.64             47.17      99.19      60.76   \n",
       "2                       107.87             47.73      94.60      63.05   \n",
       "3                       107.97             48.53      89.99      64.55   \n",
       "4                       108.05             49.84      84.78      65.72   \n",
       "...                        ...               ...        ...        ...   \n",
       "5938                    106.52             31.58      15.81      49.02   \n",
       "5939                    106.52             31.54      15.77      48.99   \n",
       "5940                    106.52             31.52      15.70      50.10   \n",
       "5941                    106.51             31.52      15.61      49.84   \n",
       "5942                    106.51             24.92      15.76      48.73   \n",
       "\n",
       "      DP_CHOKE_SIZE  BORE_OIL_VOL  BORE_GAS_VOL  BORE_WAT_VOL   FLOW_KIND  \\\n",
       "0             78.94        631.47      90439.09          0.00  production   \n",
       "1             70.63       1166.46     165720.39          0.00  production   \n",
       "2             66.05       1549.81     221707.31          0.00  production   \n",
       "3             61.41       1248.70     178063.52          0.00  production   \n",
       "4             56.15       1345.78     192602.19          0.00  production   \n",
       "...             ...           ...           ...           ...         ...   \n",
       "5938           1.26        144.01      23201.35        203.93  production   \n",
       "5939           1.20        145.22      23068.07        202.93  production   \n",
       "5940           1.28        142.74      23059.68        203.84  production   \n",
       "5941           1.20        144.46      23090.47        202.76  production   \n",
       "5942           1.30        106.30      17537.08        155.70  production   \n",
       "\n",
       "     WELL_TYPE  \n",
       "0           OP  \n",
       "1           OP  \n",
       "2           OP  \n",
       "3           OP  \n",
       "4           OP  \n",
       "...        ...  \n",
       "5938        OP  \n",
       "5939        OP  \n",
       "5940        OP  \n",
       "5941        OP  \n",
       "5942        OP  \n",
       "\n",
       "[5943 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data csv\n",
    "all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "all_wells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUTS: AVG_CHOKE_SIZE_P, AVG_WHP_P, AVG_WHT_P, BORE_OIL_VOL, BORE_GAS_VOL, BORE_WAT_VOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5943, 6)\n"
     ]
    }
   ],
   "source": [
    "#read in data for analysis \n",
    "X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = X_train.shape[1]\n",
    "number_hidden_nodes = 100\n",
    "\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(number_hidden_nodes, kernel_initializer='normal',activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal',activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#compile the model\n",
    "from keras import losses\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\",\n",
    "              optimizer=\"adam\", metrics=[r_square, rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,901\n",
      "Trainable params: 10,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "1263/1263 - 1s - loss: 0.6407 - r_square: 0.2793 - rmse: 0.6407 - val_loss: 0.4792 - val_r_square: 0.5205 - val_rmse: 0.4792\n",
      "Epoch 2/100\n",
      "1263/1263 - 0s - loss: 0.4061 - r_square: 0.5992 - rmse: 0.4061 - val_loss: 0.3670 - val_r_square: 0.6360 - val_rmse: 0.3670\n",
      "Epoch 3/100\n",
      "1263/1263 - 0s - loss: 0.3072 - r_square: 0.7510 - rmse: 0.3072 - val_loss: 0.3023 - val_r_square: 0.6769 - val_rmse: 0.3023\n",
      "Epoch 4/100\n",
      "1263/1263 - 0s - loss: 0.2560 - r_square: 0.8037 - rmse: 0.2560 - val_loss: 0.2752 - val_r_square: 0.6829 - val_rmse: 0.2752\n",
      "Epoch 5/100\n",
      "1263/1263 - 0s - loss: 0.2290 - r_square: 0.8339 - rmse: 0.2290 - val_loss: 0.2692 - val_r_square: 0.6804 - val_rmse: 0.2692\n",
      "Epoch 6/100\n",
      "1263/1263 - 0s - loss: 0.2144 - r_square: 0.8449 - rmse: 0.2144 - val_loss: 0.2507 - val_r_square: 0.6796 - val_rmse: 0.2507\n",
      "Epoch 7/100\n",
      "1263/1263 - 0s - loss: 0.2020 - r_square: 0.8461 - rmse: 0.2020 - val_loss: 0.2814 - val_r_square: 0.6452 - val_rmse: 0.2814\n",
      "Epoch 8/100\n",
      "1263/1263 - 0s - loss: 0.1974 - r_square: 0.8548 - rmse: 0.1974 - val_loss: 0.2503 - val_r_square: 0.6584 - val_rmse: 0.2503\n",
      "Epoch 9/100\n",
      "1263/1263 - 0s - loss: 0.1901 - r_square: 0.8669 - rmse: 0.1901 - val_loss: 0.2361 - val_r_square: 0.6449 - val_rmse: 0.2361\n",
      "Epoch 10/100\n",
      "1263/1263 - 0s - loss: 0.1818 - r_square: 0.8697 - rmse: 0.1818 - val_loss: 0.2288 - val_r_square: 0.6611 - val_rmse: 0.2288\n",
      "Epoch 11/100\n",
      "1263/1263 - 0s - loss: 0.1729 - r_square: 0.8732 - rmse: 0.1729 - val_loss: 0.2442 - val_r_square: 0.6392 - val_rmse: 0.2442\n",
      "Epoch 12/100\n",
      "1263/1263 - 0s - loss: 0.1691 - r_square: 0.8633 - rmse: 0.1691 - val_loss: 0.2210 - val_r_square: 0.6447 - val_rmse: 0.2210\n",
      "Epoch 13/100\n",
      "1263/1263 - 0s - loss: 0.1654 - r_square: 0.8700 - rmse: 0.1654 - val_loss: 0.2270 - val_r_square: 0.6449 - val_rmse: 0.2270\n",
      "Epoch 14/100\n",
      "1263/1263 - 0s - loss: 0.1680 - r_square: 0.8776 - rmse: 0.1680 - val_loss: 0.2297 - val_r_square: 0.6523 - val_rmse: 0.2297\n",
      "Epoch 15/100\n",
      "1263/1263 - 0s - loss: 0.1655 - r_square: 0.8794 - rmse: 0.1655 - val_loss: 0.2170 - val_r_square: 0.6418 - val_rmse: 0.2170\n",
      "Epoch 16/100\n",
      "1263/1263 - 0s - loss: 0.1628 - r_square: 0.8773 - rmse: 0.1628 - val_loss: 0.2219 - val_r_square: 0.6318 - val_rmse: 0.2219\n",
      "Epoch 17/100\n",
      "1263/1263 - 0s - loss: 0.1579 - r_square: 0.8805 - rmse: 0.1579 - val_loss: 0.2113 - val_r_square: 0.6341 - val_rmse: 0.2113\n",
      "Epoch 18/100\n",
      "1263/1263 - 0s - loss: 0.1517 - r_square: 0.8767 - rmse: 0.1517 - val_loss: 0.2153 - val_r_square: 0.6266 - val_rmse: 0.2153\n",
      "Epoch 19/100\n",
      "1263/1263 - 0s - loss: 0.1533 - r_square: 0.8847 - rmse: 0.1533 - val_loss: 0.2033 - val_r_square: 0.6358 - val_rmse: 0.2033\n",
      "Epoch 20/100\n",
      "1263/1263 - 0s - loss: 0.1565 - r_square: 0.8866 - rmse: 0.1565 - val_loss: 0.2081 - val_r_square: 0.6204 - val_rmse: 0.2081\n",
      "Epoch 21/100\n",
      "1263/1263 - 0s - loss: 0.1517 - r_square: 0.8646 - rmse: 0.1517 - val_loss: 0.2288 - val_r_square: 0.6292 - val_rmse: 0.2288\n",
      "Epoch 22/100\n",
      "1263/1263 - 0s - loss: 0.1521 - r_square: 0.8906 - rmse: 0.1521 - val_loss: 0.2051 - val_r_square: 0.6211 - val_rmse: 0.2051\n",
      "Epoch 23/100\n",
      "1263/1263 - 0s - loss: 0.1469 - r_square: 0.8918 - rmse: 0.1469 - val_loss: 0.2147 - val_r_square: 0.6284 - val_rmse: 0.2147\n",
      "Epoch 24/100\n",
      "1263/1263 - 0s - loss: 0.1494 - r_square: 0.8677 - rmse: 0.1494 - val_loss: 0.2079 - val_r_square: 0.6213 - val_rmse: 0.2079\n",
      "Epoch 25/100\n",
      "1263/1263 - 0s - loss: 0.1527 - r_square: 0.8831 - rmse: 0.1527 - val_loss: 0.2254 - val_r_square: 0.6036 - val_rmse: 0.2254\n",
      "Epoch 26/100\n",
      "1263/1263 - 0s - loss: 0.1455 - r_square: 0.8853 - rmse: 0.1455 - val_loss: 0.2039 - val_r_square: 0.6224 - val_rmse: 0.2039\n",
      "Epoch 27/100\n",
      "1263/1263 - 0s - loss: 0.1444 - r_square: 0.8812 - rmse: 0.1444 - val_loss: 0.2074 - val_r_square: 0.6163 - val_rmse: 0.2074\n",
      "Epoch 28/100\n",
      "1263/1263 - 0s - loss: 0.1419 - r_square: 0.8858 - rmse: 0.1419 - val_loss: 0.2016 - val_r_square: 0.6185 - val_rmse: 0.2016\n",
      "Epoch 29/100\n",
      "1263/1263 - 0s - loss: 0.1381 - r_square: 0.8870 - rmse: 0.1381 - val_loss: 0.1946 - val_r_square: 0.6228 - val_rmse: 0.1946\n",
      "Epoch 30/100\n",
      "1263/1263 - 0s - loss: 0.1453 - r_square: 0.8799 - rmse: 0.1453 - val_loss: 0.2042 - val_r_square: 0.6249 - val_rmse: 0.2042\n",
      "Epoch 31/100\n",
      "1263/1263 - 0s - loss: 0.1407 - r_square: 0.8987 - rmse: 0.1407 - val_loss: 0.2102 - val_r_square: 0.6123 - val_rmse: 0.2102\n",
      "Epoch 32/100\n",
      "1263/1263 - 0s - loss: 0.1384 - r_square: 0.8959 - rmse: 0.1384 - val_loss: 0.2100 - val_r_square: 0.6087 - val_rmse: 0.2100\n",
      "Epoch 33/100\n",
      "1263/1263 - 0s - loss: 0.1398 - r_square: 0.8996 - rmse: 0.1398 - val_loss: 0.2032 - val_r_square: 0.6152 - val_rmse: 0.2032\n",
      "Epoch 34/100\n",
      "1263/1263 - 0s - loss: 0.1391 - r_square: 0.8988 - rmse: 0.1391 - val_loss: 0.1955 - val_r_square: 0.6184 - val_rmse: 0.1955\n",
      "Epoch 35/100\n",
      "1263/1263 - 0s - loss: 0.1372 - r_square: 0.8915 - rmse: 0.1372 - val_loss: 0.2090 - val_r_square: 0.6190 - val_rmse: 0.2090\n",
      "Epoch 36/100\n",
      "1263/1263 - 0s - loss: 0.1358 - r_square: 0.8986 - rmse: 0.1358 - val_loss: 0.1939 - val_r_square: 0.6171 - val_rmse: 0.1939\n",
      "Epoch 37/100\n",
      "1263/1263 - 0s - loss: 0.1346 - r_square: 0.8946 - rmse: 0.1346 - val_loss: 0.2101 - val_r_square: 0.6090 - val_rmse: 0.2101\n",
      "Epoch 38/100\n",
      "1263/1263 - 0s - loss: 0.1367 - r_square: 0.8926 - rmse: 0.1367 - val_loss: 0.1974 - val_r_square: 0.6192 - val_rmse: 0.1974\n",
      "Epoch 39/100\n",
      "1263/1263 - 0s - loss: 0.1484 - r_square: 0.8900 - rmse: 0.1484 - val_loss: 0.2101 - val_r_square: 0.6126 - val_rmse: 0.2101\n",
      "Epoch 40/100\n",
      "1263/1263 - 0s - loss: 0.1355 - r_square: 0.8974 - rmse: 0.1355 - val_loss: 0.2018 - val_r_square: 0.6111 - val_rmse: 0.2018\n",
      "Epoch 41/100\n",
      "1263/1263 - 0s - loss: 0.1383 - r_square: 0.8889 - rmse: 0.1383 - val_loss: 0.2246 - val_r_square: 0.5946 - val_rmse: 0.2246\n",
      "Epoch 42/100\n",
      "1263/1263 - 0s - loss: 0.1357 - r_square: 0.9007 - rmse: 0.1357 - val_loss: 0.2050 - val_r_square: 0.5998 - val_rmse: 0.2050\n",
      "Epoch 43/100\n",
      "1263/1263 - 0s - loss: 0.1317 - r_square: 0.8878 - rmse: 0.1317 - val_loss: 0.2043 - val_r_square: 0.6242 - val_rmse: 0.2043\n",
      "Epoch 44/100\n",
      "1263/1263 - 0s - loss: 0.1362 - r_square: 0.8929 - rmse: 0.1362 - val_loss: 0.2236 - val_r_square: 0.6186 - val_rmse: 0.2236\n",
      "Epoch 45/100\n",
      "1263/1263 - 0s - loss: 0.1399 - r_square: 0.8923 - rmse: 0.1399 - val_loss: 0.2003 - val_r_square: 0.6243 - val_rmse: 0.2003\n",
      "Epoch 46/100\n",
      "1263/1263 - 0s - loss: 0.1338 - r_square: 0.8969 - rmse: 0.1338 - val_loss: 0.2013 - val_r_square: 0.6115 - val_rmse: 0.2013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f71307a88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping tuning #1\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10,verbose=0, mode='min')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486/1486 [==============================] - 0s 23us/sample - loss: 0.1392 - r_square: 0.8588 - rmse: 0.1392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13924634083604107, 0.8587698, 0.13924634]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation 1\n",
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 223 samples\n",
      "Epoch 1/100\n",
      "1263/1263 - 0s - loss: 0.1278 - r_square: 0.9103 - rmse: 0.1278 - val_loss: 0.2117 - val_r_square: 0.5930 - val_rmse: 0.2117\n",
      "Epoch 2/100\n",
      "1263/1263 - 0s - loss: 0.1323 - r_square: 0.8924 - rmse: 0.1323 - val_loss: 0.2033 - val_r_square: 0.6025 - val_rmse: 0.2033\n",
      "Epoch 3/100\n",
      "1263/1263 - 0s - loss: 0.1407 - r_square: 0.8941 - rmse: 0.1407 - val_loss: 0.2066 - val_r_square: 0.6223 - val_rmse: 0.2066\n",
      "Epoch 4/100\n",
      "1263/1263 - 0s - loss: 0.1307 - r_square: 0.9037 - rmse: 0.1307 - val_loss: 0.2160 - val_r_square: 0.6026 - val_rmse: 0.2160\n",
      "Epoch 5/100\n",
      "1263/1263 - 0s - loss: 0.1304 - r_square: 0.9043 - rmse: 0.1304 - val_loss: 0.2032 - val_r_square: 0.6007 - val_rmse: 0.2032\n",
      "Epoch 6/100\n",
      "1263/1263 - 0s - loss: 0.1326 - r_square: 0.9030 - rmse: 0.1326 - val_loss: 0.1926 - val_r_square: 0.6250 - val_rmse: 0.1926\n",
      "Epoch 7/100\n",
      "1263/1263 - 0s - loss: 0.1276 - r_square: 0.8989 - rmse: 0.1276 - val_loss: 0.1983 - val_r_square: 0.6194 - val_rmse: 0.1983\n",
      "Epoch 8/100\n",
      "1263/1263 - 0s - loss: 0.1269 - r_square: 0.9055 - rmse: 0.1269 - val_loss: 0.1947 - val_r_square: 0.6207 - val_rmse: 0.1947\n",
      "Epoch 9/100\n",
      "1263/1263 - 0s - loss: 0.1252 - r_square: 0.9008 - rmse: 0.1252 - val_loss: 0.1947 - val_r_square: 0.6228 - val_rmse: 0.1947\n",
      "Epoch 10/100\n",
      "1263/1263 - 0s - loss: 0.1268 - r_square: 0.8999 - rmse: 0.1268 - val_loss: 0.1939 - val_r_square: 0.6245 - val_rmse: 0.1939\n",
      "Epoch 11/100\n",
      "1263/1263 - 0s - loss: 0.1234 - r_square: 0.9055 - rmse: 0.1234 - val_loss: 0.1900 - val_r_square: 0.6212 - val_rmse: 0.1900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15f728a83c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#early stopping tuning #2\n",
    "from keras.callbacks import EarlyStopping\n",
    "es= EarlyStopping(monitor='val_r_square', min_delta=0.000001, patience=5,verbose=0, mode='max')\n",
    "model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_scaled,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    validation_split= .15,\n",
    "    callbacks= [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1486/1486 [==============================] - 0s 19us/sample - loss: 0.1285 - r_square: 0.8653 - rmse: 0.1285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1285217369268592, 0.86528975, 0.12852173]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation 2\n",
    "model.evaluate(X_test_scaled, y_test_scaled, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperas Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# # Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "# # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to scale data for create model function\n",
    "def data():\n",
    "    #read in data for analysis \n",
    "    all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
    "    X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
    "    y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
    "    #split into test and train data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # # Create a StandardScater model and fit it to the training data\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    y_scaler = StandardScaler().fit(y_train)\n",
    "    # # Transform the training and testing data using the X_scaler and y_scaler models\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    y_train_scaled = y_scaler.transform(y_train)\n",
    "    y_test_scaled = y_scaler.transform(y_test)\n",
    "    \n",
    "    x_train = X_train_scaled.reshape(-1,6)\n",
    "    x_test = X_test_scaled.reshape(-1,6)\n",
    "    y_train = y_train_scaled.reshape(-1,1)\n",
    "    y_test = y_test_scaled.reshape(-1,1)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "# root mean squared error (rmse) for regression (only for Keras tensors)\n",
    "def rmse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "def mse(y_true, y_pred):\n",
    "    from keras import backend\n",
    "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "# coefficient of determination (R^2) for regression  (only for Keras tensors)\n",
    "def r_square(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import losses\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import print_summary\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error, r2_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0,.30),\n",
      "        'Dense': hp.choice('Dense', [50,100,200,300,400]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0,.30),\n",
      "        'batch_size': hp.choice('batch_size', [64,128]),\n",
      "        'epochs': hp.choice('epochs', [50,100,150]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: #read in data for analysis \n",
      "   3: all_wells = pd.read_csv('Cleaned_Data/well_cleaned.csv')\n",
      "   4: X1= all_wells[[\"AVG_CHOKE_SIZE_P\",\"AVG_WHP_P\",\"AVG_WHT_P\",\"BORE_OIL_VOL\",\"BORE_GAS_VOL\", \"BORE_WAT_VOL\"]]\n",
      "   5: y1= all_wells[\"AVG_DOWNHOLE_PRESSURE\"].values.reshape(-1, 1)\n",
      "   6: #split into test and train data\n",
      "   7: from sklearn.model_selection import train_test_split\n",
      "   8: X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=42)\n",
      "   9: from sklearn.preprocessing import StandardScaler\n",
      "  10: # # Create a StandardScater model and fit it to the training data\n",
      "  11: X_scaler = StandardScaler().fit(X_train)\n",
      "  12: y_scaler = StandardScaler().fit(y_train)\n",
      "  13: # # Transform the training and testing data using the X_scaler and y_scaler models\n",
      "  14: X_train_scaled = X_scaler.transform(X_train)\n",
      "  15: X_test_scaled = X_scaler.transform(X_test)\n",
      "  16: y_train_scaled = y_scaler.transform(y_train)\n",
      "  17: y_test_scaled = y_scaler.transform(y_test)\n",
      "  18: \n",
      "  19: x_train = X_train_scaled.reshape(-1,6)\n",
      "  20: x_test = X_test_scaled.reshape(-1,6)\n",
      "  21: y_train = y_train_scaled.reshape(-1,1)\n",
      "  22: y_test = y_test_scaled.reshape(-1,1)\n",
      "  23: \n",
      "  24: \n",
      "  25: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     print(x_train.shape)\n",
      "   4:     model= Sequential() \n",
      "   5:     model.add(Dense(100, input_dim=x_train.shape[1], activation= 'relu'))\n",
      "   6:     model.add(Dropout(space['Dropout']))\n",
      "   7:     model.add(Dense(space['Dense'],activation= 'relu'))\n",
      "   8:     #model.add(Activation('relu'))\n",
      "   9:     model.add(Dropout(space['Dropout_1']))\n",
      "  10:     model.add(Dense(1, activation= 'linear'))\n",
      "  11: \n",
      "  12:     \n",
      "  13: ################################################\n",
      "  14: # CREDIT: https://github.com/keras-team/keras/issues/7947\n",
      "  15:     def rmse(y_true, y_pred):\n",
      "  16:         return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
      "  17: # mean squared error (mse) for regression  (only for Keras tensors)\n",
      "  18:     def mse(y_true, y_pred):\n",
      "  19:         return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
      "  20:     def r_square(y_true, y_pred):\n",
      "  21:         SS_res =  K.sum(K.square(y_true - y_pred)) \n",
      "  22:         SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
      "  23:         return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
      "  24: #############################################\n",
      "  25: \n",
      "  26:     model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
      "  27:     print_summary(model, line_length=None, positions=None, print_fn=None)\n",
      "  28:     result= model.fit(x_train, y_train,\n",
      "  29:                       batch_size=space['batch_size'],\n",
      "  30:                       epochs=space['epochs'],\n",
      "  31:                       verbose=2,\n",
      "  32:                       validation_split =0.15)\n",
      "  33:     validation_acc= np.min(result.history['val_loss'])\n",
      "  34:     print('Lowest Validation Loss:', validation_acc)\n",
      "  35:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
      "  36: \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_1\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_1 (Dense)              (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_1 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_2 (Dense)              (None, 100)               10100                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_2 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_3 (Dense)              (None, 1)                 101                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 10,901                                                                                                   \n",
      "Trainable params: 10,901                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/150                                                                                                            \n",
      " - 0s - loss: 0.6114 - r_square: 0.3086 - rmse: 0.6114 - val_loss: 0.4411 - val_r_square: 0.6294 - val_rmse: 0.4411    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150                                                                                                            \n",
      " - 0s - loss: 0.4509 - r_square: 0.5785 - rmse: 0.4509 - val_loss: 0.3311 - val_r_square: 0.7548 - val_rmse: 0.3311    \n",
      "\n",
      "Epoch 3/150                                                                                                            \n",
      " - 0s - loss: 0.3750 - r_square: 0.6757 - rmse: 0.3750 - val_loss: 0.2691 - val_r_square: 0.8004 - val_rmse: 0.2691    \n",
      "\n",
      "Epoch 4/150                                                                                                            \n",
      " - 0s - loss: 0.3420 - r_square: 0.7082 - rmse: 0.3420 - val_loss: 0.2470 - val_r_square: 0.8147 - val_rmse: 0.2470    \n",
      "\n",
      "Epoch 5/150                                                                                                            \n",
      " - 0s - loss: 0.3224 - r_square: 0.7358 - rmse: 0.3224 - val_loss: 0.2397 - val_r_square: 0.8218 - val_rmse: 0.2397    \n",
      "\n",
      "Epoch 6/150                                                                                                            \n",
      " - 0s - loss: 0.3086 - r_square: 0.7492 - rmse: 0.3086 - val_loss: 0.2272 - val_r_square: 0.8283 - val_rmse: 0.2272    \n",
      "\n",
      "Epoch 7/150                                                                                                            \n",
      " - 0s - loss: 0.3030 - r_square: 0.7506 - rmse: 0.3030 - val_loss: 0.2297 - val_r_square: 0.8261 - val_rmse: 0.2297    \n",
      "\n",
      "Epoch 8/150                                                                                                            \n",
      " - 0s - loss: 0.2917 - r_square: 0.7662 - rmse: 0.2917 - val_loss: 0.2218 - val_r_square: 0.8265 - val_rmse: 0.2218    \n",
      "\n",
      "Epoch 9/150                                                                                                            \n",
      " - 0s - loss: 0.2814 - r_square: 0.7801 - rmse: 0.2814 - val_loss: 0.2219 - val_r_square: 0.8419 - val_rmse: 0.2219    \n",
      "\n",
      "Epoch 10/150                                                                                                           \n",
      " - 0s - loss: 0.2729 - r_square: 0.7775 - rmse: 0.2729 - val_loss: 0.2073 - val_r_square: 0.8468 - val_rmse: 0.2073    \n",
      "\n",
      "Epoch 11/150                                                                                                           \n",
      " - 0s - loss: 0.2699 - r_square: 0.7776 - rmse: 0.2699 - val_loss: 0.2120 - val_r_square: 0.8491 - val_rmse: 0.2120    \n",
      "\n",
      "Epoch 12/150                                                                                                           \n",
      " - 0s - loss: 0.2663 - r_square: 0.7847 - rmse: 0.2663 - val_loss: 0.2047 - val_r_square: 0.8459 - val_rmse: 0.2047    \n",
      "\n",
      "Epoch 13/150                                                                                                           \n",
      " - 0s - loss: 0.2576 - r_square: 0.7990 - rmse: 0.2576 - val_loss: 0.2124 - val_r_square: 0.8533 - val_rmse: 0.2124    \n",
      "\n",
      "Epoch 14/150                                                                                                           \n",
      " - 0s - loss: 0.2549 - r_square: 0.7977 - rmse: 0.2549 - val_loss: 0.1971 - val_r_square: 0.8526 - val_rmse: 0.1971    \n",
      "\n",
      "Epoch 15/150                                                                                                           \n",
      " - 0s - loss: 0.2509 - r_square: 0.8075 - rmse: 0.2509 - val_loss: 0.1949 - val_r_square: 0.8579 - val_rmse: 0.1949    \n",
      "\n",
      "Epoch 16/150                                                                                                           \n",
      " - 0s - loss: 0.2485 - r_square: 0.8100 - rmse: 0.2485 - val_loss: 0.2037 - val_r_square: 0.8594 - val_rmse: 0.2037    \n",
      "\n",
      "Epoch 17/150                                                                                                           \n",
      " - 0s - loss: 0.2463 - r_square: 0.7972 - rmse: 0.2463 - val_loss: 0.1908 - val_r_square: 0.8608 - val_rmse: 0.1908    \n",
      "\n",
      "Epoch 18/150                                                                                                           \n",
      " - 0s - loss: 0.2446 - r_square: 0.8059 - rmse: 0.2446 - val_loss: 0.1947 - val_r_square: 0.8623 - val_rmse: 0.1947    \n",
      "\n",
      "Epoch 19/150                                                                                                           \n",
      " - 0s - loss: 0.2415 - r_square: 0.8125 - rmse: 0.2415 - val_loss: 0.1995 - val_r_square: 0.8627 - val_rmse: 0.1995    \n",
      "\n",
      "Epoch 20/150                                                                                                           \n",
      " - 0s - loss: 0.2367 - r_square: 0.8139 - rmse: 0.2367 - val_loss: 0.1806 - val_r_square: 0.8664 - val_rmse: 0.1806    \n",
      "\n",
      "Epoch 21/150                                                                                                           \n",
      " - 0s - loss: 0.2298 - r_square: 0.8216 - rmse: 0.2298 - val_loss: 0.1827 - val_r_square: 0.8658 - val_rmse: 0.1827    \n",
      "\n",
      "Epoch 22/150                                                                                                           \n",
      " - 0s - loss: 0.2312 - r_square: 0.8146 - rmse: 0.2312 - val_loss: 0.1803 - val_r_square: 0.8655 - val_rmse: 0.1803    \n",
      "\n",
      "Epoch 23/150                                                                                                           \n",
      " - 0s - loss: 0.2357 - r_square: 0.8214 - rmse: 0.2357 - val_loss: 0.1846 - val_r_square: 0.8681 - val_rmse: 0.1846    \n",
      "\n",
      "Epoch 24/150                                                                                                           \n",
      " - 0s - loss: 0.2299 - r_square: 0.8134 - rmse: 0.2299 - val_loss: 0.1855 - val_r_square: 0.8736 - val_rmse: 0.1855    \n",
      "\n",
      "Epoch 25/150                                                                                                           \n",
      " - 0s - loss: 0.2280 - r_square: 0.8230 - rmse: 0.2280 - val_loss: 0.1755 - val_r_square: 0.8707 - val_rmse: 0.1755    \n",
      "\n",
      "Epoch 26/150                                                                                                           \n",
      " - 0s - loss: 0.2208 - r_square: 0.8259 - rmse: 0.2208 - val_loss: 0.1695 - val_r_square: 0.8748 - val_rmse: 0.1695    \n",
      "\n",
      "Epoch 27/150                                                                                                           \n",
      " - 0s - loss: 0.2224 - r_square: 0.8190 - rmse: 0.2224 - val_loss: 0.1818 - val_r_square: 0.8772 - val_rmse: 0.1818    \n",
      "\n",
      "Epoch 28/150                                                                                                           \n",
      " - 0s - loss: 0.2210 - r_square: 0.8265 - rmse: 0.2210 - val_loss: 0.1849 - val_r_square: 0.8736 - val_rmse: 0.1849    \n",
      "\n",
      "Epoch 29/150                                                                                                           \n",
      " - 0s - loss: 0.2232 - r_square: 0.8269 - rmse: 0.2232 - val_loss: 0.1709 - val_r_square: 0.8788 - val_rmse: 0.1709    \n",
      "\n",
      "Epoch 30/150                                                                                                           \n",
      " - 0s - loss: 0.2172 - r_square: 0.8298 - rmse: 0.2172 - val_loss: 0.1739 - val_r_square: 0.8810 - val_rmse: 0.1739    \n",
      "\n",
      "Epoch 31/150                                                                                                           \n",
      " - 0s - loss: 0.2114 - r_square: 0.8423 - rmse: 0.2114 - val_loss: 0.1648 - val_r_square: 0.8811 - val_rmse: 0.1648    \n",
      "\n",
      "Epoch 32/150                                                                                                           \n",
      " - 0s - loss: 0.2155 - r_square: 0.8306 - rmse: 0.2155 - val_loss: 0.1709 - val_r_square: 0.8817 - val_rmse: 0.1709    \n",
      "\n",
      "Epoch 33/150                                                                                                           \n",
      " - 0s - loss: 0.2156 - r_square: 0.8323 - rmse: 0.2156 - val_loss: 0.1724 - val_r_square: 0.8777 - val_rmse: 0.1724    \n",
      "\n",
      "Epoch 34/150                                                                                                           \n",
      " - 0s - loss: 0.2139 - r_square: 0.8325 - rmse: 0.2139 - val_loss: 0.1660 - val_r_square: 0.8831 - val_rmse: 0.1660    \n",
      "\n",
      "Epoch 35/150                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2118 - r_square: 0.8311 - rmse: 0.2118 - val_loss: 0.1740 - val_r_square: 0.8833 - val_rmse: 0.1740    \n",
      "\n",
      "Epoch 36/150                                                                                                           \n",
      " - 0s - loss: 0.2111 - r_square: 0.8330 - rmse: 0.2111 - val_loss: 0.1681 - val_r_square: 0.8873 - val_rmse: 0.1681    \n",
      "\n",
      "Epoch 37/150                                                                                                           \n",
      " - 0s - loss: 0.2111 - r_square: 0.8336 - rmse: 0.2111 - val_loss: 0.1626 - val_r_square: 0.8843 - val_rmse: 0.1626    \n",
      "\n",
      "Epoch 38/150                                                                                                           \n",
      " - 0s - loss: 0.2072 - r_square: 0.8317 - rmse: 0.2072 - val_loss: 0.1656 - val_r_square: 0.8870 - val_rmse: 0.1656    \n",
      "\n",
      "Epoch 39/150                                                                                                           \n",
      " - 0s - loss: 0.2061 - r_square: 0.8408 - rmse: 0.2061 - val_loss: 0.1699 - val_r_square: 0.8869 - val_rmse: 0.1699    \n",
      "\n",
      "Epoch 40/150                                                                                                           \n",
      " - 0s - loss: 0.2068 - r_square: 0.8394 - rmse: 0.2068 - val_loss: 0.1729 - val_r_square: 0.8789 - val_rmse: 0.1729    \n",
      "\n",
      "Epoch 41/150                                                                                                           \n",
      " - 0s - loss: 0.2055 - r_square: 0.8351 - rmse: 0.2055 - val_loss: 0.1665 - val_r_square: 0.8886 - val_rmse: 0.1665    \n",
      "\n",
      "Epoch 42/150                                                                                                           \n",
      " - 0s - loss: 0.2051 - r_square: 0.8413 - rmse: 0.2051 - val_loss: 0.1696 - val_r_square: 0.8853 - val_rmse: 0.1696    \n",
      "\n",
      "Epoch 43/150                                                                                                           \n",
      " - 0s - loss: 0.2050 - r_square: 0.8426 - rmse: 0.2050 - val_loss: 0.1649 - val_r_square: 0.8888 - val_rmse: 0.1649    \n",
      "\n",
      "Epoch 44/150                                                                                                           \n",
      " - 0s - loss: 0.2027 - r_square: 0.8402 - rmse: 0.2027 - val_loss: 0.1575 - val_r_square: 0.8887 - val_rmse: 0.1575    \n",
      "\n",
      "Epoch 45/150                                                                                                           \n",
      " - 0s - loss: 0.2019 - r_square: 0.8398 - rmse: 0.2019 - val_loss: 0.1667 - val_r_square: 0.8854 - val_rmse: 0.1667    \n",
      "\n",
      "Epoch 46/150                                                                                                           \n",
      " - 0s - loss: 0.2041 - r_square: 0.8470 - rmse: 0.2041 - val_loss: 0.1643 - val_r_square: 0.8889 - val_rmse: 0.1643    \n",
      "\n",
      "Epoch 47/150                                                                                                           \n",
      " - 0s - loss: 0.2004 - r_square: 0.8505 - rmse: 0.2004 - val_loss: 0.1672 - val_r_square: 0.8883 - val_rmse: 0.1672    \n",
      "\n",
      "Epoch 48/150                                                                                                           \n",
      " - 0s - loss: 0.1982 - r_square: 0.8347 - rmse: 0.1982 - val_loss: 0.1607 - val_r_square: 0.8888 - val_rmse: 0.1607    \n",
      "\n",
      "Epoch 49/150                                                                                                           \n",
      " - 0s - loss: 0.1992 - r_square: 0.8477 - rmse: 0.1992 - val_loss: 0.1635 - val_r_square: 0.8878 - val_rmse: 0.1635    \n",
      "\n",
      "Epoch 50/150                                                                                                           \n",
      " - 0s - loss: 0.1975 - r_square: 0.8490 - rmse: 0.1975 - val_loss: 0.1601 - val_r_square: 0.8930 - val_rmse: 0.1601    \n",
      "\n",
      "Epoch 51/150                                                                                                           \n",
      " - 0s - loss: 0.1972 - r_square: 0.8445 - rmse: 0.1972 - val_loss: 0.1666 - val_r_square: 0.8913 - val_rmse: 0.1666    \n",
      "\n",
      "Epoch 52/150                                                                                                           \n",
      " - 0s - loss: 0.2018 - r_square: 0.8479 - rmse: 0.2018 - val_loss: 0.1606 - val_r_square: 0.8923 - val_rmse: 0.1606    \n",
      "\n",
      "Epoch 53/150                                                                                                           \n",
      " - 0s - loss: 0.1976 - r_square: 0.8459 - rmse: 0.1976 - val_loss: 0.1620 - val_r_square: 0.8898 - val_rmse: 0.1620    \n",
      "\n",
      "Epoch 54/150                                                                                                           \n",
      " - 0s - loss: 0.1982 - r_square: 0.8510 - rmse: 0.1982 - val_loss: 0.1601 - val_r_square: 0.8908 - val_rmse: 0.1601    \n",
      "\n",
      "Epoch 55/150                                                                                                           \n",
      " - 0s - loss: 0.1952 - r_square: 0.8497 - rmse: 0.1952 - val_loss: 0.1580 - val_r_square: 0.8941 - val_rmse: 0.1580    \n",
      "\n",
      "Epoch 56/150                                                                                                           \n",
      " - 0s - loss: 0.1962 - r_square: 0.8464 - rmse: 0.1962 - val_loss: 0.1612 - val_r_square: 0.8933 - val_rmse: 0.1612    \n",
      "\n",
      "Epoch 57/150                                                                                                           \n",
      " - 0s - loss: 0.1973 - r_square: 0.8456 - rmse: 0.1973 - val_loss: 0.1598 - val_r_square: 0.8945 - val_rmse: 0.1598    \n",
      "\n",
      "Epoch 58/150                                                                                                           \n",
      " - 0s - loss: 0.1928 - r_square: 0.8495 - rmse: 0.1928 - val_loss: 0.1585 - val_r_square: 0.8925 - val_rmse: 0.1585    \n",
      "\n",
      "Epoch 59/150                                                                                                           \n",
      " - 0s - loss: 0.1937 - r_square: 0.8521 - rmse: 0.1937 - val_loss: 0.1582 - val_r_square: 0.8899 - val_rmse: 0.1582    \n",
      "\n",
      "Epoch 60/150                                                                                                           \n",
      " - 0s - loss: 0.1932 - r_square: 0.8551 - rmse: 0.1932 - val_loss: 0.1560 - val_r_square: 0.8946 - val_rmse: 0.1560    \n",
      "\n",
      "Epoch 61/150                                                                                                           \n",
      " - 0s - loss: 0.1953 - r_square: 0.8496 - rmse: 0.1953 - val_loss: 0.1531 - val_r_square: 0.8930 - val_rmse: 0.1531    \n",
      "\n",
      "Epoch 62/150                                                                                                           \n",
      " - 0s - loss: 0.1922 - r_square: 0.8549 - rmse: 0.1922 - val_loss: 0.1512 - val_r_square: 0.8939 - val_rmse: 0.1512    \n",
      "\n",
      "Epoch 63/150                                                                                                           \n",
      " - 0s - loss: 0.1918 - r_square: 0.8521 - rmse: 0.1918 - val_loss: 0.1540 - val_r_square: 0.8947 - val_rmse: 0.1540    \n",
      "\n",
      "Epoch 64/150                                                                                                           \n",
      " - 0s - loss: 0.1946 - r_square: 0.8479 - rmse: 0.1946 - val_loss: 0.1511 - val_r_square: 0.8930 - val_rmse: 0.1511    \n",
      "\n",
      "Epoch 65/150                                                                                                           \n",
      " - 0s - loss: 0.1967 - r_square: 0.8397 - rmse: 0.1967 - val_loss: 0.1575 - val_r_square: 0.8948 - val_rmse: 0.1575    \n",
      "\n",
      "Epoch 66/150                                                                                                           \n",
      " - 0s - loss: 0.1940 - r_square: 0.8515 - rmse: 0.1940 - val_loss: 0.1545 - val_r_square: 0.8953 - val_rmse: 0.1545    \n",
      "\n",
      "Epoch 67/150                                                                                                           \n",
      " - 0s - loss: 0.1932 - r_square: 0.8464 - rmse: 0.1932 - val_loss: 0.1531 - val_r_square: 0.8934 - val_rmse: 0.1531    \n",
      "\n",
      "Epoch 68/150                                                                                                           \n",
      " - 0s - loss: 0.1906 - r_square: 0.8550 - rmse: 0.1906 - val_loss: 0.1534 - val_r_square: 0.8967 - val_rmse: 0.1534    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150                                                                                                           \n",
      " - 0s - loss: 0.1890 - r_square: 0.8534 - rmse: 0.1890 - val_loss: 0.1527 - val_r_square: 0.8966 - val_rmse: 0.1527    \n",
      "\n",
      "Epoch 70/150                                                                                                           \n",
      " - 0s - loss: 0.1913 - r_square: 0.8468 - rmse: 0.1913 - val_loss: 0.1502 - val_r_square: 0.8941 - val_rmse: 0.1502    \n",
      "\n",
      "Epoch 71/150                                                                                                           \n",
      " - 0s - loss: 0.1876 - r_square: 0.8600 - rmse: 0.1876 - val_loss: 0.1510 - val_r_square: 0.8976 - val_rmse: 0.1510    \n",
      "\n",
      "Epoch 72/150                                                                                                           \n",
      " - 0s - loss: 0.1898 - r_square: 0.8443 - rmse: 0.1898 - val_loss: 0.1486 - val_r_square: 0.8962 - val_rmse: 0.1486    \n",
      "\n",
      "Epoch 73/150                                                                                                           \n",
      " - 0s - loss: 0.1879 - r_square: 0.8569 - rmse: 0.1879 - val_loss: 0.1525 - val_r_square: 0.8936 - val_rmse: 0.1525    \n",
      "\n",
      "Epoch 74/150                                                                                                           \n",
      " - 0s - loss: 0.1895 - r_square: 0.8558 - rmse: 0.1895 - val_loss: 0.1596 - val_r_square: 0.8940 - val_rmse: 0.1596    \n",
      "\n",
      "Epoch 75/150                                                                                                           \n",
      " - 0s - loss: 0.1881 - r_square: 0.8493 - rmse: 0.1881 - val_loss: 0.1553 - val_r_square: 0.8953 - val_rmse: 0.1553    \n",
      "\n",
      "Epoch 76/150                                                                                                           \n",
      " - 0s - loss: 0.1889 - r_square: 0.8471 - rmse: 0.1889 - val_loss: 0.1542 - val_r_square: 0.8950 - val_rmse: 0.1542    \n",
      "\n",
      "Epoch 77/150                                                                                                           \n",
      " - 0s - loss: 0.1874 - r_square: 0.8529 - rmse: 0.1874 - val_loss: 0.1510 - val_r_square: 0.8955 - val_rmse: 0.1510    \n",
      "\n",
      "Epoch 78/150                                                                                                           \n",
      " - 0s - loss: 0.1895 - r_square: 0.8502 - rmse: 0.1895 - val_loss: 0.1503 - val_r_square: 0.8986 - val_rmse: 0.1503    \n",
      "\n",
      "Epoch 79/150                                                                                                           \n",
      " - 0s - loss: 0.1841 - r_square: 0.8590 - rmse: 0.1841 - val_loss: 0.1542 - val_r_square: 0.8943 - val_rmse: 0.1542    \n",
      "\n",
      "Epoch 80/150                                                                                                           \n",
      " - 0s - loss: 0.1853 - r_square: 0.8513 - rmse: 0.1853 - val_loss: 0.1519 - val_r_square: 0.8943 - val_rmse: 0.1519    \n",
      "\n",
      "Epoch 81/150                                                                                                           \n",
      " - 0s - loss: 0.1868 - r_square: 0.8485 - rmse: 0.1868 - val_loss: 0.1775 - val_r_square: 0.8920 - val_rmse: 0.1775    \n",
      "\n",
      "Epoch 82/150                                                                                                           \n",
      " - 0s - loss: 0.1882 - r_square: 0.8516 - rmse: 0.1882 - val_loss: 0.1498 - val_r_square: 0.8966 - val_rmse: 0.1498    \n",
      "\n",
      "Epoch 83/150                                                                                                           \n",
      " - 0s - loss: 0.1858 - r_square: 0.8520 - rmse: 0.1858 - val_loss: 0.1503 - val_r_square: 0.8994 - val_rmse: 0.1503    \n",
      "\n",
      "Epoch 84/150                                                                                                           \n",
      " - 0s - loss: 0.1849 - r_square: 0.8628 - rmse: 0.1849 - val_loss: 0.1521 - val_r_square: 0.8942 - val_rmse: 0.1521    \n",
      "\n",
      "Epoch 85/150                                                                                                           \n",
      " - 0s - loss: 0.1860 - r_square: 0.8540 - rmse: 0.1860 - val_loss: 0.1476 - val_r_square: 0.8961 - val_rmse: 0.1476    \n",
      "\n",
      "Epoch 86/150                                                                                                           \n",
      " - 0s - loss: 0.1848 - r_square: 0.8531 - rmse: 0.1848 - val_loss: 0.1439 - val_r_square: 0.8986 - val_rmse: 0.1439    \n",
      "\n",
      "Epoch 87/150                                                                                                           \n",
      " - 0s - loss: 0.1863 - r_square: 0.8536 - rmse: 0.1863 - val_loss: 0.1529 - val_r_square: 0.8970 - val_rmse: 0.1529    \n",
      "\n",
      "Epoch 88/150                                                                                                           \n",
      " - 0s - loss: 0.1825 - r_square: 0.8606 - rmse: 0.1825 - val_loss: 0.1451 - val_r_square: 0.8979 - val_rmse: 0.1451    \n",
      "\n",
      "Epoch 89/150                                                                                                           \n",
      " - 0s - loss: 0.1840 - r_square: 0.8583 - rmse: 0.1840 - val_loss: 0.1538 - val_r_square: 0.8979 - val_rmse: 0.1538    \n",
      "\n",
      "Epoch 90/150                                                                                                           \n",
      " - 0s - loss: 0.1836 - r_square: 0.8536 - rmse: 0.1836 - val_loss: 0.1465 - val_r_square: 0.8986 - val_rmse: 0.1465    \n",
      "\n",
      "Epoch 91/150                                                                                                           \n",
      " - 0s - loss: 0.1823 - r_square: 0.8593 - rmse: 0.1823 - val_loss: 0.1435 - val_r_square: 0.9002 - val_rmse: 0.1435    \n",
      "\n",
      "Epoch 92/150                                                                                                           \n",
      " - 0s - loss: 0.1815 - r_square: 0.8560 - rmse: 0.1815 - val_loss: 0.1478 - val_r_square: 0.8975 - val_rmse: 0.1478    \n",
      "\n",
      "Epoch 93/150                                                                                                           \n",
      " - 0s - loss: 0.1848 - r_square: 0.8511 - rmse: 0.1848 - val_loss: 0.1481 - val_r_square: 0.8969 - val_rmse: 0.1481    \n",
      "\n",
      "Epoch 94/150                                                                                                           \n",
      " - 0s - loss: 0.1825 - r_square: 0.8580 - rmse: 0.1825 - val_loss: 0.1500 - val_r_square: 0.9002 - val_rmse: 0.1500    \n",
      "\n",
      "Epoch 95/150                                                                                                           \n",
      " - 0s - loss: 0.1837 - r_square: 0.8584 - rmse: 0.1837 - val_loss: 0.1528 - val_r_square: 0.8972 - val_rmse: 0.1528    \n",
      "\n",
      "Epoch 96/150                                                                                                           \n",
      " - 0s - loss: 0.1828 - r_square: 0.8631 - rmse: 0.1828 - val_loss: 0.1488 - val_r_square: 0.8985 - val_rmse: 0.1488    \n",
      "\n",
      "Epoch 97/150                                                                                                           \n",
      " - 0s - loss: 0.1824 - r_square: 0.8577 - rmse: 0.1824 - val_loss: 0.1551 - val_r_square: 0.8919 - val_rmse: 0.1551    \n",
      "\n",
      "Epoch 98/150                                                                                                           \n",
      " - 0s - loss: 0.1842 - r_square: 0.8546 - rmse: 0.1842 - val_loss: 0.1544 - val_r_square: 0.8961 - val_rmse: 0.1544    \n",
      "\n",
      "Epoch 99/150                                                                                                           \n",
      " - 0s - loss: 0.1841 - r_square: 0.8583 - rmse: 0.1841 - val_loss: 0.1498 - val_r_square: 0.8991 - val_rmse: 0.1498    \n",
      "\n",
      "Epoch 100/150                                                                                                          \n",
      " - 0s - loss: 0.1808 - r_square: 0.8594 - rmse: 0.1808 - val_loss: 0.1478 - val_r_square: 0.8979 - val_rmse: 0.1478    \n",
      "\n",
      "Epoch 101/150                                                                                                          \n",
      " - 0s - loss: 0.1797 - r_square: 0.8583 - rmse: 0.1797 - val_loss: 0.1430 - val_r_square: 0.9010 - val_rmse: 0.1430    \n",
      "\n",
      "Epoch 102/150                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1816 - r_square: 0.8632 - rmse: 0.1816 - val_loss: 0.1527 - val_r_square: 0.8996 - val_rmse: 0.1527    \n",
      "\n",
      "Epoch 103/150                                                                                                          \n",
      " - 0s - loss: 0.1839 - r_square: 0.8601 - rmse: 0.1839 - val_loss: 0.1442 - val_r_square: 0.8993 - val_rmse: 0.1442    \n",
      "\n",
      "Epoch 104/150                                                                                                          \n",
      " - 0s - loss: 0.1809 - r_square: 0.8602 - rmse: 0.1809 - val_loss: 0.1531 - val_r_square: 0.8975 - val_rmse: 0.1531    \n",
      "\n",
      "Epoch 105/150                                                                                                          \n",
      " - 0s - loss: 0.1801 - r_square: 0.8671 - rmse: 0.1801 - val_loss: 0.1479 - val_r_square: 0.9018 - val_rmse: 0.1479    \n",
      "\n",
      "Epoch 106/150                                                                                                          \n",
      " - 0s - loss: 0.1815 - r_square: 0.8594 - rmse: 0.1815 - val_loss: 0.1360 - val_r_square: 0.9021 - val_rmse: 0.1360    \n",
      "\n",
      "Epoch 107/150                                                                                                          \n",
      " - 0s - loss: 0.1821 - r_square: 0.8562 - rmse: 0.1821 - val_loss: 0.1442 - val_r_square: 0.9008 - val_rmse: 0.1442    \n",
      "\n",
      "Epoch 108/150                                                                                                          \n",
      " - 0s - loss: 0.1773 - r_square: 0.8585 - rmse: 0.1773 - val_loss: 0.1489 - val_r_square: 0.8979 - val_rmse: 0.1489    \n",
      "\n",
      "Epoch 109/150                                                                                                          \n",
      " - 0s - loss: 0.1780 - r_square: 0.8567 - rmse: 0.1780 - val_loss: 0.1396 - val_r_square: 0.9030 - val_rmse: 0.1396    \n",
      "\n",
      "Epoch 110/150                                                                                                          \n",
      " - 0s - loss: 0.1761 - r_square: 0.8611 - rmse: 0.1761 - val_loss: 0.1414 - val_r_square: 0.9033 - val_rmse: 0.1414    \n",
      "\n",
      "Epoch 111/150                                                                                                          \n",
      " - 0s - loss: 0.1759 - r_square: 0.8604 - rmse: 0.1759 - val_loss: 0.1439 - val_r_square: 0.9004 - val_rmse: 0.1439    \n",
      "\n",
      "Epoch 112/150                                                                                                          \n",
      " - 0s - loss: 0.1810 - r_square: 0.8553 - rmse: 0.1810 - val_loss: 0.1446 - val_r_square: 0.9009 - val_rmse: 0.1446    \n",
      "\n",
      "Epoch 113/150                                                                                                          \n",
      " - 0s - loss: 0.1811 - r_square: 0.8633 - rmse: 0.1811 - val_loss: 0.1405 - val_r_square: 0.9046 - val_rmse: 0.1405    \n",
      "\n",
      "Epoch 114/150                                                                                                          \n",
      " - 0s - loss: 0.1742 - r_square: 0.8667 - rmse: 0.1742 - val_loss: 0.1460 - val_r_square: 0.9017 - val_rmse: 0.1460    \n",
      "\n",
      "Epoch 115/150                                                                                                          \n",
      " - 0s - loss: 0.1774 - r_square: 0.8604 - rmse: 0.1774 - val_loss: 0.1522 - val_r_square: 0.9015 - val_rmse: 0.1522    \n",
      "\n",
      "Epoch 116/150                                                                                                          \n",
      " - 0s - loss: 0.1785 - r_square: 0.8615 - rmse: 0.1785 - val_loss: 0.1384 - val_r_square: 0.9036 - val_rmse: 0.1384    \n",
      "\n",
      "Epoch 117/150                                                                                                          \n",
      " - 0s - loss: 0.1756 - r_square: 0.8615 - rmse: 0.1756 - val_loss: 0.1465 - val_r_square: 0.9043 - val_rmse: 0.1465    \n",
      "\n",
      "Epoch 118/150                                                                                                          \n",
      " - 0s - loss: 0.1762 - r_square: 0.8618 - rmse: 0.1762 - val_loss: 0.1577 - val_r_square: 0.8978 - val_rmse: 0.1577    \n",
      "\n",
      "Epoch 119/150                                                                                                          \n",
      " - 0s - loss: 0.1780 - r_square: 0.8612 - rmse: 0.1780 - val_loss: 0.1551 - val_r_square: 0.8975 - val_rmse: 0.1551    \n",
      "\n",
      "Epoch 120/150                                                                                                          \n",
      " - 0s - loss: 0.1766 - r_square: 0.8623 - rmse: 0.1766 - val_loss: 0.1581 - val_r_square: 0.9013 - val_rmse: 0.1581    \n",
      "\n",
      "Epoch 121/150                                                                                                          \n",
      " - 0s - loss: 0.1790 - r_square: 0.8561 - rmse: 0.1790 - val_loss: 0.1421 - val_r_square: 0.9016 - val_rmse: 0.1421    \n",
      "\n",
      "Epoch 122/150                                                                                                          \n",
      " - 0s - loss: 0.1762 - r_square: 0.8663 - rmse: 0.1762 - val_loss: 0.1443 - val_r_square: 0.9037 - val_rmse: 0.1443    \n",
      "\n",
      "Epoch 123/150                                                                                                          \n",
      " - 0s - loss: 0.1768 - r_square: 0.8627 - rmse: 0.1768 - val_loss: 0.1429 - val_r_square: 0.9047 - val_rmse: 0.1429    \n",
      "\n",
      "Epoch 124/150                                                                                                          \n",
      " - 0s - loss: 0.1769 - r_square: 0.8633 - rmse: 0.1769 - val_loss: 0.1405 - val_r_square: 0.9037 - val_rmse: 0.1405    \n",
      "\n",
      "Epoch 125/150                                                                                                          \n",
      " - 0s - loss: 0.1755 - r_square: 0.8613 - rmse: 0.1755 - val_loss: 0.1379 - val_r_square: 0.9064 - val_rmse: 0.1379    \n",
      "\n",
      "Epoch 126/150                                                                                                          \n",
      " - 0s - loss: 0.1713 - r_square: 0.8690 - rmse: 0.1713 - val_loss: 0.1420 - val_r_square: 0.9065 - val_rmse: 0.1420    \n",
      "\n",
      "Epoch 127/150                                                                                                          \n",
      " - 0s - loss: 0.1743 - r_square: 0.8550 - rmse: 0.1743 - val_loss: 0.1447 - val_r_square: 0.9025 - val_rmse: 0.1447    \n",
      "\n",
      "Epoch 128/150                                                                                                          \n",
      " - 0s - loss: 0.1760 - r_square: 0.8594 - rmse: 0.1760 - val_loss: 0.1355 - val_r_square: 0.9052 - val_rmse: 0.1355    \n",
      "\n",
      "Epoch 129/150                                                                                                          \n",
      " - 0s - loss: 0.1787 - r_square: 0.8574 - rmse: 0.1787 - val_loss: 0.1415 - val_r_square: 0.9037 - val_rmse: 0.1415    \n",
      "\n",
      "Epoch 130/150                                                                                                          \n",
      " - 0s - loss: 0.1763 - r_square: 0.8634 - rmse: 0.1763 - val_loss: 0.1365 - val_r_square: 0.9067 - val_rmse: 0.1365    \n",
      "\n",
      "Epoch 131/150                                                                                                          \n",
      " - 0s - loss: 0.1727 - r_square: 0.8649 - rmse: 0.1727 - val_loss: 0.1414 - val_r_square: 0.9053 - val_rmse: 0.1414    \n",
      "\n",
      "Epoch 132/150                                                                                                          \n",
      " - 0s - loss: 0.1760 - r_square: 0.8641 - rmse: 0.1760 - val_loss: 0.1502 - val_r_square: 0.9026 - val_rmse: 0.1502    \n",
      "\n",
      "Epoch 133/150                                                                                                          \n",
      " - 0s - loss: 0.1769 - r_square: 0.8666 - rmse: 0.1769 - val_loss: 0.1439 - val_r_square: 0.9061 - val_rmse: 0.1439    \n",
      "\n",
      "Epoch 134/150                                                                                                          \n",
      " - 0s - loss: 0.1753 - r_square: 0.8593 - rmse: 0.1753 - val_loss: 0.1492 - val_r_square: 0.9060 - val_rmse: 0.1492    \n",
      "\n",
      "Epoch 135/150                                                                                                          \n",
      " - 0s - loss: 0.1744 - r_square: 0.8648 - rmse: 0.1744 - val_loss: 0.1455 - val_r_square: 0.9032 - val_rmse: 0.1455    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150                                                                                                          \n",
      " - 0s - loss: 0.1711 - r_square: 0.8663 - rmse: 0.1711 - val_loss: 0.1467 - val_r_square: 0.9071 - val_rmse: 0.1467    \n",
      "\n",
      "Epoch 137/150                                                                                                          \n",
      " - 0s - loss: 0.1759 - r_square: 0.8653 - rmse: 0.1759 - val_loss: 0.1563 - val_r_square: 0.9000 - val_rmse: 0.1563    \n",
      "\n",
      "Epoch 138/150                                                                                                          \n",
      " - 0s - loss: 0.1715 - r_square: 0.8769 - rmse: 0.1715 - val_loss: 0.1511 - val_r_square: 0.9046 - val_rmse: 0.1511    \n",
      "\n",
      "Epoch 139/150                                                                                                          \n",
      " - 0s - loss: 0.1726 - r_square: 0.8662 - rmse: 0.1726 - val_loss: 0.1360 - val_r_square: 0.9066 - val_rmse: 0.1360    \n",
      "\n",
      "Epoch 140/150                                                                                                          \n",
      " - 0s - loss: 0.1706 - r_square: 0.8715 - rmse: 0.1706 - val_loss: 0.1375 - val_r_square: 0.9047 - val_rmse: 0.1375    \n",
      "\n",
      "Epoch 141/150                                                                                                          \n",
      " - 0s - loss: 0.1698 - r_square: 0.8654 - rmse: 0.1698 - val_loss: 0.1327 - val_r_square: 0.9072 - val_rmse: 0.1327    \n",
      "\n",
      "Epoch 142/150                                                                                                          \n",
      " - 0s - loss: 0.1708 - r_square: 0.8653 - rmse: 0.1708 - val_loss: 0.1380 - val_r_square: 0.9067 - val_rmse: 0.1380    \n",
      "\n",
      "Epoch 143/150                                                                                                          \n",
      " - 0s - loss: 0.1754 - r_square: 0.8592 - rmse: 0.1754 - val_loss: 0.1402 - val_r_square: 0.9074 - val_rmse: 0.1402    \n",
      "\n",
      "Epoch 144/150                                                                                                          \n",
      " - 0s - loss: 0.1713 - r_square: 0.8654 - rmse: 0.1713 - val_loss: 0.1387 - val_r_square: 0.9067 - val_rmse: 0.1387    \n",
      "\n",
      "Epoch 145/150                                                                                                          \n",
      " - 0s - loss: 0.1732 - r_square: 0.8724 - rmse: 0.1732 - val_loss: 0.1322 - val_r_square: 0.9069 - val_rmse: 0.1322    \n",
      "\n",
      "Epoch 146/150                                                                                                          \n",
      " - 0s - loss: 0.1720 - r_square: 0.8651 - rmse: 0.1720 - val_loss: 0.1429 - val_r_square: 0.9090 - val_rmse: 0.1429    \n",
      "\n",
      "Epoch 147/150                                                                                                          \n",
      " - 0s - loss: 0.1709 - r_square: 0.8646 - rmse: 0.1709 - val_loss: 0.1430 - val_r_square: 0.9048 - val_rmse: 0.1430    \n",
      "\n",
      "Epoch 148/150                                                                                                          \n",
      " - 0s - loss: 0.1713 - r_square: 0.8721 - rmse: 0.1713 - val_loss: 0.1348 - val_r_square: 0.9060 - val_rmse: 0.1348    \n",
      "\n",
      "Epoch 149/150                                                                                                          \n",
      " - 0s - loss: 0.1762 - r_square: 0.8637 - rmse: 0.1762 - val_loss: 0.1392 - val_r_square: 0.9056 - val_rmse: 0.1392    \n",
      "\n",
      "Epoch 150/150                                                                                                          \n",
      " - 0s - loss: 0.1685 - r_square: 0.8653 - rmse: 0.1685 - val_loss: 0.1426 - val_r_square: 0.9074 - val_rmse: 0.1426    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.13220975767425713                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_2\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_4 (Dense)              (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_3 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_5 (Dense)              (None, 200)               20200                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_4 (Dropout)          (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_6 (Dense)              (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 21,101                                                                                                   \n",
      "Trainable params: 21,101                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 0s - loss: 0.4971 - r_square: 0.5188 - rmse: 0.4971 - val_loss: 0.3048 - val_r_square: 0.7593 - val_rmse: 0.3048    \n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.3562 - r_square: 0.7070 - rmse: 0.3562 - val_loss: 0.2797 - val_r_square: 0.7841 - val_rmse: 0.2797    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.3250 - r_square: 0.7451 - rmse: 0.3250 - val_loss: 0.2638 - val_r_square: 0.8096 - val_rmse: 0.2638    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.3076 - r_square: 0.7578 - rmse: 0.3076 - val_loss: 0.2289 - val_r_square: 0.8148 - val_rmse: 0.2289    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.2878 - r_square: 0.7614 - rmse: 0.2878 - val_loss: 0.2077 - val_r_square: 0.8285 - val_rmse: 0.2077    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.2781 - r_square: 0.7900 - rmse: 0.2781 - val_loss: 0.2227 - val_r_square: 0.8286 - val_rmse: 0.2227    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.2714 - r_square: 0.7846 - rmse: 0.2714 - val_loss: 0.2081 - val_r_square: 0.8243 - val_rmse: 0.2081    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.2646 - r_square: 0.7956 - rmse: 0.2646 - val_loss: 0.2158 - val_r_square: 0.8349 - val_rmse: 0.2158    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.2574 - r_square: 0.7964 - rmse: 0.2574 - val_loss: 0.2036 - val_r_square: 0.8497 - val_rmse: 0.2036    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.2558 - r_square: 0.8087 - rmse: 0.2558 - val_loss: 0.2010 - val_r_square: 0.8523 - val_rmse: 0.2010    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.2447 - r_square: 0.8136 - rmse: 0.2447 - val_loss: 0.2036 - val_r_square: 0.8551 - val_rmse: 0.2036    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.2465 - r_square: 0.8102 - rmse: 0.2465 - val_loss: 0.2024 - val_r_square: 0.8531 - val_rmse: 0.2024    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.2375 - r_square: 0.8213 - rmse: 0.2375 - val_loss: 0.1991 - val_r_square: 0.8622 - val_rmse: 0.1991    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.2330 - r_square: 0.8252 - rmse: 0.2330 - val_loss: 0.2078 - val_r_square: 0.8606 - val_rmse: 0.2078    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.2300 - r_square: 0.8260 - rmse: 0.2300 - val_loss: 0.1984 - val_r_square: 0.8644 - val_rmse: 0.1984    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.2317 - r_square: 0.8258 - rmse: 0.2317 - val_loss: 0.1930 - val_r_square: 0.8573 - val_rmse: 0.1930    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.2235 - r_square: 0.8282 - rmse: 0.2235 - val_loss: 0.1869 - val_r_square: 0.8761 - val_rmse: 0.1869    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.2259 - r_square: 0.8272 - rmse: 0.2259 - val_loss: 0.1900 - val_r_square: 0.8757 - val_rmse: 0.1900    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.2176 - r_square: 0.8314 - rmse: 0.2176 - val_loss: 0.1899 - val_r_square: 0.8757 - val_rmse: 0.1899    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.2127 - r_square: 0.8416 - rmse: 0.2127 - val_loss: 0.1851 - val_r_square: 0.8775 - val_rmse: 0.1851    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.2152 - r_square: 0.8419 - rmse: 0.2152 - val_loss: 0.1813 - val_r_square: 0.8772 - val_rmse: 0.1813    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.2124 - r_square: 0.8429 - rmse: 0.2124 - val_loss: 0.1888 - val_r_square: 0.8804 - val_rmse: 0.1888    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.2144 - r_square: 0.8262 - rmse: 0.2144 - val_loss: 0.1871 - val_r_square: 0.8799 - val_rmse: 0.1871    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.2158 - r_square: 0.8455 - rmse: 0.2158 - val_loss: 0.1844 - val_r_square: 0.8805 - val_rmse: 0.1844    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.2092 - r_square: 0.8441 - rmse: 0.2092 - val_loss: 0.1966 - val_r_square: 0.8775 - val_rmse: 0.1966    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.2074 - r_square: 0.8409 - rmse: 0.2074 - val_loss: 0.1757 - val_r_square: 0.8846 - val_rmse: 0.1757    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.2049 - r_square: 0.8519 - rmse: 0.2049 - val_loss: 0.1705 - val_r_square: 0.8874 - val_rmse: 0.1705    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.2045 - r_square: 0.8488 - rmse: 0.2045 - val_loss: 0.1763 - val_r_square: 0.8840 - val_rmse: 0.1763    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n",
      " - 0s - loss: 0.2027 - r_square: 0.8528 - rmse: 0.2027 - val_loss: 0.1871 - val_r_square: 0.8766 - val_rmse: 0.1871    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.2038 - r_square: 0.8509 - rmse: 0.2038 - val_loss: 0.1824 - val_r_square: 0.8827 - val_rmse: 0.1824    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.2026 - r_square: 0.8500 - rmse: 0.2026 - val_loss: 0.1739 - val_r_square: 0.8767 - val_rmse: 0.1739    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.1996 - r_square: 0.8538 - rmse: 0.1996 - val_loss: 0.1640 - val_r_square: 0.8893 - val_rmse: 0.1640    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.2006 - r_square: 0.8416 - rmse: 0.2006 - val_loss: 0.1943 - val_r_square: 0.8836 - val_rmse: 0.1943    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.1974 - r_square: 0.8570 - rmse: 0.1974 - val_loss: 0.1638 - val_r_square: 0.8900 - val_rmse: 0.1638    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.1971 - r_square: 0.8528 - rmse: 0.1971 - val_loss: 0.1855 - val_r_square: 0.8843 - val_rmse: 0.1855    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.1944 - r_square: 0.8577 - rmse: 0.1944 - val_loss: 0.1763 - val_r_square: 0.8879 - val_rmse: 0.1763    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.1988 - r_square: 0.8495 - rmse: 0.1988 - val_loss: 0.1614 - val_r_square: 0.8889 - val_rmse: 0.1614    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.1941 - r_square: 0.8460 - rmse: 0.1941 - val_loss: 0.1753 - val_r_square: 0.8877 - val_rmse: 0.1753    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.1929 - r_square: 0.8565 - rmse: 0.1929 - val_loss: 0.1745 - val_r_square: 0.8870 - val_rmse: 0.1745    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.1917 - r_square: 0.8609 - rmse: 0.1917 - val_loss: 0.1665 - val_r_square: 0.8898 - val_rmse: 0.1665    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.1969 - r_square: 0.8601 - rmse: 0.1969 - val_loss: 0.1810 - val_r_square: 0.8819 - val_rmse: 0.1810    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1910 - r_square: 0.8592 - rmse: 0.1910 - val_loss: 0.1901 - val_r_square: 0.8855 - val_rmse: 0.1901    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.1934 - r_square: 0.8579 - rmse: 0.1934 - val_loss: 0.1816 - val_r_square: 0.8893 - val_rmse: 0.1816    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.1873 - r_square: 0.8665 - rmse: 0.1873 - val_loss: 0.1736 - val_r_square: 0.8916 - val_rmse: 0.1736    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.1946 - r_square: 0.8612 - rmse: 0.1946 - val_loss: 0.1860 - val_r_square: 0.8874 - val_rmse: 0.1860    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.1892 - r_square: 0.8624 - rmse: 0.1892 - val_loss: 0.1793 - val_r_square: 0.8796 - val_rmse: 0.1793    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.1872 - r_square: 0.8645 - rmse: 0.1872 - val_loss: 0.1765 - val_r_square: 0.8886 - val_rmse: 0.1765    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.1941 - r_square: 0.8505 - rmse: 0.1941 - val_loss: 0.1734 - val_r_square: 0.8855 - val_rmse: 0.1734    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.1894 - r_square: 0.8648 - rmse: 0.1894 - val_loss: 0.1778 - val_r_square: 0.8847 - val_rmse: 0.1778    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.1890 - r_square: 0.8669 - rmse: 0.1890 - val_loss: 0.1698 - val_r_square: 0.8928 - val_rmse: 0.1698    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.16136665374976103                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_3\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_7 (Dense)              (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_5 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_8 (Dense)              (None, 300)               30300                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_6 (Dropout)          (None, 300)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_9 (Dense)              (None, 1)                 301                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 31,301                                                                                                   \n",
      "Trainable params: 31,301                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 0s - loss: 0.4944 - r_square: 0.5298 - rmse: 0.4944 - val_loss: 0.2990 - val_r_square: 0.7735 - val_rmse: 0.2990    \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.3404 - r_square: 0.7256 - rmse: 0.3404 - val_loss: 0.2639 - val_r_square: 0.7761 - val_rmse: 0.2639    \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.3191 - r_square: 0.7418 - rmse: 0.3191 - val_loss: 0.2472 - val_r_square: 0.7918 - val_rmse: 0.2472    \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.2953 - r_square: 0.7677 - rmse: 0.2953 - val_loss: 0.2431 - val_r_square: 0.8158 - val_rmse: 0.2431    \n",
      "\n",
      "Epoch 5/100                                                                                                            \n",
      " - 0s - loss: 0.2883 - r_square: 0.7709 - rmse: 0.2883 - val_loss: 0.2241 - val_r_square: 0.8145 - val_rmse: 0.2241    \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.2692 - r_square: 0.7880 - rmse: 0.2692 - val_loss: 0.2235 - val_r_square: 0.8153 - val_rmse: 0.2235    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.2705 - r_square: 0.7784 - rmse: 0.2705 - val_loss: 0.2010 - val_r_square: 0.8388 - val_rmse: 0.2010    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.2592 - r_square: 0.8038 - rmse: 0.2592 - val_loss: 0.2201 - val_r_square: 0.8344 - val_rmse: 0.2201    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.2554 - r_square: 0.8042 - rmse: 0.2554 - val_loss: 0.1999 - val_r_square: 0.8468 - val_rmse: 0.1999    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.2459 - r_square: 0.8251 - rmse: 0.2459 - val_loss: 0.2029 - val_r_square: 0.8563 - val_rmse: 0.2029    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.2360 - r_square: 0.8154 - rmse: 0.2360 - val_loss: 0.2050 - val_r_square: 0.8519 - val_rmse: 0.2050    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.2326 - r_square: 0.8270 - rmse: 0.2326 - val_loss: 0.2017 - val_r_square: 0.8591 - val_rmse: 0.2017    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.2330 - r_square: 0.8254 - rmse: 0.2330 - val_loss: 0.1908 - val_r_square: 0.8643 - val_rmse: 0.1908    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.2226 - r_square: 0.8393 - rmse: 0.2226 - val_loss: 0.1895 - val_r_square: 0.8686 - val_rmse: 0.1895    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2198 - r_square: 0.8353 - rmse: 0.2198 - val_loss: 0.1939 - val_r_square: 0.8696 - val_rmse: 0.1939    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.2185 - r_square: 0.8168 - rmse: 0.2185 - val_loss: 0.1976 - val_r_square: 0.8668 - val_rmse: 0.1976    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.2154 - r_square: 0.8390 - rmse: 0.2154 - val_loss: 0.1840 - val_r_square: 0.8751 - val_rmse: 0.1840    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.2142 - r_square: 0.8385 - rmse: 0.2142 - val_loss: 0.1918 - val_r_square: 0.8792 - val_rmse: 0.1918    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.2073 - r_square: 0.8440 - rmse: 0.2073 - val_loss: 0.1827 - val_r_square: 0.8845 - val_rmse: 0.1827    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.2067 - r_square: 0.8435 - rmse: 0.2067 - val_loss: 0.1787 - val_r_square: 0.8821 - val_rmse: 0.1787    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.2057 - r_square: 0.8440 - rmse: 0.2057 - val_loss: 0.1867 - val_r_square: 0.8794 - val_rmse: 0.1867    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.1993 - r_square: 0.8499 - rmse: 0.1993 - val_loss: 0.2139 - val_r_square: 0.8713 - val_rmse: 0.2139    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.1991 - r_square: 0.8486 - rmse: 0.1991 - val_loss: 0.1782 - val_r_square: 0.8865 - val_rmse: 0.1782    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.1999 - r_square: 0.8567 - rmse: 0.1999 - val_loss: 0.1815 - val_r_square: 0.8842 - val_rmse: 0.1815    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.1973 - r_square: 0.8555 - rmse: 0.1973 - val_loss: 0.1999 - val_r_square: 0.8797 - val_rmse: 0.1999    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.1951 - r_square: 0.8422 - rmse: 0.1951 - val_loss: 0.1810 - val_r_square: 0.8878 - val_rmse: 0.1810    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.1961 - r_square: 0.8552 - rmse: 0.1961 - val_loss: 0.1910 - val_r_square: 0.8835 - val_rmse: 0.1910    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.1910 - r_square: 0.8330 - rmse: 0.1910 - val_loss: 0.1772 - val_r_square: 0.8901 - val_rmse: 0.1772    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.1880 - r_square: 0.8634 - rmse: 0.1880 - val_loss: 0.1890 - val_r_square: 0.8865 - val_rmse: 0.1890    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.1881 - r_square: 0.8608 - rmse: 0.1881 - val_loss: 0.1929 - val_r_square: 0.8846 - val_rmse: 0.1929    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.1863 - r_square: 0.8679 - rmse: 0.1863 - val_loss: 0.1816 - val_r_square: 0.8880 - val_rmse: 0.1816    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.1860 - r_square: 0.8583 - rmse: 0.1860 - val_loss: 0.2114 - val_r_square: 0.8766 - val_rmse: 0.2114    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.1841 - r_square: 0.8575 - rmse: 0.1841 - val_loss: 0.1796 - val_r_square: 0.8872 - val_rmse: 0.1796    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.1860 - r_square: 0.8654 - rmse: 0.1860 - val_loss: 0.1807 - val_r_square: 0.8913 - val_rmse: 0.1807    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.1859 - r_square: 0.8642 - rmse: 0.1859 - val_loss: 0.1933 - val_r_square: 0.8850 - val_rmse: 0.1933    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.1824 - r_square: 0.8669 - rmse: 0.1824 - val_loss: 0.1849 - val_r_square: 0.8905 - val_rmse: 0.1849    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.1806 - r_square: 0.8649 - rmse: 0.1806 - val_loss: 0.1813 - val_r_square: 0.8909 - val_rmse: 0.1813    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.1794 - r_square: 0.8604 - rmse: 0.1794 - val_loss: 0.1789 - val_r_square: 0.8932 - val_rmse: 0.1789    \n",
      "\n",
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.1777 - r_square: 0.8683 - rmse: 0.1777 - val_loss: 0.1828 - val_r_square: 0.8913 - val_rmse: 0.1828    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.1783 - r_square: 0.8688 - rmse: 0.1783 - val_loss: 0.1911 - val_r_square: 0.8908 - val_rmse: 0.1911    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.1786 - r_square: 0.8655 - rmse: 0.1786 - val_loss: 0.1853 - val_r_square: 0.8889 - val_rmse: 0.1853    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.1806 - r_square: 0.8633 - rmse: 0.1806 - val_loss: 0.1714 - val_r_square: 0.8980 - val_rmse: 0.1714    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.1785 - r_square: 0.8679 - rmse: 0.1785 - val_loss: 0.1783 - val_r_square: 0.8854 - val_rmse: 0.1783    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.1790 - r_square: 0.8621 - rmse: 0.1790 - val_loss: 0.1876 - val_r_square: 0.8843 - val_rmse: 0.1876    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.1768 - r_square: 0.8691 - rmse: 0.1768 - val_loss: 0.1956 - val_r_square: 0.8865 - val_rmse: 0.1956    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.1735 - r_square: 0.8703 - rmse: 0.1735 - val_loss: 0.1842 - val_r_square: 0.8918 - val_rmse: 0.1842    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.1745 - r_square: 0.8687 - rmse: 0.1745 - val_loss: 0.1845 - val_r_square: 0.8914 - val_rmse: 0.1845    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.1732 - r_square: 0.8687 - rmse: 0.1732 - val_loss: 0.1880 - val_r_square: 0.8933 - val_rmse: 0.1880    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.1705 - r_square: 0.8695 - rmse: 0.1705 - val_loss: 0.1817 - val_r_square: 0.8923 - val_rmse: 0.1817    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.1707 - r_square: 0.8753 - rmse: 0.1707 - val_loss: 0.1819 - val_r_square: 0.8926 - val_rmse: 0.1819    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.1719 - r_square: 0.8713 - rmse: 0.1719 - val_loss: 0.1706 - val_r_square: 0.8944 - val_rmse: 0.1706    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.1730 - r_square: 0.8766 - rmse: 0.1730 - val_loss: 0.1693 - val_r_square: 0.8975 - val_rmse: 0.1693    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.1668 - r_square: 0.8709 - rmse: 0.1668 - val_loss: 0.1734 - val_r_square: 0.8986 - val_rmse: 0.1734    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.1728 - r_square: 0.8699 - rmse: 0.1728 - val_loss: 0.1923 - val_r_square: 0.8905 - val_rmse: 0.1923    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.1694 - r_square: 0.8803 - rmse: 0.1694 - val_loss: 0.1663 - val_r_square: 0.8963 - val_rmse: 0.1663    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.1685 - r_square: 0.8713 - rmse: 0.1685 - val_loss: 0.1774 - val_r_square: 0.8943 - val_rmse: 0.1774    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.1648 - r_square: 0.8796 - rmse: 0.1648 - val_loss: 0.1860 - val_r_square: 0.8916 - val_rmse: 0.1860    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.1670 - r_square: 0.8721 - rmse: 0.1670 - val_loss: 0.1844 - val_r_square: 0.8922 - val_rmse: 0.1844    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.1676 - r_square: 0.8828 - rmse: 0.1676 - val_loss: 0.1820 - val_r_square: 0.8953 - val_rmse: 0.1820    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.1642 - r_square: 0.8787 - rmse: 0.1642 - val_loss: 0.1815 - val_r_square: 0.8957 - val_rmse: 0.1815    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.1635 - r_square: 0.8745 - rmse: 0.1635 - val_loss: 0.1763 - val_r_square: 0.8938 - val_rmse: 0.1763    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.1679 - r_square: 0.8688 - rmse: 0.1679 - val_loss: 0.1763 - val_r_square: 0.8959 - val_rmse: 0.1763    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.1645 - r_square: 0.8679 - rmse: 0.1645 - val_loss: 0.1846 - val_r_square: 0.8919 - val_rmse: 0.1846    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.1657 - r_square: 0.8718 - rmse: 0.1657 - val_loss: 0.1595 - val_r_square: 0.8989 - val_rmse: 0.1595    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.1669 - r_square: 0.8726 - rmse: 0.1669 - val_loss: 0.1788 - val_r_square: 0.8960 - val_rmse: 0.1788    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.1608 - r_square: 0.8794 - rmse: 0.1608 - val_loss: 0.1654 - val_r_square: 0.9014 - val_rmse: 0.1654    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.1629 - r_square: 0.8791 - rmse: 0.1629 - val_loss: 0.1716 - val_r_square: 0.8962 - val_rmse: 0.1716    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.1614 - r_square: 0.8780 - rmse: 0.1614 - val_loss: 0.1763 - val_r_square: 0.8934 - val_rmse: 0.1763    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.1638 - r_square: 0.8727 - rmse: 0.1638 - val_loss: 0.1795 - val_r_square: 0.8958 - val_rmse: 0.1795    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.1618 - r_square: 0.8790 - rmse: 0.1618 - val_loss: 0.1709 - val_r_square: 0.8943 - val_rmse: 0.1709    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.1645 - r_square: 0.8691 - rmse: 0.1645 - val_loss: 0.1842 - val_r_square: 0.8887 - val_rmse: 0.1842    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n",
      " - 0s - loss: 0.1636 - r_square: 0.8798 - rmse: 0.1636 - val_loss: 0.1783 - val_r_square: 0.8964 - val_rmse: 0.1783    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.1618 - r_square: 0.8756 - rmse: 0.1618 - val_loss: 0.1772 - val_r_square: 0.8938 - val_rmse: 0.1772    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.1607 - r_square: 0.8860 - rmse: 0.1607 - val_loss: 0.1855 - val_r_square: 0.8894 - val_rmse: 0.1855    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.1608 - r_square: 0.8699 - rmse: 0.1608 - val_loss: 0.1647 - val_r_square: 0.8961 - val_rmse: 0.1647    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.1590 - r_square: 0.8764 - rmse: 0.1590 - val_loss: 0.1872 - val_r_square: 0.8910 - val_rmse: 0.1872    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.1628 - r_square: 0.8796 - rmse: 0.1628 - val_loss: 0.1622 - val_r_square: 0.9039 - val_rmse: 0.1622    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.1630 - r_square: 0.8755 - rmse: 0.1630 - val_loss: 0.1734 - val_r_square: 0.9005 - val_rmse: 0.1734    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.1594 - r_square: 0.8855 - rmse: 0.1594 - val_loss: 0.1717 - val_r_square: 0.9005 - val_rmse: 0.1717    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.1575 - r_square: 0.8795 - rmse: 0.1575 - val_loss: 0.1719 - val_r_square: 0.9016 - val_rmse: 0.1719    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.1606 - r_square: 0.8811 - rmse: 0.1606 - val_loss: 0.1664 - val_r_square: 0.8993 - val_rmse: 0.1664    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1615 - r_square: 0.8788 - rmse: 0.1615 - val_loss: 0.1822 - val_r_square: 0.8943 - val_rmse: 0.1822    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.1541 - r_square: 0.8862 - rmse: 0.1541 - val_loss: 0.1697 - val_r_square: 0.8978 - val_rmse: 0.1697    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.1525 - r_square: 0.8900 - rmse: 0.1525 - val_loss: 0.1709 - val_r_square: 0.8995 - val_rmse: 0.1709    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.1538 - r_square: 0.8866 - rmse: 0.1538 - val_loss: 0.1812 - val_r_square: 0.8914 - val_rmse: 0.1812    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.1569 - r_square: 0.8859 - rmse: 0.1569 - val_loss: 0.1740 - val_r_square: 0.8989 - val_rmse: 0.1740    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.1565 - r_square: 0.8845 - rmse: 0.1565 - val_loss: 0.1802 - val_r_square: 0.8903 - val_rmse: 0.1802    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.1544 - r_square: 0.8867 - rmse: 0.1544 - val_loss: 0.1706 - val_r_square: 0.8982 - val_rmse: 0.1706    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.1568 - r_square: 0.8786 - rmse: 0.1568 - val_loss: 0.1646 - val_r_square: 0.9018 - val_rmse: 0.1646    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.1555 - r_square: 0.8862 - rmse: 0.1555 - val_loss: 0.1703 - val_r_square: 0.8958 - val_rmse: 0.1703    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.1550 - r_square: 0.8869 - rmse: 0.1550 - val_loss: 0.1904 - val_r_square: 0.8912 - val_rmse: 0.1904    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.1576 - r_square: 0.8770 - rmse: 0.1576 - val_loss: 0.1705 - val_r_square: 0.8992 - val_rmse: 0.1705    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.1581 - r_square: 0.8807 - rmse: 0.1581 - val_loss: 0.1622 - val_r_square: 0.9044 - val_rmse: 0.1622    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.1550 - r_square: 0.8877 - rmse: 0.1550 - val_loss: 0.1619 - val_r_square: 0.9021 - val_rmse: 0.1619    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.1509 - r_square: 0.8945 - rmse: 0.1509 - val_loss: 0.1704 - val_r_square: 0.8998 - val_rmse: 0.1704    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.1533 - r_square: 0.8832 - rmse: 0.1533 - val_loss: 0.1754 - val_r_square: 0.8958 - val_rmse: 0.1754    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.1590 - r_square: 0.8816 - rmse: 0.1590 - val_loss: 0.1818 - val_r_square: 0.8914 - val_rmse: 0.1818    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.1519 - r_square: 0.8861 - rmse: 0.1519 - val_loss: 0.1706 - val_r_square: 0.8985 - val_rmse: 0.1706    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.1569 - r_square: 0.8852 - rmse: 0.1569 - val_loss: 0.1645 - val_r_square: 0.8990 - val_rmse: 0.1645    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.1536 - r_square: 0.8832 - rmse: 0.1536 - val_loss: 0.1635 - val_r_square: 0.9001 - val_rmse: 0.1635    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.15945896851553154                                                                                                    \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_4\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_10 (Dense)             (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_7 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_11 (Dense)             (None, 400)               40400                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_8 (Dropout)          (None, 400)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_12 (Dense)             (None, 1)                 401                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 41,501                                                                                                   \n",
      "Trainable params: 41,501                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      " - 0s - loss: 0.5438 - r_square: 0.4333 - rmse: 0.5438 - val_loss: 0.3418 - val_r_square: 0.7337 - val_rmse: 0.3418    \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      " - 0s - loss: 0.3738 - r_square: 0.6749 - rmse: 0.3738 - val_loss: 0.2753 - val_r_square: 0.7968 - val_rmse: 0.2753    \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      " - 0s - loss: 0.3211 - r_square: 0.7337 - rmse: 0.3211 - val_loss: 0.2692 - val_r_square: 0.8184 - val_rmse: 0.2692    \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      " - 0s - loss: 0.3029 - r_square: 0.7390 - rmse: 0.3029 - val_loss: 0.2286 - val_r_square: 0.8398 - val_rmse: 0.2286    \n",
      "\n",
      "Epoch 5/100                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2871 - r_square: 0.7668 - rmse: 0.2871 - val_loss: 0.2167 - val_r_square: 0.8421 - val_rmse: 0.2167    \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      " - 0s - loss: 0.2740 - r_square: 0.7705 - rmse: 0.2740 - val_loss: 0.2097 - val_r_square: 0.8513 - val_rmse: 0.2097    \n",
      "\n",
      "Epoch 7/100                                                                                                            \n",
      " - 0s - loss: 0.2579 - r_square: 0.7932 - rmse: 0.2579 - val_loss: 0.2204 - val_r_square: 0.8504 - val_rmse: 0.2204    \n",
      "\n",
      "Epoch 8/100                                                                                                            \n",
      " - 0s - loss: 0.2549 - r_square: 0.7880 - rmse: 0.2549 - val_loss: 0.1970 - val_r_square: 0.8626 - val_rmse: 0.1970    \n",
      "\n",
      "Epoch 9/100                                                                                                            \n",
      " - 0s - loss: 0.2462 - r_square: 0.8019 - rmse: 0.2462 - val_loss: 0.2005 - val_r_square: 0.8637 - val_rmse: 0.2005    \n",
      "\n",
      "Epoch 10/100                                                                                                           \n",
      " - 0s - loss: 0.2436 - r_square: 0.8120 - rmse: 0.2436 - val_loss: 0.1935 - val_r_square: 0.8693 - val_rmse: 0.1935    \n",
      "\n",
      "Epoch 11/100                                                                                                           \n",
      " - 0s - loss: 0.2399 - r_square: 0.8037 - rmse: 0.2399 - val_loss: 0.1961 - val_r_square: 0.8716 - val_rmse: 0.1961    \n",
      "\n",
      "Epoch 12/100                                                                                                           \n",
      " - 0s - loss: 0.2358 - r_square: 0.8134 - rmse: 0.2358 - val_loss: 0.2001 - val_r_square: 0.8675 - val_rmse: 0.2001    \n",
      "\n",
      "Epoch 13/100                                                                                                           \n",
      " - 0s - loss: 0.2283 - r_square: 0.8178 - rmse: 0.2283 - val_loss: 0.2128 - val_r_square: 0.8676 - val_rmse: 0.2128    \n",
      "\n",
      "Epoch 14/100                                                                                                           \n",
      " - 0s - loss: 0.2214 - r_square: 0.8196 - rmse: 0.2214 - val_loss: 0.1838 - val_r_square: 0.8811 - val_rmse: 0.1838    \n",
      "\n",
      "Epoch 15/100                                                                                                           \n",
      " - 0s - loss: 0.2209 - r_square: 0.8185 - rmse: 0.2209 - val_loss: 0.1975 - val_r_square: 0.8756 - val_rmse: 0.1975    \n",
      "\n",
      "Epoch 16/100                                                                                                           \n",
      " - 0s - loss: 0.2186 - r_square: 0.8266 - rmse: 0.2186 - val_loss: 0.1838 - val_r_square: 0.8841 - val_rmse: 0.1838    \n",
      "\n",
      "Epoch 17/100                                                                                                           \n",
      " - 0s - loss: 0.2146 - r_square: 0.8287 - rmse: 0.2146 - val_loss: 0.1766 - val_r_square: 0.8868 - val_rmse: 0.1766    \n",
      "\n",
      "Epoch 18/100                                                                                                           \n",
      " - 0s - loss: 0.2076 - r_square: 0.8335 - rmse: 0.2076 - val_loss: 0.1830 - val_r_square: 0.8844 - val_rmse: 0.1830    \n",
      "\n",
      "Epoch 19/100                                                                                                           \n",
      " - 0s - loss: 0.2059 - r_square: 0.8363 - rmse: 0.2059 - val_loss: 0.1910 - val_r_square: 0.8795 - val_rmse: 0.1910    \n",
      "\n",
      "Epoch 20/100                                                                                                           \n",
      " - 0s - loss: 0.2077 - r_square: 0.8345 - rmse: 0.2077 - val_loss: 0.1756 - val_r_square: 0.8859 - val_rmse: 0.1756    \n",
      "\n",
      "Epoch 21/100                                                                                                           \n",
      " - 0s - loss: 0.2074 - r_square: 0.8323 - rmse: 0.2074 - val_loss: 0.1847 - val_r_square: 0.8848 - val_rmse: 0.1847    \n",
      "\n",
      "Epoch 22/100                                                                                                           \n",
      " - 0s - loss: 0.2025 - r_square: 0.8343 - rmse: 0.2025 - val_loss: 0.1803 - val_r_square: 0.8867 - val_rmse: 0.1803    \n",
      "\n",
      "Epoch 23/100                                                                                                           \n",
      " - 0s - loss: 0.1982 - r_square: 0.8394 - rmse: 0.1982 - val_loss: 0.1928 - val_r_square: 0.8819 - val_rmse: 0.1928    \n",
      "\n",
      "Epoch 24/100                                                                                                           \n",
      " - 0s - loss: 0.2005 - r_square: 0.8390 - rmse: 0.2005 - val_loss: 0.1844 - val_r_square: 0.8845 - val_rmse: 0.1844    \n",
      "\n",
      "Epoch 25/100                                                                                                           \n",
      " - 0s - loss: 0.1953 - r_square: 0.8381 - rmse: 0.1953 - val_loss: 0.1773 - val_r_square: 0.8874 - val_rmse: 0.1773    \n",
      "\n",
      "Epoch 26/100                                                                                                           \n",
      " - 0s - loss: 0.1938 - r_square: 0.8490 - rmse: 0.1938 - val_loss: 0.1945 - val_r_square: 0.8777 - val_rmse: 0.1945    \n",
      "\n",
      "Epoch 27/100                                                                                                           \n",
      " - 0s - loss: 0.1957 - r_square: 0.8439 - rmse: 0.1957 - val_loss: 0.1858 - val_r_square: 0.8888 - val_rmse: 0.1858    \n",
      "\n",
      "Epoch 28/100                                                                                                           \n",
      " - 0s - loss: 0.1932 - r_square: 0.8469 - rmse: 0.1932 - val_loss: 0.1694 - val_r_square: 0.8923 - val_rmse: 0.1694    \n",
      "\n",
      "Epoch 29/100                                                                                                           \n",
      " - 0s - loss: 0.1901 - r_square: 0.8478 - rmse: 0.1901 - val_loss: 0.1768 - val_r_square: 0.8899 - val_rmse: 0.1768    \n",
      "\n",
      "Epoch 30/100                                                                                                           \n",
      " - 0s - loss: 0.1875 - r_square: 0.8576 - rmse: 0.1875 - val_loss: 0.1788 - val_r_square: 0.8884 - val_rmse: 0.1788    \n",
      "\n",
      "Epoch 31/100                                                                                                           \n",
      " - 0s - loss: 0.1897 - r_square: 0.8555 - rmse: 0.1897 - val_loss: 0.1788 - val_r_square: 0.8896 - val_rmse: 0.1788    \n",
      "\n",
      "Epoch 32/100                                                                                                           \n",
      " - 0s - loss: 0.1900 - r_square: 0.8501 - rmse: 0.1900 - val_loss: 0.1792 - val_r_square: 0.8907 - val_rmse: 0.1792    \n",
      "\n",
      "Epoch 33/100                                                                                                           \n",
      " - 0s - loss: 0.1856 - r_square: 0.8539 - rmse: 0.1856 - val_loss: 0.1949 - val_r_square: 0.8829 - val_rmse: 0.1949    \n",
      "\n",
      "Epoch 34/100                                                                                                           \n",
      " - 0s - loss: 0.1859 - r_square: 0.8508 - rmse: 0.1859 - val_loss: 0.1613 - val_r_square: 0.8910 - val_rmse: 0.1613    \n",
      "\n",
      "Epoch 35/100                                                                                                           \n",
      " - 0s - loss: 0.1862 - r_square: 0.8504 - rmse: 0.1862 - val_loss: 0.1870 - val_r_square: 0.8883 - val_rmse: 0.1870    \n",
      "\n",
      "Epoch 36/100                                                                                                           \n",
      " - 0s - loss: 0.1836 - r_square: 0.8529 - rmse: 0.1836 - val_loss: 0.1786 - val_r_square: 0.8918 - val_rmse: 0.1786    \n",
      "\n",
      "Epoch 37/100                                                                                                           \n",
      " - 0s - loss: 0.1789 - r_square: 0.8577 - rmse: 0.1789 - val_loss: 0.1784 - val_r_square: 0.8909 - val_rmse: 0.1784    \n",
      "\n",
      "Epoch 38/100                                                                                                           \n",
      " - 0s - loss: 0.1877 - r_square: 0.8534 - rmse: 0.1877 - val_loss: 0.1796 - val_r_square: 0.8953 - val_rmse: 0.1796    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100                                                                                                           \n",
      " - 0s - loss: 0.1836 - r_square: 0.8470 - rmse: 0.1836 - val_loss: 0.1861 - val_r_square: 0.8879 - val_rmse: 0.1861    \n",
      "\n",
      "Epoch 40/100                                                                                                           \n",
      " - 0s - loss: 0.1779 - r_square: 0.8558 - rmse: 0.1779 - val_loss: 0.1803 - val_r_square: 0.8881 - val_rmse: 0.1803    \n",
      "\n",
      "Epoch 41/100                                                                                                           \n",
      " - 0s - loss: 0.1809 - r_square: 0.8531 - rmse: 0.1809 - val_loss: 0.1908 - val_r_square: 0.8888 - val_rmse: 0.1908    \n",
      "\n",
      "Epoch 42/100                                                                                                           \n",
      " - 0s - loss: 0.1821 - r_square: 0.8556 - rmse: 0.1821 - val_loss: 0.1702 - val_r_square: 0.8934 - val_rmse: 0.1702    \n",
      "\n",
      "Epoch 43/100                                                                                                           \n",
      " - 0s - loss: 0.1784 - r_square: 0.8556 - rmse: 0.1784 - val_loss: 0.1607 - val_r_square: 0.8976 - val_rmse: 0.1607    \n",
      "\n",
      "Epoch 44/100                                                                                                           \n",
      " - 0s - loss: 0.1750 - r_square: 0.8653 - rmse: 0.1750 - val_loss: 0.1874 - val_r_square: 0.8910 - val_rmse: 0.1874    \n",
      "\n",
      "Epoch 45/100                                                                                                           \n",
      " - 0s - loss: 0.1775 - r_square: 0.8540 - rmse: 0.1775 - val_loss: 0.1923 - val_r_square: 0.8849 - val_rmse: 0.1923    \n",
      "\n",
      "Epoch 46/100                                                                                                           \n",
      " - 0s - loss: 0.1759 - r_square: 0.8523 - rmse: 0.1759 - val_loss: 0.2049 - val_r_square: 0.8834 - val_rmse: 0.2049    \n",
      "\n",
      "Epoch 47/100                                                                                                           \n",
      " - 0s - loss: 0.1757 - r_square: 0.8611 - rmse: 0.1757 - val_loss: 0.1831 - val_r_square: 0.8942 - val_rmse: 0.1831    \n",
      "\n",
      "Epoch 48/100                                                                                                           \n",
      " - 0s - loss: 0.1751 - r_square: 0.8582 - rmse: 0.1751 - val_loss: 0.1793 - val_r_square: 0.8940 - val_rmse: 0.1793    \n",
      "\n",
      "Epoch 49/100                                                                                                           \n",
      " - 0s - loss: 0.1712 - r_square: 0.8622 - rmse: 0.1712 - val_loss: 0.1809 - val_r_square: 0.8917 - val_rmse: 0.1809    \n",
      "\n",
      "Epoch 50/100                                                                                                           \n",
      " - 0s - loss: 0.1722 - r_square: 0.8668 - rmse: 0.1722 - val_loss: 0.1762 - val_r_square: 0.8940 - val_rmse: 0.1762    \n",
      "\n",
      "Epoch 51/100                                                                                                           \n",
      " - 0s - loss: 0.1746 - r_square: 0.8598 - rmse: 0.1746 - val_loss: 0.1802 - val_r_square: 0.8938 - val_rmse: 0.1802    \n",
      "\n",
      "Epoch 52/100                                                                                                           \n",
      " - 0s - loss: 0.1741 - r_square: 0.8604 - rmse: 0.1741 - val_loss: 0.1776 - val_r_square: 0.8916 - val_rmse: 0.1776    \n",
      "\n",
      "Epoch 53/100                                                                                                           \n",
      " - 0s - loss: 0.1697 - r_square: 0.8645 - rmse: 0.1697 - val_loss: 0.1744 - val_r_square: 0.8947 - val_rmse: 0.1744    \n",
      "\n",
      "Epoch 54/100                                                                                                           \n",
      " - 0s - loss: 0.1712 - r_square: 0.8639 - rmse: 0.1712 - val_loss: 0.1750 - val_r_square: 0.8967 - val_rmse: 0.1750    \n",
      "\n",
      "Epoch 55/100                                                                                                           \n",
      " - 0s - loss: 0.1737 - r_square: 0.8604 - rmse: 0.1737 - val_loss: 0.1928 - val_r_square: 0.8912 - val_rmse: 0.1928    \n",
      "\n",
      "Epoch 56/100                                                                                                           \n",
      " - 0s - loss: 0.1718 - r_square: 0.8639 - rmse: 0.1718 - val_loss: 0.1793 - val_r_square: 0.8914 - val_rmse: 0.1793    \n",
      "\n",
      "Epoch 57/100                                                                                                           \n",
      " - 0s - loss: 0.1679 - r_square: 0.8677 - rmse: 0.1679 - val_loss: 0.1772 - val_r_square: 0.8948 - val_rmse: 0.1772    \n",
      "\n",
      "Epoch 58/100                                                                                                           \n",
      " - 0s - loss: 0.1692 - r_square: 0.8591 - rmse: 0.1692 - val_loss: 0.1891 - val_r_square: 0.8902 - val_rmse: 0.1891    \n",
      "\n",
      "Epoch 59/100                                                                                                           \n",
      " - 0s - loss: 0.1675 - r_square: 0.8635 - rmse: 0.1675 - val_loss: 0.1850 - val_r_square: 0.8924 - val_rmse: 0.1850    \n",
      "\n",
      "Epoch 60/100                                                                                                           \n",
      " - 0s - loss: 0.1664 - r_square: 0.8603 - rmse: 0.1664 - val_loss: 0.1708 - val_r_square: 0.8987 - val_rmse: 0.1708    \n",
      "\n",
      "Epoch 61/100                                                                                                           \n",
      " - 0s - loss: 0.1688 - r_square: 0.8608 - rmse: 0.1688 - val_loss: 0.1822 - val_r_square: 0.8958 - val_rmse: 0.1822    \n",
      "\n",
      "Epoch 62/100                                                                                                           \n",
      " - 0s - loss: 0.1694 - r_square: 0.8608 - rmse: 0.1694 - val_loss: 0.1910 - val_r_square: 0.8906 - val_rmse: 0.1910    \n",
      "\n",
      "Epoch 63/100                                                                                                           \n",
      " - 0s - loss: 0.1697 - r_square: 0.8567 - rmse: 0.1697 - val_loss: 0.1833 - val_r_square: 0.8942 - val_rmse: 0.1833    \n",
      "\n",
      "Epoch 64/100                                                                                                           \n",
      " - 0s - loss: 0.1654 - r_square: 0.8686 - rmse: 0.1654 - val_loss: 0.1771 - val_r_square: 0.8956 - val_rmse: 0.1771    \n",
      "\n",
      "Epoch 65/100                                                                                                           \n",
      " - 0s - loss: 0.1649 - r_square: 0.8634 - rmse: 0.1649 - val_loss: 0.1890 - val_r_square: 0.8921 - val_rmse: 0.1890    \n",
      "\n",
      "Epoch 66/100                                                                                                           \n",
      " - 0s - loss: 0.1655 - r_square: 0.8687 - rmse: 0.1655 - val_loss: 0.1852 - val_r_square: 0.8931 - val_rmse: 0.1852    \n",
      "\n",
      "Epoch 67/100                                                                                                           \n",
      " - 0s - loss: 0.1636 - r_square: 0.8719 - rmse: 0.1636 - val_loss: 0.1790 - val_r_square: 0.8934 - val_rmse: 0.1790    \n",
      "\n",
      "Epoch 68/100                                                                                                           \n",
      " - 0s - loss: 0.1635 - r_square: 0.8651 - rmse: 0.1635 - val_loss: 0.1809 - val_r_square: 0.8958 - val_rmse: 0.1809    \n",
      "\n",
      "Epoch 69/100                                                                                                           \n",
      " - 0s - loss: 0.1644 - r_square: 0.8704 - rmse: 0.1644 - val_loss: 0.1682 - val_r_square: 0.9002 - val_rmse: 0.1682    \n",
      "\n",
      "Epoch 70/100                                                                                                           \n",
      " - 0s - loss: 0.1637 - r_square: 0.8628 - rmse: 0.1637 - val_loss: 0.1826 - val_r_square: 0.8941 - val_rmse: 0.1826    \n",
      "\n",
      "Epoch 71/100                                                                                                           \n",
      " - 0s - loss: 0.1636 - r_square: 0.8703 - rmse: 0.1636 - val_loss: 0.1854 - val_r_square: 0.8918 - val_rmse: 0.1854    \n",
      "\n",
      "Epoch 72/100                                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1632 - r_square: 0.8704 - rmse: 0.1632 - val_loss: 0.1875 - val_r_square: 0.8909 - val_rmse: 0.1875    \n",
      "\n",
      "Epoch 73/100                                                                                                           \n",
      " - 0s - loss: 0.1629 - r_square: 0.8662 - rmse: 0.1629 - val_loss: 0.1836 - val_r_square: 0.8921 - val_rmse: 0.1836    \n",
      "\n",
      "Epoch 74/100                                                                                                           \n",
      " - 0s - loss: 0.1612 - r_square: 0.8674 - rmse: 0.1612 - val_loss: 0.1913 - val_r_square: 0.8887 - val_rmse: 0.1913    \n",
      "\n",
      "Epoch 75/100                                                                                                           \n",
      " - 0s - loss: 0.1580 - r_square: 0.8701 - rmse: 0.1580 - val_loss: 0.1758 - val_r_square: 0.8988 - val_rmse: 0.1758    \n",
      "\n",
      "Epoch 76/100                                                                                                           \n",
      " - 0s - loss: 0.1649 - r_square: 0.8685 - rmse: 0.1649 - val_loss: 0.1806 - val_r_square: 0.8961 - val_rmse: 0.1806    \n",
      "\n",
      "Epoch 77/100                                                                                                           \n",
      " - 0s - loss: 0.1626 - r_square: 0.8671 - rmse: 0.1626 - val_loss: 0.1797 - val_r_square: 0.8972 - val_rmse: 0.1797    \n",
      "\n",
      "Epoch 78/100                                                                                                           \n",
      " - 0s - loss: 0.1598 - r_square: 0.8632 - rmse: 0.1598 - val_loss: 0.1893 - val_r_square: 0.8937 - val_rmse: 0.1893    \n",
      "\n",
      "Epoch 79/100                                                                                                           \n",
      " - 0s - loss: 0.1608 - r_square: 0.8730 - rmse: 0.1608 - val_loss: 0.1800 - val_r_square: 0.8967 - val_rmse: 0.1800    \n",
      "\n",
      "Epoch 80/100                                                                                                           \n",
      " - 0s - loss: 0.1571 - r_square: 0.8763 - rmse: 0.1571 - val_loss: 0.1885 - val_r_square: 0.8919 - val_rmse: 0.1885    \n",
      "\n",
      "Epoch 81/100                                                                                                           \n",
      " - 0s - loss: 0.1593 - r_square: 0.8706 - rmse: 0.1593 - val_loss: 0.1696 - val_r_square: 0.9004 - val_rmse: 0.1696    \n",
      "\n",
      "Epoch 82/100                                                                                                           \n",
      " - 0s - loss: 0.1590 - r_square: 0.8724 - rmse: 0.1590 - val_loss: 0.1908 - val_r_square: 0.8909 - val_rmse: 0.1908    \n",
      "\n",
      "Epoch 83/100                                                                                                           \n",
      " - 0s - loss: 0.1587 - r_square: 0.8709 - rmse: 0.1587 - val_loss: 0.1878 - val_r_square: 0.8916 - val_rmse: 0.1878    \n",
      "\n",
      "Epoch 84/100                                                                                                           \n",
      " - 0s - loss: 0.1582 - r_square: 0.8664 - rmse: 0.1582 - val_loss: 0.1770 - val_r_square: 0.8971 - val_rmse: 0.1770    \n",
      "\n",
      "Epoch 85/100                                                                                                           \n",
      " - 0s - loss: 0.1573 - r_square: 0.8691 - rmse: 0.1573 - val_loss: 0.1946 - val_r_square: 0.8898 - val_rmse: 0.1946    \n",
      "\n",
      "Epoch 86/100                                                                                                           \n",
      " - 0s - loss: 0.1570 - r_square: 0.8792 - rmse: 0.1570 - val_loss: 0.1761 - val_r_square: 0.8971 - val_rmse: 0.1761    \n",
      "\n",
      "Epoch 87/100                                                                                                           \n",
      " - 0s - loss: 0.1574 - r_square: 0.8749 - rmse: 0.1574 - val_loss: 0.1717 - val_r_square: 0.8962 - val_rmse: 0.1717    \n",
      "\n",
      "Epoch 88/100                                                                                                           \n",
      " - 0s - loss: 0.1567 - r_square: 0.8712 - rmse: 0.1567 - val_loss: 0.1696 - val_r_square: 0.9024 - val_rmse: 0.1696    \n",
      "\n",
      "Epoch 89/100                                                                                                           \n",
      " - 0s - loss: 0.1570 - r_square: 0.8702 - rmse: 0.1570 - val_loss: 0.1768 - val_r_square: 0.8982 - val_rmse: 0.1768    \n",
      "\n",
      "Epoch 90/100                                                                                                           \n",
      " - 0s - loss: 0.1568 - r_square: 0.8772 - rmse: 0.1568 - val_loss: 0.1786 - val_r_square: 0.8961 - val_rmse: 0.1786    \n",
      "\n",
      "Epoch 91/100                                                                                                           \n",
      " - 0s - loss: 0.1556 - r_square: 0.8723 - rmse: 0.1556 - val_loss: 0.1614 - val_r_square: 0.9030 - val_rmse: 0.1614    \n",
      "\n",
      "Epoch 92/100                                                                                                           \n",
      " - 0s - loss: 0.1570 - r_square: 0.8730 - rmse: 0.1570 - val_loss: 0.1796 - val_r_square: 0.8975 - val_rmse: 0.1796    \n",
      "\n",
      "Epoch 93/100                                                                                                           \n",
      " - 0s - loss: 0.1551 - r_square: 0.8732 - rmse: 0.1551 - val_loss: 0.1865 - val_r_square: 0.8930 - val_rmse: 0.1865    \n",
      "\n",
      "Epoch 94/100                                                                                                           \n",
      " - 0s - loss: 0.1566 - r_square: 0.8763 - rmse: 0.1566 - val_loss: 0.1714 - val_r_square: 0.8971 - val_rmse: 0.1714    \n",
      "\n",
      "Epoch 95/100                                                                                                           \n",
      " - 0s - loss: 0.1554 - r_square: 0.8781 - rmse: 0.1554 - val_loss: 0.1835 - val_r_square: 0.8953 - val_rmse: 0.1835    \n",
      "\n",
      "Epoch 96/100                                                                                                           \n",
      " - 0s - loss: 0.1546 - r_square: 0.8750 - rmse: 0.1546 - val_loss: 0.1887 - val_r_square: 0.8939 - val_rmse: 0.1887    \n",
      "\n",
      "Epoch 97/100                                                                                                           \n",
      " - 0s - loss: 0.1535 - r_square: 0.8733 - rmse: 0.1535 - val_loss: 0.1831 - val_r_square: 0.8937 - val_rmse: 0.1831    \n",
      "\n",
      "Epoch 98/100                                                                                                           \n",
      " - 0s - loss: 0.1571 - r_square: 0.8742 - rmse: 0.1571 - val_loss: 0.1773 - val_r_square: 0.8972 - val_rmse: 0.1773    \n",
      "\n",
      "Epoch 99/100                                                                                                           \n",
      " - 0s - loss: 0.1538 - r_square: 0.8737 - rmse: 0.1538 - val_loss: 0.1706 - val_r_square: 0.9002 - val_rmse: 0.1706    \n",
      "\n",
      "Epoch 100/100                                                                                                          \n",
      " - 0s - loss: 0.1550 - r_square: 0.8733 - rmse: 0.1550 - val_loss: 0.1665 - val_r_square: 0.8991 - val_rmse: 0.1665    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.1607003916940347                                                                                                     \n",
      "(4457, 6)                                                                                                              \n",
      "Model: \"sequential_5\"                                                                                                  \n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "dense_13 (Dense)             (None, 100)               700                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_9 (Dropout)          (None, 100)               0                                                               \n",
      "_________________________________________________________________                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_14 (Dense)             (None, 200)               20200                                                           \n",
      "_________________________________________________________________                                                      \n",
      "dropout_10 (Dropout)         (None, 200)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_15 (Dense)             (None, 1)                 201                                                             \n",
      "=================================================================                                                      \n",
      "Total params: 21,101                                                                                                   \n",
      "Trainable params: 21,101                                                                                               \n",
      "Non-trainable params: 0                                                                                                \n",
      "_________________________________________________________________                                                      \n",
      "Train on 3788 samples, validate on 669 samples                                                                         \n",
      "Epoch 1/50                                                                                                             \n",
      " - 0s - loss: 0.5347 - r_square: 0.4264 - rmse: 0.5347 - val_loss: 0.3493 - val_r_square: 0.7209 - val_rmse: 0.3493    \n",
      "\n",
      "Epoch 2/50                                                                                                             \n",
      " - 0s - loss: 0.3071 - r_square: 0.7274 - rmse: 0.3071 - val_loss: 0.2408 - val_r_square: 0.8221 - val_rmse: 0.2408    \n",
      "\n",
      "Epoch 3/50                                                                                                             \n",
      " - 0s - loss: 0.2535 - r_square: 0.7941 - rmse: 0.2535 - val_loss: 0.2336 - val_r_square: 0.8387 - val_rmse: 0.2336    \n",
      "\n",
      "Epoch 4/50                                                                                                             \n",
      " - 0s - loss: 0.2342 - r_square: 0.8027 - rmse: 0.2342 - val_loss: 0.1957 - val_r_square: 0.8526 - val_rmse: 0.1957    \n",
      "\n",
      "Epoch 5/50                                                                                                             \n",
      " - 0s - loss: 0.2193 - r_square: 0.8173 - rmse: 0.2193 - val_loss: 0.1890 - val_r_square: 0.8582 - val_rmse: 0.1890    \n",
      "\n",
      "Epoch 6/50                                                                                                             \n",
      " - 0s - loss: 0.2083 - r_square: 0.8191 - rmse: 0.2083 - val_loss: 0.1730 - val_r_square: 0.8627 - val_rmse: 0.1730    \n",
      "\n",
      "Epoch 7/50                                                                                                             \n",
      " - 0s - loss: 0.2023 - r_square: 0.8277 - rmse: 0.2023 - val_loss: 0.1778 - val_r_square: 0.8668 - val_rmse: 0.1778    \n",
      "\n",
      "Epoch 8/50                                                                                                             \n",
      " - 0s - loss: 0.2014 - r_square: 0.8231 - rmse: 0.2014 - val_loss: 0.1875 - val_r_square: 0.8623 - val_rmse: 0.1875    \n",
      "\n",
      "Epoch 9/50                                                                                                             \n",
      " - 0s - loss: 0.1928 - r_square: 0.8358 - rmse: 0.1928 - val_loss: 0.1735 - val_r_square: 0.8718 - val_rmse: 0.1735    \n",
      "\n",
      "Epoch 10/50                                                                                                            \n",
      " - 0s - loss: 0.1914 - r_square: 0.8344 - rmse: 0.1914 - val_loss: 0.1730 - val_r_square: 0.8709 - val_rmse: 0.1730    \n",
      "\n",
      "Epoch 11/50                                                                                                            \n",
      " - 0s - loss: 0.1865 - r_square: 0.8487 - rmse: 0.1865 - val_loss: 0.1652 - val_r_square: 0.8778 - val_rmse: 0.1652    \n",
      "\n",
      "Epoch 12/50                                                                                                            \n",
      " - 0s - loss: 0.1817 - r_square: 0.8324 - rmse: 0.1817 - val_loss: 0.1630 - val_r_square: 0.8789 - val_rmse: 0.1630    \n",
      "\n",
      "Epoch 13/50                                                                                                            \n",
      " - 0s - loss: 0.1812 - r_square: 0.8431 - rmse: 0.1812 - val_loss: 0.1567 - val_r_square: 0.8830 - val_rmse: 0.1567    \n",
      "\n",
      "Epoch 14/50                                                                                                            \n",
      " - 0s - loss: 0.1793 - r_square: 0.8461 - rmse: 0.1793 - val_loss: 0.1592 - val_r_square: 0.8881 - val_rmse: 0.1592    \n",
      "\n",
      "Epoch 15/50                                                                                                            \n",
      " - 0s - loss: 0.1756 - r_square: 0.8535 - rmse: 0.1756 - val_loss: 0.1555 - val_r_square: 0.8808 - val_rmse: 0.1555    \n",
      "\n",
      "Epoch 16/50                                                                                                            \n",
      " - 0s - loss: 0.1767 - r_square: 0.8498 - rmse: 0.1767 - val_loss: 0.1605 - val_r_square: 0.8908 - val_rmse: 0.1605    \n",
      "\n",
      "Epoch 17/50                                                                                                            \n",
      " - 0s - loss: 0.1741 - r_square: 0.8489 - rmse: 0.1741 - val_loss: 0.1501 - val_r_square: 0.8901 - val_rmse: 0.1501    \n",
      "\n",
      "Epoch 18/50                                                                                                            \n",
      " - 0s - loss: 0.1664 - r_square: 0.8606 - rmse: 0.1664 - val_loss: 0.1451 - val_r_square: 0.8899 - val_rmse: 0.1451    \n",
      "\n",
      "Epoch 19/50                                                                                                            \n",
      " - 0s - loss: 0.1690 - r_square: 0.8484 - rmse: 0.1690 - val_loss: 0.1483 - val_r_square: 0.8849 - val_rmse: 0.1483    \n",
      "\n",
      "Epoch 20/50                                                                                                            \n",
      " - 0s - loss: 0.1713 - r_square: 0.8515 - rmse: 0.1713 - val_loss: 0.1531 - val_r_square: 0.8874 - val_rmse: 0.1531    \n",
      "\n",
      "Epoch 21/50                                                                                                            \n",
      " - 0s - loss: 0.1688 - r_square: 0.8564 - rmse: 0.1688 - val_loss: 0.1469 - val_r_square: 0.8905 - val_rmse: 0.1469    \n",
      "\n",
      "Epoch 22/50                                                                                                            \n",
      " - 0s - loss: 0.1646 - r_square: 0.8635 - rmse: 0.1646 - val_loss: 0.1424 - val_r_square: 0.8945 - val_rmse: 0.1424    \n",
      "\n",
      "Epoch 23/50                                                                                                            \n",
      " - 0s - loss: 0.1660 - r_square: 0.8605 - rmse: 0.1660 - val_loss: 0.1444 - val_r_square: 0.8914 - val_rmse: 0.1444    \n",
      "\n",
      "Epoch 24/50                                                                                                            \n",
      " - 0s - loss: 0.1635 - r_square: 0.8524 - rmse: 0.1635 - val_loss: 0.1494 - val_r_square: 0.8938 - val_rmse: 0.1494    \n",
      "\n",
      "Epoch 25/50                                                                                                            \n",
      " - 0s - loss: 0.1634 - r_square: 0.8606 - rmse: 0.1634 - val_loss: 0.1403 - val_r_square: 0.8971 - val_rmse: 0.1403    \n",
      "\n",
      "Epoch 26/50                                                                                                            \n",
      " - 0s - loss: 0.1642 - r_square: 0.8616 - rmse: 0.1642 - val_loss: 0.1412 - val_r_square: 0.8930 - val_rmse: 0.1412    \n",
      "\n",
      "Epoch 27/50                                                                                                            \n",
      " - 0s - loss: 0.1608 - r_square: 0.8602 - rmse: 0.1608 - val_loss: 0.1467 - val_r_square: 0.8919 - val_rmse: 0.1467    \n",
      "\n",
      "Epoch 28/50                                                                                                            \n",
      " - 0s - loss: 0.1576 - r_square: 0.8639 - rmse: 0.1576 - val_loss: 0.1440 - val_r_square: 0.8997 - val_rmse: 0.1440    \n",
      "\n",
      "Epoch 29/50                                                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.1583 - r_square: 0.8579 - rmse: 0.1583 - val_loss: 0.1500 - val_r_square: 0.8992 - val_rmse: 0.1500    \n",
      "\n",
      "Epoch 30/50                                                                                                            \n",
      " - 0s - loss: 0.1594 - r_square: 0.8629 - rmse: 0.1594 - val_loss: 0.1367 - val_r_square: 0.8976 - val_rmse: 0.1367    \n",
      "\n",
      "Epoch 31/50                                                                                                            \n",
      " - 0s - loss: 0.1591 - r_square: 0.8567 - rmse: 0.1591 - val_loss: 0.1407 - val_r_square: 0.9003 - val_rmse: 0.1407    \n",
      "\n",
      "Epoch 32/50                                                                                                            \n",
      " - 0s - loss: 0.1594 - r_square: 0.8618 - rmse: 0.1594 - val_loss: 0.1381 - val_r_square: 0.9008 - val_rmse: 0.1381    \n",
      "\n",
      "Epoch 33/50                                                                                                            \n",
      " - 0s - loss: 0.1551 - r_square: 0.8668 - rmse: 0.1551 - val_loss: 0.1388 - val_r_square: 0.8972 - val_rmse: 0.1388    \n",
      "\n",
      "Epoch 34/50                                                                                                            \n",
      " - 0s - loss: 0.1565 - r_square: 0.8654 - rmse: 0.1565 - val_loss: 0.1383 - val_r_square: 0.9022 - val_rmse: 0.1383    \n",
      "\n",
      "Epoch 35/50                                                                                                            \n",
      " - 0s - loss: 0.1545 - r_square: 0.8638 - rmse: 0.1545 - val_loss: 0.1353 - val_r_square: 0.9002 - val_rmse: 0.1353    \n",
      "\n",
      "Epoch 36/50                                                                                                            \n",
      " - 0s - loss: 0.1523 - r_square: 0.8640 - rmse: 0.1523 - val_loss: 0.1331 - val_r_square: 0.9030 - val_rmse: 0.1331    \n",
      "\n",
      "Epoch 37/50                                                                                                            \n",
      " - 0s - loss: 0.1507 - r_square: 0.8704 - rmse: 0.1507 - val_loss: 0.1420 - val_r_square: 0.8961 - val_rmse: 0.1420    \n",
      "\n",
      "Epoch 38/50                                                                                                            \n",
      " - 0s - loss: 0.1569 - r_square: 0.8613 - rmse: 0.1569 - val_loss: 0.1398 - val_r_square: 0.9018 - val_rmse: 0.1398    \n",
      "\n",
      "Epoch 39/50                                                                                                            \n",
      " - 0s - loss: 0.1507 - r_square: 0.8725 - rmse: 0.1507 - val_loss: 0.1328 - val_r_square: 0.9032 - val_rmse: 0.1328    \n",
      "\n",
      "Epoch 40/50                                                                                                            \n",
      " - 0s - loss: 0.1505 - r_square: 0.8708 - rmse: 0.1505 - val_loss: 0.1378 - val_r_square: 0.9012 - val_rmse: 0.1378    \n",
      "\n",
      "Epoch 41/50                                                                                                            \n",
      " - 0s - loss: 0.1503 - r_square: 0.8692 - rmse: 0.1503 - val_loss: 0.1299 - val_r_square: 0.9046 - val_rmse: 0.1299    \n",
      "\n",
      "Epoch 42/50                                                                                                            \n",
      " - 0s - loss: 0.1483 - r_square: 0.8706 - rmse: 0.1483 - val_loss: 0.1388 - val_r_square: 0.8996 - val_rmse: 0.1388    \n",
      "\n",
      "Epoch 43/50                                                                                                            \n",
      " - 0s - loss: 0.1496 - r_square: 0.8721 - rmse: 0.1496 - val_loss: 0.1363 - val_r_square: 0.8986 - val_rmse: 0.1363    \n",
      "\n",
      "Epoch 44/50                                                                                                            \n",
      " - 0s - loss: 0.1469 - r_square: 0.8706 - rmse: 0.1469 - val_loss: 0.1291 - val_r_square: 0.9030 - val_rmse: 0.1291    \n",
      "\n",
      "Epoch 45/50                                                                                                            \n",
      " - 0s - loss: 0.1462 - r_square: 0.8746 - rmse: 0.1462 - val_loss: 0.1292 - val_r_square: 0.9067 - val_rmse: 0.1292    \n",
      "\n",
      "Epoch 46/50                                                                                                            \n",
      " - 0s - loss: 0.1460 - r_square: 0.8719 - rmse: 0.1460 - val_loss: 0.1326 - val_r_square: 0.9044 - val_rmse: 0.1326    \n",
      "\n",
      "Epoch 47/50                                                                                                            \n",
      " - 0s - loss: 0.1463 - r_square: 0.8747 - rmse: 0.1463 - val_loss: 0.1256 - val_r_square: 0.9050 - val_rmse: 0.1256    \n",
      "\n",
      "Epoch 48/50                                                                                                            \n",
      " - 0s - loss: 0.1479 - r_square: 0.8758 - rmse: 0.1479 - val_loss: 0.1280 - val_r_square: 0.9027 - val_rmse: 0.1280    \n",
      "\n",
      "Epoch 49/50                                                                                                            \n",
      " - 0s - loss: 0.1449 - r_square: 0.8775 - rmse: 0.1449 - val_loss: 0.1289 - val_r_square: 0.9071 - val_rmse: 0.1289    \n",
      "\n",
      "Epoch 50/50                                                                                                            \n",
      " - 0s - loss: 0.1448 - r_square: 0.8683 - rmse: 0.1448 - val_loss: 0.1304 - val_r_square: 0.9049 - val_rmse: 0.1304    \n",
      "\n",
      "Lowest Validation Loss:                                                                                                \n",
      "0.12564605643752802                                                                                                    \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:44<00:00,  8.91s/trial, best loss: -0.16136665374976103]\n",
      "1486/1486 [==============================] - 0s 9us/step\n",
      "Evaluate: 0.17111314383923285\n",
      "Best Performing Model: {'Dense': 200, 'Dropout': 0.25100000541347456, 'Dropout_1': 0.2738488340941711, 'batch_size': 64, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "#defining the create model function\n",
    "exec('from __future__ import absolute_import, division, print_function')\n",
    "from hyperas.distributions import uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras import backend as K\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    print(x_train.shape)\n",
    "    model= Sequential() \n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], activation= 'relu'))\n",
    "    model.add(Dropout({{uniform(0,.30)}}))\n",
    "    model.add(Dense({{choice([50,100,200,300,400])}},activation= 'relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0,.30)}}))\n",
    "    model.add(Dense(1, activation= 'linear'))\n",
    "\n",
    "    \n",
    "################################################\n",
    "# CREDIT: https://github.com/keras-team/keras/issues/7947\n",
    "    def rmse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "# mean squared error (mse) for regression  (only for Keras tensors)\n",
    "    def mse(y_true, y_pred):\n",
    "        from keras import backend\n",
    "        return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
    "    def r_square(y_true, y_pred):\n",
    "        SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "        SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "        return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "#############################################\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer= 'adam', metrics=[r_square, rmse])\n",
    "    from keras.utils import print_summary\n",
    "    print_summary(model, line_length=None, positions=None, print_fn=None)\n",
    "    result= model.fit(x_train, y_train,\n",
    "                      batch_size={{choice([64,128])}},\n",
    "                      epochs={{choice([50,100,150])}},\n",
    "                      verbose=2,\n",
    "                      validation_split =0.15)\n",
    "    validation_acc= np.min(result.history['val_loss'])\n",
    "    print('Lowest Validation Loss:', validation_acc)\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}   \n",
    "\n",
    "#finding the best model\n",
    "best_run, best_model= optim.minimize(model=create_model,\n",
    "                                     data=data,\n",
    "                                     algo=tpe.suggest,\n",
    "                                     max_evals=5,\n",
    "                                     trials=Trials(),\n",
    "                                     eval_space=True,\n",
    "                                     notebook_name='NeuralAnalysis')\n",
    "score= best_model.evaluate(X_test_scaled,y_test_scaled, batch_size= 64)\n",
    "\n",
    "predictions_test = best_model.predict(X_test_scaled)\n",
    "predictions_train = best_model.predict(X_train_scaled)\n",
    "\n",
    "#print best model results\n",
    "print('Evaluate:', score[0])\n",
    "#print('Predictions:', predictions[:6])\n",
    "print('Best Performing Model:', best_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'r_square', 'rmse']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result metrics\n",
    "best_model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "[0.17111314849208534, 0.8860461711883545, 0.17111314833164215]\n"
     ]
    }
   ],
   "source": [
    "#using data to evaluate best model \n",
    "x_train, y_train, x_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test, verbose=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using model to predict y values\n",
    "predictions = best_model.predict(X_test_scaled)\n",
    "predictions1 = best_model.predict(X_train_scaled)\n",
    "\n",
    "#predictions= test\n",
    "#predictions1= train \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Residuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title('Neural Network Residual Plot')\n",
    "plt.scatter(predictions1, predictions1 - y_train_scaled, c= \"orange\",label=\"Training Data\", s=4)\n",
    "plt.scatter(predictions, predictions - y_test_scaled, c= \"blue\",label=\"Testing Data\",s=4)\n",
    "plt.ylim(-2,2)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('neuralnetworkresidual.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the prediction with mse and r2 (train data)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_train = mean_squared_error(y_train_scaled, predictions1)\n",
    "r2_train = r2_score(y_train_scaled, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the prediction with mse and r2 (test data)\n",
    "mse_test = mean_squared_error(y_test_scaled, predictions)\n",
    "r2_test = r2_score(y_test_scaled, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) Train Data: 0.13920958578125808\n",
      "R-squared (R2) Train Data: 0.8607904142187419\n",
      "-----------------------------------\n",
      "Mean Squared Error (MSE) Test Data: 0.1399211308376265\n",
      "R-squared (R2) Test Data: 0.8577363184421886\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Squared Error (MSE) Train Data: {mse_train}\")\n",
    "print(f\"R-squared (R2) Train Data: {r2_train}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Mean Squared Error (MSE) Test Data: {mse_test}\")\n",
    "print(f\"R-squared (R2) Test Data: {r2_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Volve",
   "language": "python",
   "name": "volve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
